---
title: "Łagodne wprowadzenie do statystyki"
author:
- name: Tomasz Przechlewski
  email: t.plata-przechlewski@psw.kwidzyn.edu.pl
  affiliation: Powiślańska Szkoła Wyższa (Kwidzyn/Poland)
date: "Niedatowany/wersja robocza"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
link-citations: yes
description: (c) Tomasz Przechlewski / CC-BY license
subtitle: Podręcznik dla studentów wydziałów nauk o zdrowiu
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F )

## https://pogotowiestatystyczne.pl/jak-analizowac-wyniki-badan-przy-uzyciu-ankiety-wlasnego-autorstwa/
##
library("knitr")
library("ggplot2")
library("tidyverse")
library("ggpubr")
library("rstatix")
library ("lm.beta")
library ("pROC")
##
sample.size <- 1000

## Rozkład średniej z próby w zależności od wielkości próby 
## Podejście empiryczne

mks <- function  (n, maxN) {
  ## w is global
  sample <- rep(0, sample.size)
  for(i in 1:sample.size) {
    s <- floor(runif(n, min=0, max=maxN))
    sample[i] <- mean(w[s])
  }
  return (sample)
}

diffMx <- function (s, t)  { 
  ## sample (vector) - true_mean
  mean.diff <- s - t
## 10% błąd wagi
  max.err <- 0.1 * true.mean.w 

  return ( sum(abs(mean.diff) > max.err) )
  }


```

# Przedmiot i metody badań statystycznych

## Przedmiot statystyki

Wyraz statystyka ma wiele znaczeń: **statystyki zgonów** albo **statystyki
alkoholizmu** czyli **dane** dotyczące zgonów lub alkoholizmu.
Statystyka to też **dziedzina wiedzy**, upraszczając zbiór metod, które służą
do tworzenia statystyk w pierwszym znaczeniu tego słowa. 
Wreszcie statystyka to **pojedyncza metoda** ze zbioru metod opracowanych
w dziedzinie, np. średnia to statystyka. Trochę to niefortunne, ale
świat nie jest doskonały jak wiemy...

**Statystyka** (obiegowo): dział matematyki, a w związku z tym
wiedza absolutnie
pewna i obiektywna. Nieprawda choćby z tego powodu,
że nie jest działem matematyki.
Korzysta z metod matematycznych jak wiele innych dziedzin.

**Statystyka** od strony czysto praktycznej to: **dane** + **procedury**
(zbierania, przechowania, analizowania, prezentowania *danych*)
+ **programy**; Jeżeli statystyka kojarzy się komuś ze matematyką,
wzorami i liczeniem, to jak widać jest  to zaledwie podpunkt
procedury→analizowanie.

## Podstawowe pojęcia

Celem **badania statystycznego** jest uzyskanie informacji
o interesującym zjawisku na podstawie danych.
Zjawisko ma charakter masowy czyli dotyczy dużej liczby *obiektów*.
Nie interesuje nas jeden zgon (obiekt) tylko zgony wielu ludzi.

**Populacja** (**zbiorowość statystyczna**) to zbiór obiektów będący
przedmiotem badania statystycznego. Na przykład zgony w Polsce w roku 2022.

Każdy **obiekt** w populacji to 
**obserwacja** (zwana także **jednostką statystyczną** albo **pomiarem**)
na jednej lub więcej **zmiennych**.
Jeżeli interesującym zjawiskiem są zgony, obserwacją jest osoba zmarła
a zmiennymi wiek,
płeć, przyczyna zgonu oraz dzień tygodnia (w którym nastąpił zgon) zmarłej osoby.

**Próba** to część **populacji**.
Na przykład część zgonów w Polsce w roku 2022.

**Parametr**: wielkość numeryczna obliczona na podstawie populacji.

**Statystyka**: wielkość numeryczna obliczona na podstawie próby.

Populacja powinna być zdefiniowana w taki sposób, aby nie było wątpliwości
co tak naprawdę jest badane. Zgony to w oczywisty sposób za mało.
*Zgony mieszkańców Kwidzyna w roku 2022*.

Zwróćmy uwagę, że *Zgony w mieście Kwidzyn w roku 2022* to nie to samo
(ktoś może być mieszkańcem
a umrzeć w Polsce i/lub ktoś może nie być mieszkańcem i umrzeć w Kwidzynie.)

**Generalizacja**: ocena całości na podstawie części. Badamy zjawisko wypalenia
zawodowego pielęgniarek i pielęgniarzy w Polsce (populacja). Wobec zaporowych kosztów
mierzenia wszystkich decydujemy się na przeprowadzenie ankiety wśród studentów
pielęgniarstwa PSW (próba). Czy możemy twierdzić na podstawie próby, że wyniki
badania dla całej Polski są identyczne? Raczej nie...

Próba, która pozwala na generalizację nazywa się próbą **reprezentatywną**.
Najlepszym sposobem na uzyskanie próby reprezentatywnej jest losowanie.

W oczywisty sposób badanie na podstawie próby jest tańsze niż badanie całości, co nie
oznacza że jest tanie. Kontynuując przykład: musielibyśmy mieć listę wszystkich 
pielęgniarek i pielęgniarzy w Polsce. Z tej listy wylosować próbę a następnie skontaktować
się z wybranymi osobami (jak?). Dlatego też badania w oparciu o próbę nielosową są całkiem
popularne (bo są tanie); należy jednakże mieć świadomość ich ograniczeń, w tym a zwłaszcza
uogólnienia uzyskanych wyników.

**Mądrość statystyczna** nt liczebności próby i wnioskowania z próby niereprezentatywnej:
badano czy nowy preparat podnosi
nośność kur, w 33,3% przypadków podniósł w 33,3% przypadków nie
podniósł, a na 33,3 nie wiadomo, bo kura uciekła.

## Pomiar

Potocznie kojarzy się z linijką i wagą ale w statystyce używany jest w szerszym
znaczeniu. Ustalenie płci albo przyczyny zgonu to też pomiar.

**Pomiar** to przyporządkowanie wariantom **zmiennej** liczb lub symboli z pewnej **skali pomiarowej**.
Przykładowo jeżeli jednostką statystyczną jest zgon a zmiennymi 
wiek, płeć,
przyczyna zgonu oraz dzień tygodnia to
pomiar będzie polegał na ustaleniu (przyporządkowaniu) wieku w latach,
płci ('K'/'M'), przyczyny (identyfikatora z katalogu ICD10 zapewne)
oraz numeru dnia tygodnia (lub nazwy dnia tygodnia).
Wiek oraz numer dnia są liczbami, płeć i przyczyna symbolem.

Wyróżnia się następujące **typy skal pomiarowych**:

* **nominalna** (*nominal scale*), klasyfikuje: płeć zmarłego;

* **porządkowa** (*ordinal scale*), klasyfikuje i porządkuje: dzień tygodnia
w którym nastąpił zgon (po poniedziałku jest wtorek);

* **liczbowa**, mierzy w potocznym tego słowa znaczeniu: wiek zmarłego w latach

Mówimy **zmienna mierzalna** albo **zmienna ilościowa** dla zmiennych mierzonych
za pomocą skali liczbowej.  Mówimy **zmienna niemierzalna** albo
**zmienna jakościowa** dla zmiennych mierzonych za pomocą skali
nominalnej/porządkowej.

Zmienne mierzalne dzielą się na **skokowe**
oraz **ciągłe**.  Skokowe są to cechy, które przyjmują skończoną liczbę
wartości, zwykle są to liczby całkowite; Ciągłe są to cechy, które
przyjmują dowolne wartości liczbowe z pewnego przedziału liczbowego, np. ciśnienie krwi.

**Rodzaje danych**

* Przekrojowe (zmarli w Kwidzynie)

* Czasowe: każda obserwacja ma przypisany czas (liczba zmarłych w Polsce w latach 2000--20222)

* Przestrzenne : każda obserwacja ma przypisane miejsce na kuli ziemskiej (współrzędne geograficzne)

## Rodzaje i sposoby analizy danych

Rodzaje **analizy statystycznej** zależą od rodzaju danych
(jakie mamy dane takie możemy stosować metody):

* jedna zmienna/dane przekrojowe: analiza struktury

* jedna zmienna/dane czasowe: analiza dynamiki zjawiska

* co najmniej dwie zmienne: analiza współzależności (nadwaga powoduje cukrzycę)


Sposoby analizy danych zależą od sposobu pomiaru (populacja/próba/generalizacja):

**Opis statystyczny** -- (proste) przedstawienie badanych zbiorowości/zmiennych
 tabel, wykresów lub parametrów (np. średnia, mediana) ;
 Opis statystyczny może dotyczyć: -- struktury zbiorowości; -- współzależności; --
 zmian zjawiska w czasie.

**Wnioskowanie statystyczne**: wnioskowanie na temat całości na podstawie próby;
wykorzystuje metody analizy matematycznej

**Opisujemy** populację lub próbę. **Wnioskujemy** na podstawie próby o całości...

## Sposoby pomiaru danych i organizacja badania

Sposób pomiaru/organizacja badania ma zasadnicze znaczenie dla interpretacji wyników.
Są dwa fundamentalne rodzaje pomiaru
(sposobu zebrania danych) **eksperyment** oraz **obserwacja**.

Mówimy w związku z tym **dane eksperymentalne** albo **dane obserwacyjne**.

**Przykład**: chcemy ustalić czy spożywanie kawy w czasie sesji egzaminacyjnej
skutkuje uzyskaniem lepszej oceny. W celu oceny prawdziwości takiej
tezy przeprowadzono badanie wśród studentów pytając ich o to ile
kawy pili w czasie sesji i zestawiając te dane z wynikami egzaminów.
Średnie wyniki w
grupie studentów pijących dużo kawy były wyższe w grupie pijącej mało kawy.
Czy można powiedzieć, że udowodniono iż picie
dużej ilości kawy poprawia wynik egzaminu?

Raczej nie: można sobie wyobrazić, że studenci którzy poświęcili 
więcej czasu na naukę pili w tym czasie kawę (na przykład żeby nie zasnąć). 
Prawdziwą przyczyną jest czas poświęcony na przygotowanie a nie to ile ktoś
wypił lub nie wypił kawy. Inaczej mówiąc gdyby ktoś pił dużo kawy,
bo uwierzył, że to poprawi mu wyniki 
i się nie uczył, to pewnie by się rozczarował.

Rodzaje badań: **eksperymentalne** vs **obserwacyjne**. 

**Eksperyment kontrolowany** (zrandomizowany lub nie):
służy do weryfikacja związku **przyczyna-skutek**.
Skutek może być rezultatem działania wielu **czynników** (zmiennych).
Eksperymentator manipuluje wielkością przyczyn
(zmiennych **niezależnych**) oraz mierzy wielkość skutku (zmiennej **zależnej**);
Wszystkie pozostałe czynniki (zmienne **ukryte**) są **kontrolowane** (w tym
sensie, że ich wpływ na skutek jest ustalony.

Pomiarowi/manipulacji podlega zbiór jednostek podzielonych
**losowo** na dwie grupy: grupa **eksperymentalna** (**experimental group**)
oraz **grupa kontrolna** (**control group**)

W medycynie używa się terminu **badania kliniczne** czyli badania
które dotyczą ludzi. Badania kliniczne  także dzielą 
się na eksperymentalne oraz obserwacyjne. Eksperyment nazywa się 
RCT (*randomized clinical trial*/randomizowane kontrolowane badania kliniczne.)
Manipulacja określana jest jako
ekspozycja (**exposure**) albo leczenie (**treatment**)
Zmienne ukryte określa się mianem **confunding factors** (**czynniki zakłócające**)

Rysunek przedstawia zależność pomiędzy wynikiem (*outcome*), przyczyną
oraz czynnikami zakłócającymi na przykładzie zależności dotyczącej domniemanego
wpływu fluoryzowania wody na zwiększenie ryzyka zgonów z powodu nowotworów.
W badaniu którego autor uważał że udowodnił związek fluoryzowanie→nowotór
porównał on współczynniki zgonów z miast fluoryzujących oraz
nie fluoryzujących wodę. Okazało się, że przeciętnie współczynnik ten był wyższy
w grupie miast fluoryzujących wodę. Czy to świadczy, że fluoryzowanie wody
powoduje raka? Nie...

W innym badaniu tych samych miast okazało się, że
w grupie miast fluoryzujących wodę przeciętnie mieszkają starsi ludzie. 
A ponieważ współczynniki zgonów rosną wraz ze wzrostem wieku, to nie można
wykluczyć, że prawdziwą przyczyną obserwowanego zwiększenia wartości
współczynników zgonów jest wiek a nie fluoryzacja wody.


![](./Model1.png)

**Efekt przyczynowy** to **ilościowe** określenie wpływu
ekspozycji na wynik 
poprzez porównanie wielkości wyniku dla różnych wielkości ekspozycji

Są dwa typy **efektu przyczynowego**:
indywidualny efekt interwencji (*individual treatment effect*) oraz
średni efekt interwencji (*average treatment effect*)

**Individual Treatment Effect (ITE)**

Indywidualny efekt interwencji (ITE) określa ilościowo wpływ
interwencji dla konkretnej osoby, poprzez porównanie
wyników dla różnych wartości interwencji.
     
Mogę pić kawę lub nie pić kawy a wynikiem będzie ocena. Oczywiście
nie mogą zrobić tych dwóch rzeczy na raz...

**Average Treatment Effect (ATE)**

Średni efekt interwencji 
określa ilościowo wpływ interwencji dla grupy osób

W grupie studentów jedni pili kawę inni nie...

Jeżeli grupa (populacja) została uprzednio podzielona (losowo) na
grupę **eksperymentalną** oraz **grupę kontrolną**
możemy policzyć ATE oddzielnie dla obu grup.
Wtedy efekt przyczynowy można zdefiniować jako:

ATT - ATC (albo ATT/ATC)

gdzie: ATT oznacza ATE w grupie eksperymentalnej 
a ATC oznacza ATE w grupie kontrolnej.

**Przykład (kontynuuacja)**:
można przypuszczać, że oprócz kawy na wynik egzaminu ma wpływ np. wrodzone predyspozycje
w dziedzinie intelektualnej oraz czas poświęcony na naukę.
Aby kontrolować ten czynnik można podzielić losowo grupę studentów;
dzięki czemu średnia wielkość predyspozycji oraz czasu w obu grupach będzie podobna.
Następnie zalecamy studentom w **grupie eksperymentalnej** picie 1l kawy dziennie
a studentom w **grupie kontrolnej** podajemy 1l brązowej wody o smaku i zapachu kawy :-).
Średnie wyniki w
grupie studentów pijących 1l kawy okazały się wyższe niż w grupie pijącej kolorową wodę.
Czy można powiedzieć że udowodniono
iż picie dużej ilości kawy poprawia wynik egzaminu?
Raczej tak...


**Badania obserwacyjne** można z kolei podzielić na **analityczne** i **opisowe**.

W badaniach **analitycznych** porównuje się grupę kontrolną z grupą poddaną ekspozycji/leczeniu;
w badaniach przekrojowych nie ma grupy kontrolnej.

Badania analityczne dzielimy dalej na:

* **kohortowe**, 

* **kliniczno-kontrolne**,

* **przekrojowe**.

Badanie **kohortowe** (**cohort study**): wieloletnie badania na dużej grupie jednostek.
Pomiar zaczynamy od ekspozycji kończymy na wyniku/chorobie/zgonie 
(takie badanie nazywamy **prospektywnym**.
Problem: koszty (np. choroby rzadkie wymagają ogromnych kohort).

Badanie **kliniczno-kontrolne** (**case-control study**): **restrospektywna** ocena ekspozycji
dla jednostek, u których stwierdzono wynik (chorobę). Grupę kontrolną tworzą **dopasowane** jednostki
u których wyniku nie stwierdzono (dopasowane w sensie, że są podobne podobne.)
W praktyce badanie kliniczno-kontrolne to badanie chorych, którzy zgłosili się do przychodni;
grupą kontrolną są podobni chorzy (wiek, płeć) z innej przychodni :-)

Problem1: błąd pamięci (**recall bias**) pacjenci -- zwłaszcza zdrowi -- słabo pamiętają
fakty które miały miejsce lata temu.
Problem2: trudności z **dopasowaniem** grupy kontrolnej (łatwiej powiedzieć niż zrobić.)

Badania **prospektywne**: od przyczyny do skutku (cohort); badanie **retrospektywne**:
od skutku do przyczyny (case-control)

Badanie przekrojowe (**cross-sectional study**): badanie związku między wynikiem a ekspozycją
bez podziału na grupę eksperymentalną i kontrolną.

Problem: nie da się określić związku przyczyna-skutek w taki sposób jaki się stosuje w badaniach analitycznych,
ale można do tego celu zastosować **model** regresji liniowej.

**Przykład**: badamy grupę pacjentów przychodni onkologicznej. Stwierdzamy że 90% z nich paliło
papierosy. Czy z tego wynika że palenie powoduje raka? Niekoniecznie. Możemy **dopasować**
pacjentów o podobnym profilu demograficzno-społecznym z innej przychodni (którzy nie chorują na raka)
i stwierdzić że 20% z nich paliło. 
To już jest konkretny argument -- ale takie badanie nie jest już **przekrojowe**
tylko **kliniczno-kontrolne**.

**Przykład (kontynuuacja)**:
można oprócz pytania studentów o ilość kawy i wynik pytać ich jeszcze o czas poświęcony
na naukę oraz o średnią ze studiów (wrodzone predyspozycje w dziedzinie intelektualnej). 
Za pomocą metody regresji możemy ustalić czy i jak bardzo kawa, czas i predyspozycje
wpływają na ocenę. Teoretycznie zamiast eksperymentu można używać regresji, ale jest to w większości
przypadków trudne--albo zmienne nie da się zmierzyć (czy średnia ze studiów jest dobrą miarą predyspozycji?)
albo jakąś ważną zmienną pominiemy. Więcej na temat regresji w rozdziale 3.

Badanie **ekologiczne**: badanie (przekrojowe) zależności pomiędzy danymi **zagregowanymi** a nie indywidualnymi.
Przykładowo zależność pomiędzy przeciętną
wielkością dochodu narodowego, a przeciętną oczekiwaną długością życia np. na poziomie kraju.

Problem: błąd ekologizmu (**ecological fallacy**.) Zależności na poziomie indywidualnym oraz zagregowanym
mogą być różne. Można oczekiwać że im większy dochód tym osoba dłużej żyje (poziom indywidualny.) Jeżeli
w kraju występują duże różnice w dochodach (na przykład USA) to przeciętnie dochód jest wysoki, ale jest
dużo osób o niskich dochodach, o ograniczonym dostępie do służby zdrowia, i krótszej oczekiwanej długości życia.
Przeciętna oczekiwana długość życia na poziomie całego kraju jest niższa (bo jest sumą wysokiej
dla bogatych + niskiej dla biednych);
w rezultacie zależność na poziomie zagregowanym może się znacząco różnić
od tej na poziomie indywidualnym.

### Przykłady badań

Jest ustalony szablon artykułu naukowego, który powinien być podzielony na
następujące części:

1. **Wprowadzenie**: określenie problemu badawczego, celu badania;
2. **Materiał i metoda**: Opis danych i zastosowanych metod statystycznych
3. **Wyniki**: Rezultaty analiz
4. **Dyskusja**: Znaczenie uzyskanych wyników, jeżeli we wstępie postawiono hipotezy
   to tutaj należy 
   
Żeby się zorientować jakie dane (jakie zmienne i jak mierzone) oraz jakie metody statystyczne zostały
wykorzystane w pracy wystarczy zapoznać się z treścią punktu **materiał i metoda**. W szczególności
powinien tam być określony **rodzaj badania**: eksperyment, badanie kohortowe, kliniczno-kontrolne,
przekrojowe lub inne...

**Przykład 1: Czy konsumpcja soli kuchennej szkodzi? (eksperyment)**

Neal B. i inni zastosowali eksperyment kontrolowany do zbadania
wpływu substytucji chlorku sodu chlorkiem potasu na choroby sercowo-naczyniowe 
(*Effect of Salt Substitution on Cardioviscular Events and Death,
New England Journal of Medicine*,
https://doi.org/10.1056/NEJMoa2105675). W badaniu 
przeprowadzonym w Chinach, uczestniczyli mieszkańcy 600 wsi, podzieleni
losowo na dwie grupy. Uczestnik badania musiał mieć minimum 60 lat oraz
nadciśnienie krwi. W badaniu uczestniczyło prawie 21 tysięcy osób. 
Przez pięć lat trwania eksperymentu grupa kontrolna używała soli zawierającej 75% chlorku potasu oraz 25%
chlorku sodu; grupa badana zaś używała soli tradycyjnej czyli zawierającej
wyłącznie chlorek sodu. Obserwowano w okresie pięcioletnim w obu grupach 
liczbę udarów, incydentów sercowo-naczyniowych oraz zgonów. Wpływ 
substytucji oceniono porównując współczynniki ryzyka w obu grupach.


**Przykład 2: Konflikt praca-dom w zawodzie pielęgniarki (przekrojowe)**

Simon i inni badali konflikt Praca-Dom w zawodzie Pielęgniarki/Pielęgniarza
(Work-Home Conflict in the European Nursing Profession
Michael Simon 1, Angelika Kümmerling, Hans-Martin Hasselhorn; Next-Study Group
Int J Occup Environ Health 2004 Oct-Dec;10(4):384-91. doi: 10.1179/oeh.2004.10.4.384.
https://pubmed.ncbi.nlm.nih.gov/15702752/)

Konflikt Praca-Dom (WHC) to sytuacja kiedy
nie można zająć się zadaniami lub obowiązkami w jednej dziedzinie ze względu na obowiązki
w drugiej domenie. Teoria zapożyczona z obszaru Nauk o Zarządzaniu zapewne.
Ten konflikt jest mierzony odpowiednią skalą pomiarową składającą się z pięciu pytań.
Czynnikami które WHC mają powodować są: czas pracy,
grafik (w sensie rodzaj etatu/zmianowość),
nacisk-na-nadgodziny (występuje lub nie),
intensywność pracy, 
obciążenie emocjonalne oraz jakość zarządzania.
(ostatnie trzy mierzone odpowiednimi skalami pomiarowymi,
czytaj: serią pytań w ankiecie).
Badano 27,603 osoby.
Podstawowym narzędziem badawczym jak się łatwo domyśleć była ankieta,
a przyczyny WHC ustalono za pomocą metody regresji wielorakiej.

Teraz porówajmy koszty badania #1, w którym jedynie starano się ustalić że sól szkodzi (lub nie)
z badaniem #2, w którym starano się ustalić przyczyny stanów psychicznych badanych-:)


## Miary częstości chorób

**Populacja narażona** (*population at risk*): grupa osób podatnych na zdarzenie (chorobę); 
rak szyjki macicy dotyczy  kobiet a nie wszystkich.

**Współczynnik chorobowości** (*prevalence rate*): liczba chorych w określonym czasie (dzień, tydzień, rok) podzielona przez wielkość populacji narażonej. 
Ponieważ są to zwykle bardzo małe liczby, mnoży się wynik przez $10^n$ dla ułatwienia interpretacji. 
Czyli jeżeli
chorych w populacji narażonej o wielkości 1mln jest 20 osób, to współczynnik wynosi 20/1mln = 0,000002 co trudno
skomentować po polsku. Jeżeli pomnożymy owe 0,000002 przez 100 tys ($n=5$), to współczynnik będzie równy 2, 
co interpretujemy jako dwa przypadki na 100 tys.
(albo 0,2 na 10 tys, jeżeli $n=4$, co już jednak brzmi trochę gorzej.)

**Współczynnik zapadalności** (*incidence rate*): liczba nowych chorych w określonym czasie (dzień, tydzień, rok) podzielona przez wielkość populacji narażonej. Też zwykle pomnożona przez $10^n$

**Współczynnik śmiertelności** (*case fatality rate*): liczba zgonów z powodu X w określonym czasie (dzień, tydzień, rok) podzielona
przez liczbę chorych na X w tym samym czasie. Śmiertelność jest miarą ciężkości choroby X.

**Współczynnik zgonów** (*death rate*): liczba zgonów w określonym czasie przez średnią
liczbę ludności w tym czasie (pomnożone przez $10^n$).

Jeżeli współczynnik zgonów nie uwzględnia wieku, nazywany jest surowym (*crude*); grupy różniące się strukturą wieku
nie powinny być porównywane za pomocą współczynników surowych tylko standaryzowanych (*age-standardized* albo
*age-adjusted*). Przykładowo jeżeli porównamy współczynnik zgonów USA i Nigerii to okaże się że w USA jest wyższy
a to z tego powodu że społeczeństwo amerykańskie jest znacznie starsze (a umierają zwykle ludzie starzy)

**Współczynnik zgonów** standaryzowany według wieku to ważona średnia współczynników w poszczególnych
grupach wiekowych, gdzie wagami są udziały tychże grup wiekowych w pewnej **standardowej populacji**


## Oprogramowanie

Nie da się praktykować statystyki bez korzystania z programów komputerowych
i mamy w tym zakresie trzy możliwości:

1. Arkusz kalkulacyjny. Przydatny na etapie zbierania danych i ich wstępnej
   analizy, później już niekoniecznie. Policzenie niektórych rzeczy jest niemożliwe
   (brak stosownych procedur) lub czasochłonne (w porównaniu do 2--3)
  
2. Oprogramowanie specjalistyczne komercyjne takie jak programy STATA czy SPSS.
   Wady: cena i czas niezbędny na ich poznanie. 

3. Oprogramowanie specjalistyczne darmowe: Jamovi oraz R
   Same zalety:-)
   
W większości podręczników opisuje się **procedury** 
oraz **program**, w którym te procedury można zastosować jednocześnie. 
My zdecydowaliśmy się oddzielnie przestawić teorię statystyki (rozdziały 1--4)
a oddzielnie opis posługiwania się konkretnym programem (rozdział 5.)

# Analiza jednej zmiennej

**Statystyka opisowa** (opis statystyczny) to zbiór metod statystycznych służących do -- surprise, surprise -- opisu
(w sensie przedstawienia sumarycznego) zbioru danych;
w zależności od typu danych (przekrojowe, czasowe, przestrzenne) oraz sposobu pomiaru
(dane nominalne, porządkowe liczbowe) należy używać różnych metod.

W przypadku **danych przekrojowych** opis statystyczny nazywany jest **analizą struktury**
i sprowadza się do opisania danych z wykorzystaniem:

* tablic (statystycznych)

* wykresów

* parametrów (takich jak średnia czy mediana)

**Rozkład cechy** (zmiennej) to przyporządkowanie
wartościom cechy zmiennej odpowiedniej **liczby wystąpień** (liczebności albo częstości 
(czyli popularnych procentów).)

**Analiza struktury** (dla jednej zmiennej) obejmuje:

* **określenie tendencji centralnej** (tzw. **miary położenia** / wartość przeciętna, mediana, dominanta);

* **zróżnicowanie wartości** (rozproszenie);

* **asymetrię** (rozłożenie wartości wokół średniej);


## Tablice statystyczne

**Tablica statystyczna** to (w podstawowej formie) dwukolumnowa tabela zawierająca
wartości cechy oraz odpowiadające tym wartościom liczebności.

**Przykład 1**: Tablica dla cechy niemierzalnej (nominalnej albo porządkowej)

Absolwenci studiów pielęgniarskich w ośmiu największych
krajach UE w roku 2018

**Jednostka badania**: absolwent studiów pielęgniarskich w roku 2018, 

**Badana cecha**: kraj w którym ukończył studia (nominalna)


```{r, echo=F}
members <- read.csv("eu_codes_members.csv", sep = ';', dec = ".",  header=T, na.string="NA" ) %>%
  add_row(member = 'Other', geo = "OTHER")
members.codes <- members$geo
members.big <-c ('DE', 'ES', 'FR', 'IT', 'PL', 'RO', 'NL', 'BE')

g0 <- read.csv("nursing_graduates_UE.csv", sep = ';', dec = ".",  header=T, na.string="NA" )

g1 <- g0 %>%
  filter (year == 2018 & isco08 == 'OC2221_3221' & unit == 'NR') %>%
  filter (geo %in%  members.codes) %>%
  filter (geo %in%  members.big) %>%
  mutate ( geo =  as.factor(geo)) %>%
  left_join(members, by='geo') %>%
  select (member, values)

t1 <- kable(g1, col.names = c('kraj', 'liczba'))
```

Tablica: Absolwenci studiów pielęgniarskich w ośmiu największych
krajach UE w roku 2018

```{r, echo=F}
t1
```

Źródło: Eurostat, tablica Health graduates (HLTH_RS_GRD)

**Przykład 2**: Tablica dla cechy mierzalnej (liczbowej; skokowej lub ciągłej)

Jeżeli liczba wariantów cechy jest mała tablica zawiera wyliczenie
wariantów cechy i odpowiadających im liczebności. Jeżeli liczba wariantów
cechy jest duża tablica zawiera klasy wartości (przedziały wartości)
oraz odpowiadające im liczebności.

* Co do zasady klasy wartości powinny być jednakowej rozpiętości.

* Na zasadzie wyjątku dopuszcza się aby pierwszy i ostatni przedział
były **otwarte**, tj. nie miały dolnej (pierwszy) lub górnej
(ostatni) **granicy**


Tablica: Gospodarstwa domowe we wsi X wg liczby samochodów w roku 2022

```{r, echo=F}
l.s <- c('0', '1', '2', '3 i więcej', 'razem')
n.s <- c(230, 280, 70, 5, 585)
samochody.L <- tibble(l.s, n.s) %>%
  mutate (p = n.s/585 * 100 )

t3 <- kable(samochody.L, col.names = c('liczba samochodów', 'liczba gospodarstw', '%'))
t3
```

Źródło: obliczenia własne

Tablica dla cechy mierzalnej (liczbowej ciągłej--wymaga pogrupowania w klasy):

**Przykład**: Dzietność kobiet na świecie

Współczynnik dzietności (*fertility ratio* albo FR) -- przeciętna liczba urodzonych dzieci przypadających
na jedną kobietę w wieku rozrodczym (15–49 lat).
Przyjmuje się, iż FR między 2,10–2,15 zapewnia zastępowalność pokoleń.

Dane dotyczące dzietności dla wszystkich krajów świata można
znaleźć na stronie https://ourworldindata.org/grapher/fertility-rate-complete-gapminder)
Zbudujmy tablicę przedstawiającą rozkład współczynników dzietności w roku 2018

```{r, echo=F}
dA <- read.csv("fertility_rate_2003_2018.csv", sep = ';',
  header=T, na.string="NA");
d2018 <- dA %>% filter(yr==2018)
s2018 <- summary(d2018$frate)
mean2018 <- s2018[["Mean"]]
median2018 <- s2018[["Median"]]
srednia2018 <- s2018[["Mean"]]
min2018 <- s2018[["Min."]]
max2018 <- s2018[["Max."]]
N2018 <-nrow(d2018)

q1.2018 <- quantile(d2018$frate, probs = 0.25)
q3.2018 <- quantile(d2018$frate, probs = 0.75)
```

Krajów jest `r N2018`. Wartość minimalna to `r min2018` a wartość
maksymalna to `r max2018`. Decydujemy się na rozpiętość przedziału równą 0,5;
dolny koniec pierwszego przedziału przyjmujemy jako 1,0.

Zwykle przyjmuje się za końce przedziałów **okrągłe liczby**
bo dziwnie by wyglądało gdyby koniec przedziału np. był równy 1,05
zamiast 1,0. 

Liczba przedziałów jest dobierana metodą prób i błędów, tak aby:

* nie było przedziałów z zerową liczebnością

* przedziałów nie było za dużo ani za mało (typowo 8--15)

* większość populacji nie znajdowała się w jednej czy dwóch przedziałach


Tablica: Kraje świata według współczynnika dzietności (2018)

```{r, echo=F}
## https://www.statology.org/data-binning-in-r/
d2018 <- d2018 %>% mutate(frateClass = cut(frate, breaks=seq(1, 8, by=.5)))
##levels(d2018$frateClass)

d2018s <- d2018 %>% group_by(frateClass) %>% summarise(n=n())

t2 <- kable(d2018s, col.names = c('Wsp. dzietności', 'liczba krajów'))
t2
```

Źródło: https://ourworldindata.org/grapher/fertility-rate-complete-gapminder

Każda tablica statystyczna **musi** mieć:

1. Część liczbową (kolumny i wiersze); 

   + żadna rubryka w części liczbowej nie może być pusta (żelazna zasada); w szczególności brak danych należy
     explicite zaznaczyć umownym symbolem
   
2. Część opisową:

   + tytuł tablicy; 
   + nazwy (opisy zawartości) wierszy; 
   + nazwy (opisy zawartości) kolumn; 
   + wskazanie źródła danych;
   + ewentualne uwagi odnoszące się do danych liczb.

Pominięcie czegokolwiek z powyższego jest **ciężkim błędem**. Jeżeli
nie ma danych (a często nie ma--z różnych powodów -- należy to zaznaczyć a nie
pozostawiać pustą rubrykę)

## Wykresy

**Wykresy statystyczne** są graficzną formą prezentacji materiału
statystycznego, są mniej precyzyjne i szczegółowe niż tablice,
natomiast bardziej sugestywne.

Celem jest pokazanie rozkładu wartości cechy w populacji: jakie wartości występują
często a jakie rzadko, jak bardzo wartości różnią się między sobą. Jak różnią
się rozkłady dla różnych, ale logicznie powiązanych populacji
(np rozkład czegoś-tam w kraju A i B albo w roku X, Y i Z).

Do powyższego celu celu stosuje się: 

* **wykres słupkowy** (skala nominalna/porządkowa)

* **wykres kołowy** (skala nominalna/porządkowa)

* **histogram** (albo wykres słupkowy dla skal nominalnych)

Uwaga: **wykres kołowy** jest
zdecydowanie gorszy od wykresu słupkowego i nie jest zalecany.
**Każdy** wykres kołowy można wykreślić jako słupkowy i w takiej postaci
będzie on bardziej zrozumiały i łatwiejszy w interpretacji.

### skala nominalna

Wykres słupkowy (*bar chart*)

```{r, echo=F}

g2 <- g0 %>%
  filter (year == 2018 & isco08 == 'OC2221_3221' & unit == 'NR') %>%
  filter (geo %in%  members.codes) %>%
  mutate(geo=recode(geo,
    'AT' = 'AT', 'BE' = 'BE', 'BG' = 'BG', 'CY' = 'OTHER', 'CZ' = 'CZ',
    'DE' = 'DE', 'DK' = 'DK', 'EE' = 'OTHER', 'EL' = 'EL',
    'ES' = 'ES', 'FI' = 'FI', 'FR' = 'FR', 'HR' = 'HR', 'HU' = 'HU',
    'IE'= 'IE', 'IT' = 'IT', 'LT' = 'OTHER', 'LU' = 'OTHER',
    'LV' = 'OTHER', 'MT' = 'OTHER', 'NL' = 'NL', 'PL' = 'PL', 'PT' = 'PT',
    'RO' = 'RO', 'SI' = 'SI', 'SK' = 'SK' )) %>%
  group_by(geo) %>%
  summarise(values=sum(values)) %>%
  mutate ( geo =  as.factor(geo)) %>%
  left_join(members, by='geo') %>%
  select (member, values)

pc4 <- ggplot(g1, aes(x = reorder(member, values), y=values )) +
  geom_bar(stat="identity", fill='blue') +
  xlab(label="") + 
  ylab(label="") +
  theme(legend.position = "none") +
  coord_flip()+ 
  ggtitle("Rysunek: Absolwenci studiów pielęgniarskich w ośmiu największych krajach UE w roku 2018") +
  theme(plot.title = element_text(hjust = 0.5, size=8)) +
  labs(caption="Żródło: Eurostat, tablica Health graduates (HLTH_RS_GRD)")
pc4
```

Ekwiwalentny wykres kołowy wygląda być może efektowniej (z uwagi na paletę kolorów)

```{r, echo=F}
pc2 <- g1 %>%
  mutate(pct = values/sum(values)*100)  %>%
  ggplot(aes(x="", y=pct, fill=member)) + # pct used here so slices add to 100
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  geom_text(aes(label = values), size=3, position = position_stack(vjust=0.5)) +
  ggtitle("Rysunek: Absolwenci studiów pielęgniarskich w ośmiu największych krajach UE w roku 2018") +
  ##facet_wrap(~pie, ncol = 2) +
  theme_void() +
  theme(legend.position = "right") +
  theme(plot.title = element_text(hjust = 0.5, size=8)) +
  labs(caption="Żródło: Eurostat, tablica Health graduates (HLTH_RS_GRD)")
pc2
```


Ale jest mniej efektywny. Wymaga legendy w szczególności, która utrudnia 
interpretację treści (nieustannie trzeba porównywać koło z legendą żeby ustalić
który kolor to który kraj.)

Jeżeli zwiększymy liczbę krajów wykres kołowy staje się zupełnie nieczytelny
(brakuje rozróżnialnych kolorów a wycinki koła są zbyt wąskie żeby cokolwiek
wyróżniały):

```{r, echo=F}
pc21 <- g2 %>%
  mutate(pct = values/sum(values)*100)  %>%
  ggplot(aes(x="", y=pct, fill=member)) + # pct used here so slices add to 100
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  geom_text(aes(label = values), size=3, position = position_stack(vjust=0.5)) +
  ##facet_wrap(~pie, ncol = 2) +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5, size=8)) +
  ggtitle("Rysunek: Absolwenci studiów pielęgniarskich w krajach UE w roku 2018") +
  theme(legend.position = "right") +
  labs(caption="Żródło: Eurostat, tablica Health graduates (HLTH_RS_GRD)")
pc21
```

Wykres słupkowy dalej jest natomiast OK:

```{r, echo=F}
pc41 <- ggplot(g2, aes(x = reorder(member, values), y=values )) +
  geom_bar(stat="identity", fill='blue') +
  xlab(label="") + 
  ylab(label="") +
  theme(legend.position = "none") +
  coord_flip()+ 
  ggtitle("Absolwenci studiów pielęgniarskich w krajach UE w roku 2018") +
  theme(plot.title = element_text(hjust = 0.5, size=8) ) +
  labs(caption="Żródło: Eurostat, tablica Health graduates (HLTH_RS_GRD)")
pc41
```

### skala liczbowa

Histogram to coś w rodzaju wykresu słupkowego tylko na jednej osi zamiast
wariantów cechy są przedziały wartości.
Histogram przedstawiający rozkład współczynników dzietności dla 
wszystkich krajów świata w roku 2018

```{r message=FALSE, echo=FALSE}
h2018 <- ggplot(d2018, aes(x = frate)) + 
 geom_histogram(binwidth = 0.25, fill=default_cyan) +
 ylab("liczba krajów") +
 xlab("współczynnik dzietności") +
 ggtitle("Kraje świata według współczynnika dzietności (2018)") +
 labs(caption="źródło: https://ourworldindata.org/grapher/fertility-rate-complete-gapminder") +
 coord_cartesian(ylim = c(0, 30), xlim=c(0, 8))
h2018

```

Podobnie jak tablice, rysunki powinny być opatrzone tytułem
oraz zawierać źródło wskazujące na pochodzenie danych
(zobacz przedstawione przykłady.)

## Florence Nightingale

Nie każdy wie że Florence Nightingale, która 
w czasie wojny krymskiej zorganizowała opiekę nad rannymi żołnierzami,
była także statystykiem.

Aby przekonać swoich przełożonych do zwiększenia nakładów na szpitale polowe prowadziła
nie tylko staranną ewidencję szpitalną, ale zgromadzone dane potrafiła analizować, używając
także wykresów własnego projektu.

W szczególności słynny jest diagram Nightingale zwane także różą Nightingale, które wprawdzie
(podobno) nie okazały się szczególnie użyteczny, no ale nie każdy nowy 
pomysł jest od razu genialny:

![](./FN_diagram.jpg)

Jest to coś w rodzaju wykresu słupkowego tyle że zamiast słupków są wycinki koła. Wycinków jest dwanaście tyle ile miesięcy.
Długość promienia a co za tym idzie wielkość pola wycinka zależy od wielkości zjawiska,
który reprezentuje (przyczyna śmierci: rany/choroby/inne)

Wpisując Florence+Nightingale można znaleźć dużo informacji 
na temat, w tym: http://www.matematyka.wroc.pl/ciekawieomatematyce/pielegniarka-statystyczna

W 1859 roku Nightingale została wybrana jako pierwsza kobieta na członka Royal Statistical Society (Królewskie Stowarzyszenie Statystyczne) oraz została honorowym członkiem American Statistical Association (Amerykańskiego Stowarzyszenia Statystycznego).  

Więc szanowi czytelnicy wnioski są oczywiste :-) 

## Analiza parametryczna

Analiza parametryczna z oczywistych względów dotyczy tylko zmiennych
mierzonych na skali liczbowej.

### Miary położenia

Miary przeciętne (**położenia**) charakteryzują średni lub
typowy poziom wartości cechy. Są to więc takie wartości, wokół których
skupiają się wszystkie pozostałe wartości analizowanej cechy.

![](./canvas_distr_11.png)

Na rysunku po lewej mamy dwa rozkłady różniące się poziomem przeciętnym (czerwony ma przeciętnie mniejsze wartości
niż turkusowy). Są to rozkłady **jednomodalne**, tj. wartości skupiają się wokół jednej wartości.
Dla takich rozkładów ma sens obliczanie średniej arytmetycznej. 

Na rysunku po prawej mamy rozkłady **nietypowe**: **wielomodalne** (turkusowy)
lub **niesymetryczne** (fioletowy.) W rozkładzie niesymetrycznym wartości skupiają się nie centralnie,
ale po prawej/lewej od środka przedziału zmienności/wartości średniej).

W świecie rzeczywistym zdecydowana większość rozkładów jest jednomodalna. 
Rzadkie przypadki rozkładów wielomodalnych zwykle wynikają z łącznego analizowania
dwóch różniących się wartością średnią zbiorów danych.
Oczywistym zaleceniem w takiej sytuacji jest analiza każdego zbioru oddzielnie.

Rodzaje miar położenia


* klasyczne 
  + **średnia arytmetyczna**
* pozycyjne 
  + **mediana**
  + **dominanta**
  + **kwartyle**
  + ewentualnie kwantyle, decyle, centyle (rzadziej używane)

**Średnia arytmetyczna** (*Mean*, *Arithmetic mean*) to łączna suma
wartości podzielona przez liczbę sumowanych jednostek. Jeżeli
wartość jednostki $i$ w $N$-elementowym zbiorze oznaczymy 
jako $x_i$ (gdzie: $i=1,\ldots,N$) to
średnią można zapisać jako $\bar x = (x_1 + \cdots + x_N)/N$

Uwaga: we wzorach statystycznych zmienne zwykle oznacza się małymi literami
a średnią dla zmiennej przez umieszczenie nad nią kreski poziomej czyli
$\bar x$ to średnia wartość zmiennej $x$.

**Mediana** (*Median*, kwartyl drugi) dzieli **uporządkowaną** zbiorowość na dwie równe części;
połowa jednostek ma wartości cechy mniejsze lub równe medianie, a połowa
wartości cechy równe lub większe od mediany. 
Stąd też mediana bywa nazywana wartością środkową.

Własności mediany: odporna na wartości nietypowe (w przeciwieństwie do średniej)

**Kwartyle**: coś jak mediana tylko bardziej szczegółowo. Kwartyli jest trzy i dzielą
one zbiorowość na 4 równe części, każda zawierająca 25% całości. 

Pierwszy kwartyl dzieli **uporządkowaną** zbiorowość w proporcji 25%--75%.
Trzeci dzieli **uporządkowaną** zbiorowość w proporcji 75%--25%. 
Drugi kwartyl to mediana.

**Kwantyle** (D, wartości dziesiętne), podobnie jak kwartyle, tyle że dzielą na 10 części.

**Centyle** (P, wartości setne), podobnie jak kwantyle tyle że dzielą na 100 części.
Przykładowo wartość 99 centyla i mniejszą ma 99% jednostek w populacji.

**Przykład: współczynnik dzietności na świecie w roku 2018**

Średnia wartość współczynnika `r sprintf ("%.2f", mean2018)`; mediana -- `r median2018`. 
Interpretacja średniej:
wartość współczynnika dzietności wyniosła `r sprintf ("%.2f", mean2018)` dziecka. Uwaga:
średnia dzietność na świecie **nie wynosi** `r sprintf ("%.2f", mean2018)`
(bo kraje różnią się liczbą ludności).
Interpretacja mediany: dzietność kobiet w połowie krajów na świecie
wynosiła `r median2018` i mniej. Uwaga: dzietność połowy kobiet na świecie wyniosła
`r median2018` i mniej jest niepoprawną interpretacją (różne wielkości krajów.)

**Generalna uwaga**: interpretacja średniej-średnich często jest nieoczywista i należy uważać.
(a współczynnik dzietności jest średnią: średnia liczba dzieci urodzonych przez kobietę 
w wieku rozrodczym. Jeżeli liczymy średnią dla 202 krajów, to mamy *średnią-średnich*).
Inny przykład: odsetek ludności w wieku poprodukcyjnym wg powiatów (średnia z czegoś takiego
nie da nam odsetka ludności w wieku poprodukcyjnym w Polsce, 
bo powiaty różnią się liczbą ludności.)

**Kontynuując przykład**:

Pierwszy kwartyl: `r q1.2018`; trzeci kwartyl `r q3.2018` co oznacza że
25% krajów miało wartość współczynnika dzietności nie większą niż `r q1.2018` dziecka
a 75% krajów miało wartość współczynnika dzietności 
nie większą niż `r q3.2018` dziecka.

### Miary zmienności

Miary zmienności określają zmienność (dyspersję albo rozproszenie) w zbiorowości

Rodzaje miar zmienności:

* Klasyczne
  + Wariancja i odchylenie standardowe

* Pozycyjne
  + rozstęp
  + rozstęp ćwiartkowy


**Wariancja** (*variance*) jest to średnia arytmetyczna kwadratów
odchyleń poszczególnych wartości cechy od średniej arytmetycznej
zbiorowości. Co można zapisać

$$s^2 = \frac{1}{N} \left( (x_1 - \bar x)^2 + (x_2 - \bar x)^2 + 
\cdots +  (x_N - \bar x)^N \right)$$ 

Przy czym często zamiast dzielenie przez $N$ dzielimy przez $N-1$.

**Odchylenie standardowe** (*standard deviation*, sd) jest
pierwiastkiem kwadratowym z wariancji. Parametr ten określa
przeciętną różnicą wartości cechy od średniej arytmetycznej.

**Rozstęp ćwiartkowy** (*interquartile range*, IQR) ma banalnie prostą definicję:

$$
R_Q = Q_3 - Q_1
$$
gdzie: $Q_1$, $Q_3$ oznaczają odpowiednio pierwszy oraz trzeci kwartyl.

**Przykład**: współczynnik dzietności na świecie w roku 2018 (cd)

```{r, echo=F}
sd2018 <-  sd(d2018$frate)
iqr2018 <- q3.2018 - q1.2018
```

Średnie odchylenie od średniej wartości współczynnika wynosi `r sd2018` dziecka. 
Wartość rozstępu ćwiartkowego wynosi `r iqr2018` dziecka.

**Uwaga**: odchylenie standardowe/ćwiartkowe są miarami mianowanymi. Zawsze należy
podać jednostkę miary.

### Miary asymetrii

Asymetria (*skewness*), to odwrotność symetrii. Szereg jest symetryczny
jeżeli jednostki są rozłożone ,,równomiernie'' wokół wartości średniej.
W szeregu symetrycznym wartości średniej i mediany są sobie równe.

![](./Negative_and_positive_skew.png)

Skośność może być dodatnia (*Positive Skew*) lub ujemna (*Negative Skew*). Czym się różni jedna
od drugiej widać na rysunku.

Miary asymetrii:

* klasyczny współczynnik asymetrii ($g$)

  + przyjmuje wartości ujemne dla asymetrii lewostronnej; a dodatnie
    dla prawostronnej. Teoretycznie może przyjąć dowolnie dużą wartość
    ale w praktyce rzadko przekracza 3 do do wartości bezwzględnej.
  + wartości większe od 2 świadczą o dużej a większe od 3 o bardzo dużej
    asymetrii

* współczynniki asymetrii Pearsona ($W_s$)
  + wykorzystuje różnice między średnia Medianą: $W_s = (\bar x - Me)/s$

* Współczynnik asymetrii (skośności) oparty na odległościach 
  między kwartylami lub decylami:
  
  + Obliczany jest według następującej 
    formuły: $W_{sq} =  \frac{(Q_3 - Q_2) - (Q_2 - Q_1)}{Q_3 - Q_1}$
 
 
### (Parametryczna) analiza struktury w jednym zdaniu

Polega na obliczeniu

  * średniej i mediany
  
  * odchylenia standardowego i rozstępu ćwiartkowego
   
  * współczynnika skośności $g$
  
Oraz
  
  *  zinterpretowaniu powyższych parametrów (patrz przykłady)


## Porównanie wielu rozkładów

Często strukturę jednego rozkładu należy porównać z innym. Albo trzeba porównać
strukturę wielu rozkładów. Pokażemy jak to zrobić na przykładzie.

```{r}
hw <- 4

fb <- read.csv("rwc-2015-2023.csv", sep = ';', dec = ".",  header=T, na.string="NA" ) %>%
  select(year, weight, poscode )

```

**Przykład: masa ciała uczestników Pucharu Świata w Rugby**

W turniejach o puchar świata w Rugby w latach 2015, 2019 i 2023 uczestniczyło łącznie `r nrow(fb)` zawodników.
W grze w rugby drużyna jest podzielona na dwie **formacje**: ataku i młyna. Należy scharakteryzować
rozkład masy ciała zawodników obu formacji.

**Zawodnicy ataku**

```{r}
backs <- c('BR', 'CE', 'FB', 'FH', 'WI', 'SH', 'HB', 'BB')
forwards <- c('PR', 'SR', 'HK', 'FF')

fb <- fb %>% mutate (poscode = recode(poscode,
'BR' = 'A',
'CE' = 'A',
'FB' = 'A',
'FH' = 'A',
'WI' = 'A',
'SH' = 'A',
'HB' = 'A',
'BB' = 'A',
'PR' = 'M',
'SR' = 'M',
'HK' = 'M',
'FF' = 'M'
                                    ) )

b <- fb %>% filter (poscode == 'A')

mean.b <- mean(b$weight, na.rm = T)  
median.b <- median(b$weight, na.rm=T) 
q1.b <- quantile(b$weight, probs=.25, na.rm  =TRUE)
q3.b <- quantile(b$weight, probs=.75, na.rm =TRUE) 
iqr.b <- IQR(b$weight, na.rm = T)
sd.b <- sd(b$weight, na.rm=T)
```

Przeciętnie zawodnik ataku ważył `r sprintf ("%.1f", mean.b)` kg; 
mediana `r sprintf("%.1f", median.b)` kg (połowa
zawodników ataku ważyła `r sprintf ("%.1f", median.b)` kg i mniej);
pierwszy/trzeci kwartyl `r q1.b`/`r q3.b` kg (1/4 zawodników
ataku ważyła `r q1.b` kg i mniej; 
1/4 zawodników ataku ważyła `r q3.b` kg i więcej;

Odchylenie standardowe `r sprintf("%.1f", sd.b)` kg (przeciętnie
odchylenie od średniej arytmetycznej wynosi `r sprintf("%.1f", sd.b)` kg);
rozstęp ćwiartkowy wynosi `r iqr.b` kg (rozstęp 50% środkowych wartości 
wynosi `r iqr.b` kg)

Histogram przy przyjęciu długości przedziału równej `r hw`kg 
(linia zielona  oznacza poziom średniej):

```{r, warning=FALSE}
h1.b <- ggplot(b, aes(x = weight)) + 
  geom_histogram(binwidth = hw, fill='deepskyblue3') +
  ylab("N") +
  xlab("kg") +
  geom_vline(xintercept = mean.b, colour="forestgreen", size=1) +
  ggtitle("Masa ciała zawodników ataku")
h1.b
```

**Zawodnicy młyna**

```{r}
f <- fb %>% filter (poscode == 'M' )

mean.f <- mean(f$weight, na.rm=T)  
median.f <- median(f$weight, na.rm=T) 
q1.f <- quantile(f$weight, probs=.25, na.rm =T)
q3.f <- quantile(f$weight, probs=.75, na.rm =T)
iqr.f <- IQR(f$weight, na.rm = T)
sd.f <- sd(f$weight, na.rm=T)
```

Średnio zawodnik młyna ważył `r sprintf ("%.1f", mean.f)` kg; 
mediana `r sprintf("%.1f", median.f)` kg (połowa zawodników
młyna ważyło `r median.f` kg i mniej);
pierwszy/trzeci kwartyl `r q1.f`/`r q3.f` kg (1/4 zawodników
młyna ważyło `r q1.f` kg i mniej; 
1/4 zawodników młyna ważyło `r q3.f` kg i więcej;

Odchylenie standardowe `r sprintf("%.1f", sd.f)` kg (przeciętnie
odchylenie od średniej arytmetycznej wynosi `r sprintf("%.1f", sd.f)` kg);
rozstęp ćwiartkowy wynosi `r iqr.f` kg (rozstęp 50% środkowych wartości 
wynosi `r iqr.f` kg)

Histogram przy przyjęciu długości przedziału równej `r hw`kg
(linia zielona  oznacza poziom średniej):

```{r, warning=FALSE}
h1.f <- ggplot(f, aes(x = weight)) + 
  geom_histogram(binwidth = hw, fill='deepskyblue3') +
  ylab("N") +
  xlab("kg") +
  geom_vline(xintercept = mean.f, colour="forestgreen", size=1) +
  ggtitle("Masa ciała zawodników młyna")
h1.f
```

**Porównanie atak vs młyn**


| Miara      | Atak         |  Młyn        |
|------------|--------------|--------------|
| średnia    | `r mean.b`   | `r mean.f`   |
| mediana    | `r median.b` | `r median.f` |
| odchyl.st  | `r sd.b`     | `r sd.f`     |
| iqr        | `r iqr.b`    | `r iqr.f`    |

średnio zawodnik młyna ważył prawie 20 kg więcej od zawodnika ataku (w przypadku mediany
jest to dokładnie 20 kg więcej). 
Zmienność mierzona wielkością odchylenia standardowego oraz IQR jest w obu grupach podobna.

```{r}
ggarrange(h1.b, h1.f, ncol = 2, nrow = 1)
```

### Wykres pudełkowy

Do porównania wielu rozkładów szczególnie użyteczny jest wykres zwany pudełkowym (**box-plot**)

Konstrukcja pudełka na wykresie: 
górny/dolny bok równy kwartylom, a linia pozioma w środku pudełka równa medianie;
linie pionowe (zwane wąsami) mają długość równą $Q_1 - 1,5 \textrm{IQR}$ 
oraz $Q_3 + \textrm{IQR}$ (dla przypomnienia: $Q_1$, $Q_3$ to kwartyle, zaś $\textrm{IQR}$ to odstęp między kwartlowy); Linia pozioma w połowie pudełka określa przeciętny poziom zjawiska; wysokość pudełka/wąsów
określa zmienność (im większe wąsy/wysokość tym większa zmienność).
Obserwacje nietypowe (czyli takie których wartość jest albo mniejsza od $Q_1 - 1,5\textrm{IQR}$
albo większa od $Q_3 + 1,5\textrm{IQR}$) są zaznaczane indywidualnie jako kropki nad/pod wąsami.

![](./box-plot-0.jpg)

Zwróć uwagę na sztuczkę: wartości nietypowe nie są definiowane jako (na przykład) górne/dolne
1% wszystkich wartości (bo wtedy **każdy rozkład** miałby wartości nietypowe);
ale jako wartości mniejsze/większe od $Q_* \pm 1,5 \times \mathrm{IQR}$.
Wszystkie wartości rozkładów o umiarkowanej zmienności mieszczą się wewnątrz czegoś takiego.

Wykres pudełkowy dla zawodników rugby w podziale na formacie ataku i młyna. 

```{r}
pow <- fb %>%
  na.omit() %>%  ggplot(aes(y=weight, x=poscode, fill=weight)) + 
  geom_boxplot() + 
  ylab("#") + 
  xlab('')
pow
```

Z wykresu od razu widać, który rozkład ma wyższą średnią a który większe rozproszenie.


Pudełek może być więcej oczywiście. Przykładowo
masa ciała zawodników na poszczególnych turniejach:

```{r}
pox <- fb %>%
  na.omit() %>%  ggplot(aes(y=weight, x=as.factor(year), fill=weight)) + 
  geom_boxplot() + 
  ylab("#") + 
  xlab('')
pox
```

Od razu widać, że przeciętnie najcięższy zawodnicy byli na turnieju w roku 2019; największe zróżnicowanie masy
ciała występowało na turnieju w roku 2023.

# Łagodne wprowadzenie do wnioskowanie statystycznego

**Chcemy się dowiedzieć czegoś na temat populacji (całości)
na podstawie próby (części tej całości).**

Przykładowo chcemy ocenić ile wynosi średnia waga główki kapusty
na 100 h polu. Można ściąć wszystkie i zważyć, ale można też ściąć
trochę (pobrać próbę się mówi uczenie) zważyć i poznać średnią
na całym polu z dobrą dokładnością.

## Przykładowy problem nr 1


```{r}
r <- read.csv("rwc2015.csv", sep = ';', dec = ",",  header=T, na.string="NA")

w <- as.vector(na.omit(r$weight))
wN <- length(w)
```

W turnieju o Puchar Świata w rugby w 2015 roku uczestniczyło
`r wN` rugbystów. Znamy szczegółowe dane odnośnie wzrostu i wagi każdego
uczestnika turnieju. Obliczamy (prawdziwą) średnią, odchylenie standardowe 
i współczynnik zmienności masy ciała:

```{r}
summary(w)
## 102.8 kg
#sd(w)
## 12.9 kg
true.mean.w <- mean(w)
## 46.24 lat
#sd(w, na.rm = T)
max.err <- 0.1 * true.mean.w 
max.err.sd <- sd(w, na.rm = T) 

#max.err.sd / true.mean.w * 100
```

Czyli średnio rugbysta na turnieju RWC'2015 ważył 
`r sprintf ("%.2f", true.mean.w)` kg (`Mean` na wydruku powyżej)
a odchylenie standardowe (*s*) wyniosło `r sprintf("%.2f", max.err.sd)` kg.

Wykres (rozkład jest dwumodalny; bo w rugby są dwie grupy zawodników, wcale
nie wszyscy > 110 kg):

```{r}
q1 <- ggplot(r, aes(x=weight)) +
  geom_vline(xintercept = true.mean.w, colour="forestgreen", size=.4) +
  geom_histogram(binwidth=2, alpha=.5, fill="steelblue") +
  ggtitle("Rozkład wagi zawodników")
q1
```


**Szacujemy średnią na podstawie 2 zawodników pobranych losowo**

Powtarzamy eksperyment `r sample.size` razy (dwóch bo dla jednego nie obliczmy 
wariancji)

```{r}
s02 <- mks(2, wN)

summary(s02)
mean.s02 <- mean(s02)
sd.s02 <- sd(s02)
```

średnia (średnich z próby) ma wartość `r sprintf("%.2f", mean.s02)` 
a odchylenie standardowe `r sprintf("%.2f", sd.s02)`.
Wartość $s/\sqrt{2}$ (odchylenie standardowe podzielone przez pierwiastek kwadratowy 
z liczebności próby) jest równa `r sprintf("%.2f", max.err.sd/sqrt(2)) `. Zauważmy że ta wartość
jest zbliżona do odchylenia standardowego uzyskanego 
w eksperymencie (`r sprintf("%.2f", sd.s02)` vs `r sprintf ("%.2f", max.err.sd/sqrt(2)) `)

**szacujemy średnią na podstawie 10 zawodników pobranych losowo**

Powtarzamy eksperyment `r sample.size` razy

```{r}
s10 <- mks(10, wN)

summary(s10)
#sd(s10)
mean.s10 <- mean(s10)
sd.s10 <- sd(s10)
```

średnia wyszła `r round(mean.s10, 2)` a odchylenie standardowe 
`r round(sd.s10, 2)`.
Wartość $s/\sqrt{10}$ jest równa `r round(max.err.sd/sqrt(10), 2)`.

**szacujemy średnią na podstawie 40 zawodników pobranych losowo**

Uwaga: 40 zawodników to około `r sprintf ("%.1f%%", 40/wN *100)` 
całego zbioru.
Powtarzamy eksperyment `r sample.size` razy

```{r}
s40 <- mks(40, wN)
summary(s40)
##sd(s40)
mean.s40 <- mean(s40)
sd.s40 <- sd(s40)

```

średnia jest równa `r round(mean.s40, 2)` a odchylenie standardowe `r round(sd.s40, 2)`.
Wartość $s/\sqrt{40}$ jest równa `r round(max.err.sd/sqrt(40), 2)`.

**Wykres**

Podsumujmy eksperyment wykresem rozkładu wartości średnich.

```{r}
all.samples <- data.frame(s02, s10, s40)

error10 <- true.mean.w  * 0.1

p1 <- all.samples %>%
  pivot_longer(cols = c(s02, s10, s40), names_to = 'k', values_to = 'v') %>%
  ggplot(aes(x=v)) +
  facet_wrap(~ k) +
  geom_vline(xintercept = true.mean.w, colour="forestgreen", size=.4) +
  geom_vline(xintercept = true.mean.w - max.err.sd, colour="red", size=.4) +
  geom_vline(xintercept = true.mean.w + max.err.sd, colour="red", size=.4) +
  geom_vline(xintercept = true.mean.w - error10, colour="orange", size=.4) +
  geom_vline(xintercept = true.mean.w + error10, colour="orange", size=.4) +
  geom_histogram(binwidth=1, alpha=.5, fill="steelblue") +
  ggtitle("rozkład średniej wagi rugbystów w zależności od wielkości próby")
p1
```

**Wnioski z eksperymentu**

Wartość średnią wyznaczamy na podstawie jakiejś konkretnej **metody**.
Wydaje się na podstawie powyższych eksperymentów, że z dobrym skutkiem
możemy jako metodę wykorzystać **średnią-z-próby**.

W ogólności taką metodą, która formalnie jest funkcją elementów z próby, nazywa się
w statystyce **estymatorem**. Warto to pojęcie zapamiętać. Wnioskujemy
o wartości parametru w populacji posługując się estymatorem.

Kontynuując wnioski z eksperymentu należy zauważyć, że
wszystkie średnie-ze-średnich (bez względu na liczebność próby) są zbliżone do wartości
prawdziwej (to się nazywa **nieobciążoność** estymatora);
Mówiąc innymi słowy jeżeli będziemy oceniać wartość prawdziwej średniej na podstawie próby,
a naszą ocenę powtórzymy wielokrotnie,
to średnia będzie zbliżona do wartości prawdziwej (a nie np. niższa czy wyższa)
Ta cecha jest niezależna od wielkości próby.

Jeżeli rośnie liczebność próby to zmienność wartości średniej-w-próbie maleje, co za tym
idzie  prawdopodobieństwo, że wartość oceniona na podstawie
średniej z próby będzie zbliżona do wartości szacowanego parametru rośnie (to się nazywa **zgodność**).
Co więcej dobrym przybliżeniem zmienności średniej-w-próbie
jest prosta formuła $s/\sqrt{n}$ gdzie $n$ jest liczebnością próby a $s$ jest odchyleniem
standardowym w populacji z której pobrano próbę. 

Jeżeli mamy dwa rózne estymatory służące do oszacowania parametru, 
oba są **nieobciążone** oraz **zgodne**, to który wybrać?
Ten która ma **mniejszą wariancję**. Taki estymator nazywa się **efektywny**.

Estymator zatem powinien być **nieobciążony**, **zgodny** oraz **efektywny** (czyli mieć
małą wariancję). Można matematycznie udowodnić, że pewien estymator ma tak małą wariancję, że
niemożliwe jest wynalezienie czegoś jeszcze bardziej efektywnego. Takim estymatorem
średniej w populacji  jest średnia z próby...

Konkretną wartość estymatora dla konkretnych wartości próby nazywamy **oceną**
(parametru)

## Przykładowy problem nr 2

```{r}
r <- read.csv("kandydaci_ws_2018_3.csv", sep = ';', dec = ",",  header=T, na.string="NA")

w <- as.vector(na.omit(r$wiek))
wN <- length(w)
```

W wyborach samorządowychych w Polsce w roku 2018 o mandat radnego
sejmików wojewódzkich ubiegało się `r wN` kandydatów. 
Znamy szczegółowe dane odnośnie wieku każdego kandydata,
bo to zostało publicznie podane przez Państwową Komisję Wyborczą.
Obliczamy (prawdziwą) średnią, odchylenie standardowe 
i współczynnik zmienności wieku kandydatów:

```{r}
summary(w)
true.mean.w <- mean(w)
##sd(w)
max.err <- 0.1 * true.mean.w 
max.err.sd <- sd(w) 
##max.err.sd / true.mean.w * 100
```

Czyli średnio kandydat miał `r round(true.mean.w, 2)` lat
a odchylenie standardowe wieku wyniosło `r round(max.err.sd, 2)` lat.

Wykres (rozkład znowu jest dwumodalny z jakiś powodów):

```{r}
q1 <- ggplot(r, aes(x=wiek)) +
  geom_vline(xintercept = true.mean.w, colour="forestgreen", size=.4) +
  geom_histogram(binwidth=2, alpha=.5, fill="steelblue") +
  ggtitle("Rozkład wieku kandydatów")
q1
```


**Szacujemy średnią na podstawie 2 kandydatów pobranych losowo**

Powtarzamy eksperyment `r sample.size` razy


```{r}
k02 <- mks(2, wN)

summary(k02)
sd02 <- sd(k02)
mean.s02 <- mean(k02)
```

Średnia średnich z próby ma wartość `r round(mean.s02, 2)` lat.
Odchylenie standardowe wyniosło `r  round(sd02, 2)`.
Wartość $s/\sqrt{2}$ jest równa `r round(max.err.sd/sqrt(2), 2) `.

**Szacujemy średnią na podstawie 10 kandydatów pobranych losowo**

Powtarzamy eksperyment `r sample.size` razy.

```{r}
k10 <- mks(10, wN)
summary(k10)
sd10 <- sd(k10)
mean.s10 <- mean(k10)
```

Średnia średnich z próby ma wartość `r round(mean.s10, 2)` lat.
Odchylenie standardowe wyniosło `r  round(sd10, 2)`.
Wartość $s/\sqrt{10}$ jest równa `r round(max.err.sd/sqrt(10), 2) `.

**Szacujemy średnią na podstawie 40 kandydatów pobranych losowo**

Uwaga: 40 kandydatów to ok 0.6% całości.
Powtarzamy eksperyment `r sample.size` razy.

```{r}
##40/wN * 100

k40 <- mks(40, wN)

summary(k40)
sd40 <- sd(k40)
## 46 / 2.37
##diffMx(k40, true.mean.w)
mean.s40 <- mean(k40)
```

Średnia średnich z próby ma wartość `r round(mean.s40, 2)` lat.
Odchylenie standardowe wyniosło `r sd40`.
Wartość $s/\sqrt{40}$ jest równa `r max.err.sd/sqrt(40) `.

**Szacujemy średnią na podstawie 70 kandydatów pobranych losowo**

Uwaga: 70 kandydatów to około ok 1% całości (`r sample.size` powtórzeń)

```{r}
##70/wN * 100

k70 <- mks(70, wN)
summary(k70)
sd70 <- sd(k70)
##diffMx(k70, true.mean.w)
mean.s70 <- mean(k70)
```

Średnia średnich z próby ma wartość `r round(mean.s70, 2)` lat.
Odchylenie standardowe wyniosło `r  sd70`
Wartość $s/\sqrt{70}$ jest równa `r max.err.sd/sqrt(70) `.

**Wykres**

Podsumujmy eksperyment wykresem rozkładu wartości średnich.

```{r}
all.samples <- data.frame(k02, k10, k40, k70)

error10 <- true.mean.w  * 0.1

p1 <- all.samples %>%
  pivot_longer(cols = c(k02, k10, k40, k70), names_to = 'k', values_to = 'v') %>%
ggplot(aes(x=v)) +
  facet_wrap(~ k) +
  geom_vline(xintercept = true.mean.w, colour="forestgreen", size=.4) +
  geom_vline(xintercept = true.mean.w - max.err.sd, colour="red", size=.4) +
  geom_vline(xintercept = true.mean.w + max.err.sd, colour="red", size=.4) +
  geom_vline(xintercept = true.mean.w - error10, colour="red", size=.4) +
  geom_vline(xintercept = true.mean.w + error10, colour="red", size=.4) +
  geom_histogram(binwidth=1, alpha=.5, fill="steelblue") +
  ggtitle("rozkład średniej wieku kandydatów w zależności od wielkości próby")
p1
```

Obserwujemy to samo co w przypadku wagi rugbystów: im większa próba tym
dokładniejsza wartość średniej wieku. Bez względu na wielkość próby przeciętnie
otrzymujemy prawdziwą wartość średniej.

Wniosek: precyzja wnioskowania zwiększa się wraz z liczebnością próby; tym szybciej
im rozproszenie w populacji generalnej jest mniejsze. Żeby z dużą dokładnością
wnioskować o średniej dla dużej populacji wcale nie trzeba pobierać 
dużej próby (w ostatnim przykładzie było to 1% całości).

## Rozkład normalny

**Rozkład empiryczny** zmiennej to
przyporządkowanie kolejnym wartościom zmiennej odpowiadających im liczebności. 


Załóżmy że istnieje zapotrzebowanie społeczne na  wiedzę na temat wieku kandydatów
na radnych. Możemy to jak widać łatwo liczyć ale jednocześnie jest to kłopotliwe. 
Należy do tego mieć zbiór ponad 7 tys liczb. 
**Rozkład teoretyczny** to matematyczne uogólnienie **rozkładu empirycznego**.
Jest to model matematyczny operujący pojęciem (ściśle sformalizowanym) **prawdopodobieństwa**
(zamiast liczebności). **Rozkład teoretyczny** jest: 

* zbliżony do empirycznego jeżeli chodzi o wyniki (jest przybliżeniem empirycznego)

* jest zdefiniowany za pomocą kilku liczb; nie ma potrzeby korzystania z liczebności

Żeby było ciekawiej istnieje dokładnie jeden **rozkład  teoretyczny**, który z dobrą dokładnością
opisuje rozkłady empiryczne będące wynikiem powyższej zabawy. 
Ten rozkład (zwany **normalnym**)
zależy tylko od dwóch parametrów: średniej i odchylenia standardowego, gdzie średnia będzie
równa (prawdziwej) średniej w populacji a odchylenie standardowe 
równe odchyleniu standardowemu w populacji podzielonemu przez pierwiastek z wielkości próby.

Dla próby 40-elementowej (wiek kandydatów) wygląda to tak:

```{r}
this.sample.size <- 40
k1000m <- true.mean.w
k1000sd <- max.err.sd / sqrt(this.sample.size)
this.binwd <- .25
p1b <- data.frame(k40) %>%
  ggplot(aes(x=k40)) +
  geom_histogram(binwidth= this.binwd, alpha=.5, fill="steelblue") +
  stat_function(fun = function(x) 
  {dnorm(x, mean = k1000m, sd = k1000sd) * sample.size * this.binwd},
  color="red")
p1b
```

dla próby 70-elementowej tak:

```{r}
this.sample.size <- 70
k1000m <- true.mean.w
k1000sd <- max.err.sd / sqrt(this.sample.size)
this.binwd <- .25
p1b <- data.frame(k70) %>%
  ggplot(aes(x=k70)) +
  geom_histogram(binwidth= this.binwd, alpha=.5, fill="steelblue") +
  stat_function(fun = function(x) 
  {dnorm(x, mean = k1000m, sd = k1000sd) * sample.size * this.binwd},
  color="red")
p1b
```

Prawda, że wynik jest całkiem dobry? Teoretyczność czerwonej krzywej
polega na tym, że ona zawsze będzie identyczna, podczas gdy histogram będzie różny.
Gdybyśmy powtórzyli nasz 
eksperyment (generowania `r sample.size` losowych prób przypominam),
to zapewne trochę by się różnił,  bo byśmy wylosowali inne wartości do prób. 
Ta **teoretyczna abstrakcja** nazywa się 
**prawdopodobieństwem**. Rzucając monetą `r sample.size` razy spodziewamy
się po `r sample.size/2` orłów i reszek, 
co w modelu matematycznym będzie opisane jak:
prawdopodobieństwo wyrzucenia orła wynosi 0,5. 
Rzucanie monetą to bardzo prosty eksperyment; nasz z liczeniem średniej
wieku jest bardziej skomplikowany więc miło jest się
dowiedzieć,  że używając czerwonej krzywej można łatwo obliczyć jak bardzo
prawdopodobne jest na przykład popełnienie błędu większego niż 10% średniej, albo
większego niż 0,1 lat. Albo jak duża powinna być próba żeby ten
błąd był nie większy niż 0,1 lat.

Interpretacja wartości rozkładu empirycznego zwykle jest w kategoriach ryzyka/szansy czy
prawdopodobieństwa. Przykładowo interesuje nas prawdopodobieństwo, że kandydat ma
mniej niż 30 lat. 
Takich kandydatów jest `r nrow( r %>% filter (wiek < 30))`
a wszystkich kandydatów dla przypomnienia
jest `r nrow(r)`. Iloraz tych wartości będzie interpretowany 
jako ryzyko/szansa/prawdopodobieństwo
(wynosi ono `r round(nrow( r %>% filter (wiek < 30)) / nrow(r) * 100, 2)`%.)

Podobnie można obliczyć prawdopodobieństwo, że wiek kandydata będzie się
zawierał w przedziale 50--60 lat.
Ponieważ kandydatów w wieku 50--60 lat jest `r nrow( r %>% filter (wiek >= 50 & wiek <= 60))`,
to szukane prawdopodobieństwo 
jest równe: `r round(nrow( r %>% filter (wiek >= 50 & wiek <= 60)) / nrow(r) * 100, 2)`%.)

Jeżeli zamiast rozkładu empirycznego będziemy używać rozkład normalnego, który jak widzimy
jest jego dobrym przybliżeniem, to nie musimy liczyć empirycznych liczebności. Wystarczy że
znamy średnią i odchylenie standardowe a potrafimy obliczyć każde prawdopodobieństwo dla
każdego przedziału wartości zmiennej.

W szczególności dla rozkładu normalnego prawdopodobieństwo $m \pm s$ (przyjęcie wartości z przedziału
średnia plus/minus odchylenie standardowe) wynosi około 0,68
prawdopodobieństwo $m \pm 2 \times s$ wynosi około 0,95 a $m \pm 3 \times s$ około 0,997.
Czyli w przedziale $[-3s < m, m +3s]$ znajdują się praktycznie wszystkie wartości
rozkładu. Albo innymi słowy przyjęcie wartości spoza przedziału średnia plus/minus trzykrotność
odchylenia standardowego jest bardzo mało prawdopodobna.

Rozkład normalny będzie identyczny dla wagi rugbystów, wieku czy czasu opóźnień.
Uogólnieniem teoretycznym pojęcia **zmiennej statystycznej**, które do tej pory
używaliśmy jest **zmienna losowa**, zmienna której wartości są liczbami a realizują się
z określonym prawdopodobieństwem np. określonym przez rozkład normalny.

**Przykład: szacowanie odsetka kobiet**

```{r}
r <- read.csv("kandydaci_ws_2018_4.csv", sep = ';', dec = ",",  header=T, na.string="NA") %>%
    mutate (plec = recode(plec, "K"=1, "M"=0))

p.k <- mean(r$plec)

w <- as.vector(na.omit(r$plec))
wN <- length(w)

x020 <-mks(20,wN)
##summary(x020)
x020.mean <- mean(x020)

x120 <-mks(120,wN)
##summary(x120)
x120.mean <- mean(x120)

x420 <-mks(420,wN)
x420.mean <- mean(x420)
##summary(x420)
```

Dane dotyczące kandydatów zawierają także płeć. Ktoś może być ciekaw
jaki był odsetek kobiet w tej grupie. Taki parametr nazywa się proporcją
albo ryzykiem, a potocznie i niefachowo procentem. 
Matematycznym modelem jest **zmienna dwuwartościowa**, która
z określonym prawdopodobieństwem przyjmuje wartość `kobieta`. 
Obliczmy
empiryczną wartość tego prawdopodobieństwa jako liczbę kobiet do liczby
wszystkich kandydatów. Wartość tego parametru wynosi `r p.k` (albo 
`r round(p.k *100, 2)`%). 
Potraktujmy to jako prawdziwą wartość prawdopodobieństwa (p), że
kandydat jest kobietą i empirycznie sprawdźmy czy możemy szacować
o prawdziwej wartości tego parametru 
używając (jako estymatora żeby się przyzwyczajać do nowych terminów) proporcji z próby.
Tradycyjnie powtarzamy eksperyment 1000 razy 
dla trzech różnych wielkości próby. Rozkład otrzymanych wartości przedstawia rysunek.



```{r}
all.samples <- data.frame(x020, x120, x420)

p1 <- all.samples %>%
  pivot_longer(cols = c(x020, x120, x420), names_to = 'k', values_to = 'v') %>%
  ggplot(aes(x=v)) +
  facet_wrap(~ k) +
  geom_histogram(binwidth=.02, fill="steelblue") +
  geom_vline(xintercept = p.k, colour="forestgreen", size=.4) +
  ggtitle("rozkład wielkości p dla różnej wielkości próby")
p1

```

Wnioski: 

* Dla próby 20 elementowej rozkład nie przypomina rozkładu normalnego

* Dla prób 120 i 420 elementowej rozkład jest podobny do normalnego

* Zmienność estymatora maleje wraz ze wzrostem liczebności próby; 
każe nam to przypuszczać (i tak jest w istocie) że jest on zgodny

* W każdym przypadku średnia z 1000 eksperymentów jest zbliżona do wartości prawdziwej
 każe nam to przypuszczać (i tak jest w istocie) że estymator jest nieobciążony
 
Rozkład normalny jest tak magiczny że nawet jeżeli zmienna której parametr
szacujemy nie ma rozkładu zbliżonego
do normalnego (jak w przypadku zmiennej która przyjmuje tylko dwie wartości)
to i tak estymator tego parametru będzie normalny. Co najwyżej będziemy
potrzebowali większej próby żeby znormalniał (jak w opisywanym przykładzie)
 

## Wnioskowanie statystyczne (*interferance*)

Analizując dane uzyskane z próby celem jest ich **uogólnienie** na całą populację.
Przypominamy, że wnioskujemy
o wartości parametru w populacji posługując się **estymatorem**. W przypadku
wnioskowania o średniej estymatorem jest średnia-z-próby.
Dobrze by było wiedzieć jak bardzo wiarygodna jest ta wartość (zwana oceną parametru) uzyskana
na podstawie konkretnego estymatora, inaczej mówiąc jak dużo mogliśmy się pomylić.

Do oceny tej wiarygodności można użyć wariancji-średniej-z-próby (która nazywa się
**wariancją błędu** albo **error variance**)
Jeżeli wariancja błędu jest duża, to w pojedynczej próbie mogą wystąpić wartości
znacznie różniące się od prawdziwej średniej; jeżeli jest mała to takie bardzo różniące
się od prawdziwej średniej wartości mają małe szanse na zaistnienie. Do tego w przypadku rozkładu
normalnego wiemy ze wariancja błędu jest równa $s^2/n$
(gdzie $s^2$ jest wariancją w populacji a $n$ wielkością próby.)

W ramach wnioskowania stosowane są trzy metody (podejścia): 

* Estymacja punktowa,  

* Estymacja przedziałowa,

* Testowanie hipotez.

### Estymacja punktowa

Szacujemy średnią (inny parametr) i tę wartość uznajemy za wartość prawdziwą;
dokładność szacunku jest nieokreślona. Inaczej mówiąc wartość **estymatora**
dla konkretnej próby przyjmujemy za ocenę parametru.

Estymatorem punktowym średniej jest średnia z próby a estymatorem
punktowym proporcji/ryzyka jest proporcja/ryzyko z próby.

### Estymacja przedziałowa

Nie można ustalić prawdopodobieństwa popełnienia 
błędu dla dokładnej wartości parametru (co wynika z właściwości matematycznych
modelu), ale można dla dowolnego przedziału od--do. 

Czyli nie można ustalić, że z prawdopodobieństwem 95%
oszacujemy wartość średnią czegoś jako 5,000000,
ale można z prawdopodobieństwem 95% oszacować
**przedział** w którym znajdzie się średnia (np że będzie to na przykład 4,9--5,1).

Estymacja przedziałowa to oszacowanie przedziału wartości od--do,
który z zadanym z góry prawdopodobieństwem zawiera prawdziwą wartość średniej.

Z góry wyznaczone prawdopodobieństwo nazywa się
**poziomem ufności** (określa jak często mamy się NIE rąbnąć)

### Testowanie hipotez

Większość analiz statystycznych polega na porównaniu. W wyniku
tego porównania otrzymujemy liczbę. Załóżmy, że mamy dwie próby dotyczące wieku
kandydatów na radnych do sejmików wojewódzkich z roku 2018 (średnia 46,1) 
oraz z roku 2014 (47,2). Różnica wynosi 1,1 lat i może być spowodowana błędem przypadkowym
(tj. gdybyśmy wylosowali jeszcze raz dwie próby, to wynik byłby zupełnie odmienny np 46,9 vs 46,5)
i/lub wynikać z tego że faktycznie w roku 2014 kandydaci byli starsi. 

Formalnie stawiamy **hipotezę**, że różnica średnich wynosi zero. Jest to tzw. **hipoteza zerowa**. Niezbędne jest także postawienie **hipotezy alternatywnej**,
którą może być proste zaprzeczenie zerowej. Zapisuje się to następująco:

$H_0$: różnica średnich wieku wynosi zero ($m_1 = m_2$)

$H_1$: różnica średnich wieku jest różna od zera ($m_1 \not= m_2$)

Hipotezy sprawdzamy wykorzystując **test statystyczny** czyli funkcję 
której wartości zależą wartości testowanych parametrów (w tym przypadku $m_1$ oraz $m_2$)

Nie jest chyba wielkim zaskoczeniem, że testem dla różnicy średnich jest
różnica średnich w próbie. Całkiem **zdroworozsądkowo** możemy przyjąć, że duże różnice
świadczą na rzecz hipotezy alternatywnej a małe na rzecz hipotezy zerowej. 

Duża różnica pomiędzy **hipotezą** a wynikiem z próby może wynikać z tego, że

1. pechowo trafiła nam się nietypowa próba, który zdarza się rzadko (rozkład normalny)

2. hipoteza jest fałszywa, średnie mają inną wartość niż zakładamy w hipotezie zerowej

Statystyk zawsze wybierze drugą wersję. Pozostaje tylko ustalić (dla statystyka) co to jest rzadko?

Rzadko to z prawdopodobieństwem mniejszym niż z góry ustalone prawdopodobieństwo 
otrzymania różnicy (zakładające że hipoteza zerowa jest prawdziwa),
którą otrzymaliśmy w próbie lub większej 
(coś jak założenie że zrealizował się najlepszy z najgorszych scenariuszy).

Przyjmijmy przykładowo że prawdopodobieństwo wystąpienia różnicy 1,1 lat (i większej) oszacowane
na podstawie odpowiedniego modelu matematycznego (rozkład normalny) wynosi 0,3 
co znaczy że coś takiego
zdarza się względnie często -- trzy razy na 10 pobranych prób.

Załóżmy z kolei że, ta różnica wyniosła 3,2 lata. Prawdopodobieństwo 
wystąpienia takiej różnicy (i większej) wynosi 0,009 co znaczy że coś takiego
zdarza się względnie rzadko -- 9 razy na tysiąc prób.

Przyjmując, że możemy się mylić 5 razy na 100 w pierwszym przypadku statystyk powie,
że nie ma podstaw do odrzucenia hipotezy $H_0$. 
Różnica 1,1 lat wynika z przypadku. W drugim wypadku
powie że hipoteza jest fałszywa, bo zdarzyło się coś co nie powinno się zdarzyć.

Prawdopodobieństwo ,,graniczne'' ustalamy z góry i
nazywa się ono **poziomem istotności**.  Określa ono jak często
możemy się rąbnąć **odrzucając hipotezę zerową która jest prawdziwa**.

Ale jest jeszcze drugi przypadek popełnienia błędu: 
**przyjmujemy hipotezę która jest fałszywa**. W testach
statystycznych nie określa się tego prawdopodobieństwa a w związku z tym nie można
**przyjąć hipotezy zerowej** (bo nie znamy ryzyka popełnienia błędu).

W konsekwencji hipotezę zerową albo się odrzuca albo nie ma podstaw do odrzucenia.
Wniosek cokolwiek niekonkluzywny, ale tak jest. 

Dlatego też często ,,opłaca się'' odrzucić hipotezę zerową, bo taki rezultat jest
,,bardziej konkretny''.

### Testy nieparametryczne

Można testować hipotezy nt. wartości parametrów ale można też testować
przypuszczenia o charakterze mniej konkretnym. Na przykład, że dwie zmienne
są niezależne (co to znaczy wyjaśniono w następnym rozdziale), albo
że dwa rozkłady są podobne do siebie (rozkłady nie średnie).
Takie hipotezy/testy określa się jako **nieparametryczne**.
Przykładami są testy niezależności chi-kwadrat albo normalności
Shapiro-Wilka (opisane w następnym rozdziale)

Oczywiste ale podkreślmy: przypuszczenia o charakterze nieparametrycznym 
możemy tylko testować (sprawdzać hipotezy);
nie obliczamy wtedy ani ocen ani nie wyznaczamy przedziałów ufności 
z oczywistych względów.

## Słownik terminów które warto znać

Estymator (nieobciążony, zgodny, efektywny): funkcja na wartościach próby która służy
do oszacowania parametru. Estymator średniej wartości

Ocena (parametru); konkretna wartość estymatora dla pewnej próby.

Rozkład (prawdopodobieństwa)

Estymacja (punktowa, przedziałowa)

Wnioskowanie statystyczne

Hipoteza statystyczna

Test statystyczny

Poziom istotności (testu); oznaczany jako $\alpha$; zwykle 0,05

Poziom ufności; prawdopodobieństwo, że przedział ufności zawiera prawdziwą wartość parametru;
oznaczany jako $1- \alpha$; zwykle 0,95




# Analiza współzależności pomiędzy zmiennymi

Pomiędzy zjawiskami występują związki (zależności.) Nauki formułują te związki
w postaci **praw**. Jak takie **prawo naukowe** powstaje? Typowo w dwu etapach,
najpierw za pomocą **dedukcji** stawia się **hipotezę**, potem konfrontuje się 
hipotezę z danymi (podejście hipotetyczno-dedukcyjne). 
Na tym drugim etapie używa się statystyki (lub matematyki jeżeli prawo ma charakter deterministyczny)

Upraszczając *metoda hypodedukcji* sprowadza się do dedukcyjnego sformułowania hipotezy, która następnie jest empirycznie *falsyfikowana*, tj. próbuje się wykazać, że jest ona nieprawdziwa. Konsekwencje:
nie można dowieść prawdziwości żadnej hipotezy, można natomiast wykazać, że 
hipoteza jest fałszywa.

Związki między cechami mogą być: **funkcyjne** (nauki przyrodnicze) -- wartościom jednej zmiennej odpowiada tylko jedna wartość drugiej zmiennej lub
**stochastyczne** -- wartościom jednej zmiennej odpowiadają z pewnym
przybliżeniem wartości innej zmiennej.

Problem: czy istnieje związek (zależność) pomiędzy cechami? 
Przykładowo czy istnieje związek pomiędzy paleniem (przyczyna)
a chorobą nowotworową (skutek), wiekiem a prawdopodobieństwem zgonu z powodu COVID19 itd

Jaki jest charakter zależności? Jaka jest siła zależności?

Rodzaj metod zastosowanej do empirycznej weryfikacji zależy 
w szczególności od sposobu pomiaru danych (nominalne, porządkowe, liczbowe.)
co pokazano na diagramie.

![](./DiagramMetod.png)

Optymistyczną informacją jest że metod (oznaczonych krojem pogrubionym na diagramie), 
które omawiamy dalej w rodziale, jest raptem siedem czyli niedużo.



## Dwie zmienne nominalne

### Ryzyko względne oraz iloraz szans

Ryzyko to udział (iloraz) liczby sukcesów do liczby prób (zdarzeń pozytywnych/wyróżnionych do wszystkich). Zwykle podawany w procentach. Warto zauważyć że jest to 
empiryczny odpowiednik prawdopodobieństwa.


**Przykład: Podawanie witaminy C a przeziębienie/brak przeziębienia**

Eksperyment przeprowadził Linus Pauling (laureat nagrody Nobla 
za odkrycie witaminy C).

Eksperyment Paulinga polegał na tym, że podzielił 280 narciarzy na dwie grupy
po 140 osób; przez 5--7 dni podawał witaminę C jednej grupie
oraz placebo drugiej grupie;
obserwował zachorowania na przeziębienie przez następne dwa tygodnie.
Jeden narciarz nie dokończył eksperymentu. Historia milczy dlaczego :-)

![](./Pauling.jpg){width=50%}


W grupie 139 narciarzy, którym podano witaminę C
(grupa C) zachorowało 17. W grupie 140 narciarzy, którym podano placebo (grupa P)
zachorowało 31. Zatem:

* Ryzyko zachorowania w grupie C wyniosło 17/139 = 12,2%.
* Ryzyko zachorowania w grupie P wyniosło 31/140 = 22,14%

Na tzw. chłopski rozum jeżeli witamina C **nie działa** to powinien
zachorować ten sam odsetek narciarzy w obu grupach. 
A tak nie jest jak widać...

Prostymi miarami oceny siły zależności mogą być: 

* różnica  ryzyk (**risk difference**)
* ryzyko względne (**relative risk**), oraz 
* iloraz szans (**odds ratio**).

Jeżeli $r_e$ oznacza ryzyko w grupie eksperymentalnej 
(test group; grupa narażona/exposed group),
a $r_k$ w grupie kontrolnej (control group; grupa nienarażona/unexposed), 
to **różnica ryzyk** to po prostu $r_e - r_k$.
W przykładzie będzie to $22,14 - 12,2 = -9,94$%
Ta miara aczkolwiek prosta jest rzadko stosowana. 

Znacznie częściej używa się **ryzyka względnego** definiowanego jako
$RR = r_e/r_k$. W przykładzie będzie to $12,2/22,14 = 0,55$. 
Podanie witaminy C zmniejsza ryzyko o prawie połowę. 
Oczywiste jest że $RR < 1$ oznacza zmniejszenie
ryzyka; $RR > 1$ zwiększenia a $RR = 1$ oznacza brak zależności.

Zamiast ryzyka (czyli ilorazu liczby sukcesów do liczby prób) można używać
pojęcia szansa/szansy (**odds**) definiowanego
jako iloraz sukcesów do porażek. 

Przykładowo jeżeli w dwukrotnym rzucie monetą otrzymano orła i reszkę to ryzyko
otrzymania orła wynosi 1/2 = 0,5 a szansa otrzymania orła wynosi 1/1 = 1.

**Przykład: Narciarze Paulinga cd** 

Ryzyko zachorowania w grupie C wynosi 12,2 (jak wiemy); natomiast szansa, że narciarz grupie C
zachoruje wynosi 17/122 = 13,9%. (A w grupie P wynosi 28,44%)

Jak widać dla dużych ryzyk (rzut monetą) szansa 
różni się znacznie od prawdopodobieństwa, ale dla małych ryzyk obie miary mają zbliżoną wartość.

Jeżeli $o_e$ oznacza szanse w grupie eksperymentalnej 
a $o_k$ w grupie kontrolnej, to **iloraz szans** (*odds ratio*), jest
definiowany jako stosunek $\textrm{OR} = o_e/o_k$.

Zatem iloraz szans
dla narciarzy wyniesie 13,9/28,44 = 0,48.
Podanie witaminy C zmniejsza szansę na zachorowanie o ponad połowę. 
Albo 1/0,48 = 2,04, narciarz który nie brał witaminy C ma ponad 
dwukrotnie większą szansę na zachorowanie.

Właściwości ilorazu szans: 

* jeżeli równe 1 to sukces/porażka równie prawdopodobne;
* jeżeli większe od 1 to sukces bardziej prawdopodobny;
* jeżeli jest mniejsze od 1 to porażka jest bardziej prawdopodobna.

Dane w badaniach wykorzystujących ryzyko/szanse mają często postać tabeli
dwudzielnej o wymiarach $2\times 2$, którą można przestawić następująco
(a, b, c i d to liczebności):


|                       | sukces |  porażka |
|-----------------------|--------|----------|
| grupa kontrolna       | a      |  b       |
| grupa eksperymentalna | c      |  d       |


Dla danych w tej postaci: 

* $\textrm{RR} = c(a+b)/a(c+d)$ oraz
* $\textrm{OR} = (ad)/ (bc)$ 

czyli dla eksperymentu Paulinga:

|                       | katar  |  zdrowy  |
|-----------------------|--------|----------|
| grupa C               | 17     |  122     |
| grupa P               | 31     |  109     |



### Przedziały ufności dla ryzyka względnego oraz ilorazu szans

Ryzyko, ryzyko względne czy iloraz szans to parametry podobne do procentu kobiet
wśród kandydatów na radnych z przykładu w poprzednim rozdziale. Wiemy,
że estymatorem punktowym proporcji jest proporcja z próby. Nie będzie
wielkim odkryciem, że estymatorem punktowym ryzyka jest ryzyko z próby,
ryzyka względnego/ilorazu szans zaś ryzyko względne/iloraz szans z próby.

Standardem jest obliczanie dla ryzyka względnego oraz ilorazu szans
oprócz ocen punktowych także
przedziałów ufności czyli podawania dwóch wartości, pomiędzy którymi
z zadanym prawdopodobieństem znajduje się nieznana wartość szacowanego
parametru.

Przykładowo (kontynuując eksperyment Paulinga)

```{r}
b_t <- 122
a_t <- 17
d_t <- 109
c_t <- 31

## RR
rr.e <- (a_t/(a_t + b_t)) 

rr.t <- (c_t /(c_t + d_t))

rr <- rr.e/rr.t

seRR <- sqrt(1 /a_t + 1/c_t - 1/(a_t+b_t) - 1/(c_t+d_t))

rr_low <- exp(log(rr) - 1.96 * seRR)
rr_upr <- exp(log(rr) + 1.96 * seRR)

## OR
or <- (a_t * d_t )/ (b_t * c_t )

seOR <- sqrt(1/a_t + 1/b_t + 1/c_t + 1/d_t)
or_low <- exp(log(or) - 1.96 * seOR)
or_upr <- exp(log(or) + 1.96 * seOR)
```

Końce przedziałów ufności dla ilorazu szans (ocena punktowa `r or`) wynoszą: 
[`r or_low`; `r or_upr`] zaś dla
ryzyka względnego (ocena punktowa `r rr`) przedział ufności wynosi [`r rr_low`; `r rr_upr`].

**Uwaga**: nie jest specjalnie istotne jaka jest konkretna formuła obliczania
przedziałów ufności, przecież obliczenia i tak koniec-końców wykona
program komputerowy.

Przedział ufności dla ilorazu szans nie zawiera 1; 
zatem branie witaminy C zmniejsza szanse na zachorowanie;
albo zwiększa na niezachorowanie od $1/25 = 4$ do $1/0,9 = 1,1$. Żeby
to zabrzmiało ładnie i po polsku. 
Zwiększa na niezachorowanie od 300% do 10%.

Dlaczego taka znacząca rozpiętość? Bo próba jest względnie mała. Gdyby
Pauling zwerbował nie 280 a 2800 narciarzy mógłby weryfikować działanie
swojej witaminy z większą pewnością.

### Tabele wielodzielcze

Łączny rozkład dwóch lub większej liczby zmiennych można przedstawić
w tabeli. Taka tabela nazywa się dwudzielcza (dla dwóch zmiennych)
lub wielodzielcza albo wielodzielna (dla więcej niż dwóch liczby zmiennych.) 
Inne nazwy tych tabel to krzyżowe albo kontyngencji
(cross-tabulation, contingency **two-way tables**.)

Ograniczmy się do analizy tabel dwudzielnych.

**Przykład: Narciarze Paulinga jeszcze raz**

Eksperyment Paulinga można przedstawić w postaci tablicy dwudzielczej
(P/C oznacza czy narciarz zażywał witaminę czy placebo; cold/nocold
czy zachorował czy nie zachorował na katar):

```{r, message=FALSE, echo=FALSE}
vitC <- read.csv(file='vit_C.csv',sep=';',header=T)
narciarze <- table(vitC)
narciarze.table <- addmargins(narciarze)
kable(narciarze.table, col.names = c('nocold', 'cold', 'razem'))
```

Taka tabela składa się z wierszy i kolumn. Dolny wiersz (Sum czyli Razem
po polsku) zawiera łączną liczebność dla wszystkich wierszy w danej kolumnie. Podobnie prawa skrajna kolumna zawiera łączną
liczebność dla wszystkich kolumn dla danego wiersza. Dolny wiersz/Prawą
kolumnę nazywamy **rozkładami brzegowymi**.
Pozostałe kolumny/wiersze (ale bez wartości łącznych) nazywane
są **rozkładami warunkowymi**. Rozkładów warunkowych jest tyle ile
wynosi iloczyn $r \times c$ gdzie $r$ to liczba wariantów jednej cechy
a $c$ to liczba wariantów drugiej cechy.

Przy warunku że narciarz brał witaminę C, `r narciarze[1,1]` takich osób
nie zachorowało (**nocold**) a `r narciarze[1,2]` zachorowało (**cold**). 
Drugi rozkład warunkowy: `r narciarze[2,1]` narciarzy, którzy brali placebo
nie zachorowało, a `r narciarze[2,2]` zachorowało. Są także rozkłady
warunkowe dla drugiej cechy. W grupie narciarzy, którzy zachorowali
`r narciarze[1,1]` brało witaminę C, a `r narciarze[2,1]` brało placebo.
Wreszcie w grupie narciarzy, którzy nie zachorowali
`r narciarze[2,1]` brało witaminę C, a `r narciarze[2,2]` brało placebo.
Rozkładów warunkowych jest 4 bo obie cechy mają po dwa warianty. Jest
to najmniejsza możliwa tabela wielodzielcza.

Zamiast liczebności można posługiwać się odsetkami (procentami):


```{r}
narciarze.total <- sum(narciarze)
narciarze.p <- narciarze/narciarze.total *100

narciarze.table.p <- addmargins(narciarze.p)
kable(narciarze.table.p)
```

Narciarzy którzy brali witaminę C nie nie zachorowali stanowi `r  narciarze.table.p[1,1]`%
wszystkich narciarzy. Mało przydatne...

Ciekawsze jest obliczenie procentów każdego wiersza osobno, tj. dzielimy
liczebności w każdej kolumnie przez liczebności rozkładu brzegowego (wartości
ostatniej kolumny):

```{r}

narciarze.p <- proportions(narciarze, margin = 1)
narciarze.p.m <- addmargins(narciarze.p, margin = 1)
n.m <- margin.table(narciarze,2) /narciarze.total
narciarze.x <- cbind(rbind(narciarze.p, n.m), c(1,1,1)) * 100
kable(narciarze.x)
```

Otrzymaliśmy ryzyka zachorowania na katar (lub nie zachorowania). Ryzyko
zachorowania dla całej grupy wynosi `r narciarze.x[3,2]`% a nie zachorowania
`r narciarze.x[3,1]`%. Jest przyznajmy całkiem **zdroworozsądkowym założeniem**
(uczenie hipotezą statystyczną), że jeżeli przyjmowanie witaminy nie ma związku
z zachorowaniem lub nie na katar, to w grupie tych co brali i tych co nie brali
powinniśmy mieć identyczne rozkłady warunkowe równe rozkładowi brzegowemu.
Czyli powinno przykładowo zachorować `r  narciarze.x[3,2]`% narciarzy, którzy
brali witaminę C a widzimy , że zachorowało jedynie `r narciarze.x[1,2]`%.

Na oko księgowego witamina C działa (bo są różnice), ale dla statystyka liczy się 
czy ta różnica jest na tyle duża, że (z założonym prawdopodobieństwem) 
można wykluczyć działanie przypadku.

Rozumowanie jest następujące: jeżeli prawdopodobieństwo wystąpienia 
tak dużej różnicy jest małe, to cechy nie są niezależne. 
Jest to istota i jedyny wniosek z czegoś co się nazywa 
testem istotności-chi-kwadrat. 
Test chi-kwadrat porównuje liczebności tablicy wielodzielnej z idealną-tablicą-wielodzielną, która zakłada niezależność jednej zmiennej od drugiej.

Można udowodnić, że taka tablica powstanie przez przemnożenie dla 
każdego elementu tablicy odpowiadających mu wartości brzegowych 
a następnie podzieleniu tego przez łączną liczebność (czyli przykładowo pierwszy
element poniższej tablicy to `r narciarze.table[3,1]` pomnożone przez
`r narciarze.table[1,3]` i podzielone przez `r narciarze.table[3,3]`; proszę
sprawdzić,
że jest to `r narciarze.table[3,1] * narciarze.table[1,3] / narciarze.table[3,3]`):


```{r, message=FALSE, echo=FALSE}
chi_skiers <- chisq.test(narciarze)
narciarze.expected <- chi_skiers$expected
narciarze.ex.table <- addmargins(narciarze.expected)

chipv <- chi_skiers$p.value
chipv.txt <- sprintf("%f", chipv)
kable(narciarze.ex.table)
```

Proszę
zwrócić uwagę że **rozkłady brzegowe** są identyczne, identyczna
jest też łączna liczebność. Różnią się tylko rozkłady warunkowe (które nie są
liczbami całkowitami ale tak ma być--nie jest to błąd)

Za pomocą testu Chi-kwadrat obliczamy jakie jest prawdopodobieństwo, wystąpienia
tak dużych lub większych różnic. Wynosi ono `r chipv.txt`.
Czyli wystąpienie tak dużych różnic
pomiędzy **oczekiwanymi** (przy założeniu o niezależności zmiennych)
liczebnościami
a obserwowanymi liczebnościami zdarza się około 4 razy na 100.

Jeszcze raz przypominamy ideę testu: jeżeli prawdopodobieństwo zaobserwowanych
różnic jest małe to zakładamy że 

* albo mamy pecha i pięć razy podrzucając monetą zawsze nam spadła
reszka (prawdopodobieństwo około 0,03), albo

* że założenie co do niezależności jest fałszywe. 

Statystyk zawsze wybierze
drugie. Pozostaje tylko ustalenie co to znaczy **małe**.

Małe to takie które jest mniejsze od arbitralnie przyjętego
przez statystyka. Zwykle jest to 0,05 lub 0,01 (czasami 0,1)
co oznacza że odrzucając założenie o braku związku pomiędzy
katarem a braniem witaminy C pomylimy się pięć lub raz na 100.

**Uwaga**: proszę zwrócić uwagę że wniosek z testu niezależności jest
słabszy niż z porówania ryzyk. Tam mamy informację że zależność istnieje 
i oszacowaną jej wielkość (np. za pomocą ryzyka względnego) tutaj tylko
zweryfikowaliśmy fakt czy obie zmienne są niezależne czy też nie.

**Przykład: palenie a status społeczno-ekonomiczny**

Dla pewnej grupy osób odnotowujemy ich status-społeczno-ekonomiczny
(wysoki/**high**, średni/**middle**, niski/**low**)
oraz status-względem-palenia 
(wartości: pali/**current**, palił-nie-pali/**former**, nigdy-nie-palił/**never**). 
Obie zmienne są nominalne, obie mają po trzy wartości. Można
poklasyfikować wszystkich badanych w następujący sposób:

```{r message=FALSE, echo=F}
smokerData <- read.csv(file='smoker.csv',sep=';',header=T)
#summary(smokerData)
#nrow(smokerData)
#
smoke <- table(smokerData)

smoke.table <- addmargins(smoke)
kable(smoke.table)
```

Uwaga: status-społeczno-ekonomiczny to powiedzmy miara prestiżu używana w socjologii
(można na Wikipedii doczytać co to dokładnie jest)

Tym razem tabela składa się z 3 wierszy i 3 kolumn (ostatni wiersz/kolumna się
nie liczą bo to sumy--rozkłady brzegowe)

Przedstawmy tą tabelę w postaci udziałow procentowych sumujących się
dla każdego wiersza osobno do 100% (tj. dzielimy
liczebności w każdej kolumnie przez liczebności rozkładu brzegowego (wartości
ostatniej kolumny):

```{r}
smoke.total <- sum(smoke)
smoke.p <- proportions(smoke, margin = 1)
smoke.p.m <- addmargins(smoke.p, margin = 1)
n.m <- margin.table(smoke,2) /smoke.total
smoke.x <- cbind(rbind(smoke.p, n.m), c(1,1,1)) * 100
kable(smoke.x)
```

Rozumowanie jest identyczne jak dla narciarzy Pauliga. Jeżeli nie ma zależności
pomiędzy paleniem a statusem to procenty w ostatnim wierszu powinny
być identyczne jak w wierszach 1--3 (nagłówka nie liczymy). Tym idealnym 
procentom odpowiadają następujące liczebności:


```{r, message=FALSE, echo=FALSE}
chi_smokers <- chisq.test(smoke)
smokers.expected <- chi_smokers$expected
smokers.ex.table <- addmargins(smokers.expected)

chipv <- chi_smokers$p.value
chipv.txt <- sprintf("%f", chipv)
kable(smokers.ex.table)
```

Wartość prawdopodobieństwa dla testu chi-kwadrat określająca, że przy założeniu niezależności obu zmiennych tak duża różnica między liczebnościami rzeczywistymi a idealnymi 
(porównaj stosowne tabele wyżej) jest dziełem przypadku wynosi `r chipv.txt`.
Jest to prawdopodobieństwo tak małe, że statystyk odrzuca założenie o niezależności
statusu i palenia (myląc się w przybliżeniu `r chipv.txt` ≈ raz na tysiąc)

## Zmienna liczbowa i zmienna nominalna

Obliczamy średnie wartości zmiennej liczbowej **w grupach** określonych przez wartości zmiennej nominalnej,
np wypalenie zawodowe w podziale na miejsce pracy. Grup może być dwie lub więcej

Stawiamy hipotezę że wartości średnie w każdej grupie są równe, wobec hipotezy alternatywnej
że tak nie jest (że są różne jeżeli grup jest dwie; co najmniej jedna jest różna jeżeli grup jest
więcej niż dwie). Stosujemy odpowiedni test statystyczny:

+ jeżeli liczba grup wynosi 2 oraz można przyjąć założenie o przybliżonej
  normalności rozkładów, to stosujemy test $t$-Studenta (dla prób niezależnych), 

+ jeżeli liczba grup wynosi 2, ale nie można założyć normalności
  rozkładów to stosujemy test U-Manna-Whitneya 

+ jeżeli liczba grup jest większa niż dwie oraz można przyjąć założenie
  o normalności rozkładów to stosujemy test pn. ANOVA
  
+ jeżeli liczba grup jest większa od dwóch oraz nie można przyjąć założenia
  o normalności rozkładów, to stosujemy test Kruskall-Wallisa 

Powyższe w postaci diagramu ze strzałkami przedstawiono na rysunku

![](./TestFlowChart.png)


### test $t$-Studenta

Test stosujemy jeżeli porównujemy dwie średnie oraz można przyjąć
założenie że rozkład wartości w obu grupach jest normalny.

**Przykład**: Poziom depresji a miejsce pracy

Studenci pielęgniarstwa i ratownictwa PSW w 2023 roku wypełnili
ankietę zawierającą 
test depresji Becka, mierzący **poziom depresji** (wartość liczbowa) 
oraz pytanie o rodzaj miejsca pracy (skala nominalna). Poniżej
zestawiono średnie wartości **poziomu depresji** w podziale
na rodzaj miejsca pracy (szpital/przychodnia)

```{r, echo=F}
s0 <- read.csv("depresjaPSW.csv", sep = ';', header = T)

s0.mp <- s0 %>%
  group_by(praca) %>%
  summarise(m = mean(P), n=n())
s0.mp.szpital <- s0.mp %>% filter (praca == 'Szpital') %>% 
  select (m) %>% unlist() %>% unname ()
s0.mp.przychodnia <- s0.mp %>% filter (praca == 'Przychodnia') %>% 
  select (m) %>% unlist() %>% unname ()

kable(s0.mp, col.names = c('m-pracy', 'średnia', 'n'))
```

Średnie różnią się 
o `r sprintf ("%.2f", s0.mp.szpital - s0.mp.przychodnia)`. 
Pytanie czy to dużo czy mało?

Przyjmijmy (na razie bez sprawdzania), że rozkłady wartości poziomu depresji
w obu grupach są (w przybliżeniu) 
normalne. Można zatem zastosować test $t$-Studenta

```{r, echo=F}
ttest.mp <- s0 %>%  t_test(P ~ praca) %>%
  select(group1, group2, n1, n2, statistic, p)
pval.mp <- ttest.mp$p
kable(ttest.mp, col.names = c('Grupa1', 'Grupa2', 'n1', 'n2', 't', 'p'))
```

Ponieważ wartość $p$ równa `r pval.mp`` jest większa od każdego zwyczajowo
przyjmowanego poziomu istotności nie ma podstaw 
do odrzucenia hipotezy, że średnie w obu grupach są równe. Skoro tak, to
w konsekwencji stwierdzamy że pomiędzy poziomem depresji 
a miejscem pracy nie ma zależności.


### Testowanie normalności

Statystyk nie przyjmuje założeń na słowo honoru.
Kiedy zatem można przyjąć założenie o normalności a kiedy nie?
Można to ocenić na podstawie wykresu kwantylowego. Oraz
posługując się testem Shapiro-Wilka
(bo Statystycy na każde pytanie mają zawsze **jakiś** stosowny test)

**Przykład**: Poziom depresji a miejsce pracy

Wykres kwantylowy dla **poziomu depresji**
wygląda jak na poniższym rysunku

```{r, echo=F, warning=F, message=F}
p1.mp <- s0 %>% filter (praca == 'Szpital') %>% ggplot(aes(sample=P)) + stat_qq() + stat_qq_line() + 
  xlab ('Teoretyczny') + ylab ('Zaobserwowany') + ggtitle("Szpital")
p2.mp <- s0 %>% filter (praca == 'Przychodnia') %>% ggplot(aes(sample=P)) + stat_qq() + stat_qq_line() + 
  xlab ('Teoretyczny') + ylab ('Zaobserwowany') + ggtitle("Przychodnia")
ggarrange(p1.mp, p2.mp, ncol = 2, nrow = 1)
```

Prosta odpowiada teoretycznym wartościom kwantyli rozkładu poziomu depresji przy założeniu
że mają one rozkład normalny. Punkty odpowiadają zaobserwowanym wartościom kwantyli. 
Im bardziej punkty nie pokrywają się z prostą 
(zwłaszcza na skrajach rozkładu) tym mniej wierzymy, że rozkład jest normalny.

W tym przypadku wygląda, że rozkład w grupie Szpital **nie jest** normalny.
W grupie Przychodnia jest lepiej ale jednocześnie to lepiej jest mało wiarygodne
z uwagi na małą liczebność grupy (zaledwie 12).

Wizualne obserwacja można potwierdzić stosując test Shapiro-Wilka. 
Interpretacja tego testu jest „standardowa“, mianowicie małe wartości $p$
świadczą przeciwko hipotezie zerowej (że rozkład jest Normalny)


```{r, echo=F}
sw.table <- s0 %>%
  group_by(praca) %>%
  shapiro_test(P) %>% select(praca, statistic, p)

kable(sw.table, col.names = c('m-pracy', 'statystyka', 'p'))
## małe wartości świadczą przeciw $H_0$
```

Rozkład w grupie `szpital` nie jest normalny. Nasze założenie co do normalności
było niepoprawne i należy do weryfikacji hipotezy o równości średniej zamiast
testu $t$-Studenta zastosować test U Manna-Whitneya.

### test U Manna-Whitneya

**Przykład: Poziom depresji a miejsce pracy** 

Ponieważ grup jest dokładnie 2 a rozkład nie jest normalny, stosujemy test U Manna-Whitneya.

```{r, echo=F}
wilcoxp.table <- wilcox_test(P ~ praca, data=s0) %>%
  select(group1, group2, n1, n2, statistic, p)
kable(wilcoxp.table, col.names = c('Grupa1', 'Grupa2', 'n1', 'n2', 'U', 'p'))
pval.u <- wilcoxp.table$p
```

Prawdopodobieństwo wystąpienia tak dużej różnicy przy założeniu, że 
średnie w obu grupach 
są identyczne wynosi `r  pval.u` (różnica jest zatem nieistotna; obie średnie są identyczne--nie ma zależności)


### test ANOVA

Jeżeli liczba grup jest większa niż dwie ale można przyjąć założenie
o normalności rozkładów to stosujemy test ANOVA.

**Przykład: Poziom depresji a staż pracy** 

W ankiecie, którą wypełnili
Studenci pielęgniarstwa i ratownictwa PSW w 2023 roku 
było też pytanie o staż pracy. Oryginalną liczbową wartość zmiennej
staż zamieniono na zmienną w skali nominalnej o następujących
czterech wartościach: `<6` (oznacza od 0 do 6 lat stażu pracy), `07-12` (7--12 lat), `13-18` (13--18 lat)
oraz `>19` (19 i więcej lat.)

```{r, echo=F}
s0.staz <- s0 %>%
  group_by(staz) %>%
  summarise(m = mean(P), n=n())
kable(s0.staz, col.names = c('staż (kategoria)', 'średnia', 'n'))
```

Zakładając że rozkłady w grupach są normalne, do weryfikacji hipotezy o równości wszystkich
średnich możemy zastosować test ANOVA.

```{r, message=F, warning=F}
anova.test <- anova_test(P ~ staz, data=s0)
p.anova <- anova.test$p
```

Wartość $p$ równa `r p.anova` świadczy że nie istotnych różnic pomiędzy średnimi, co oznacza
że pomiędzy poziomem depresji a kategoriami stażu pracy nie ma zależności.

Czy zastosowanie testu ANOVA było poprawne? Żeby się o tym przekonać trzeba
zastosować (znowu) test Shapiro-Wilka:

```{r, echo=F}
sw.table.staz <- s0 %>%
  group_by(staz) %>%
  shapiro_test(P) %>% select(staz, statistic, p)
##sw.table.staz
kable(sw.table.staz, col.names = c('m-pracy', 'statystyka', 'p'))
```

Wobec takiego wyniku testu do oceny istotności różnic
należy zastosować bardziej ogólny test Kruskalla-Wallisa

### test Kruskalla-Wallisa

**Przykład: Poziom depresji a staż pracy** 

```{r, echo=F}
kw <- kruskal.test(P ~ staz, data = s0)
pval <- kw['p.value']
```

Prawdopodobieństwo tak dużych różnic w średnich
przy założeniu, że  średnie we wszystkich grupach są identyczne wynosi
`r  pval` (różnice są zatem nieistotne;
wszystkie średnie są identyczne--nie ma zależności)

## Zmienna liczbowa i zmienne liczbowe lub nominalne

### Przypadek szczególny: dwie zmienne liczbowe

Oznaczamy jedną zmienną jako $X$ a drugą jako $Y$. 
W tym przypadku dobrze jest rozpocząć analizę od wykresu.

### Korelacyjny wykres rozrzutu (korelogram, wykres XY w Excelu, scatter plot)

W układzie kartezjańskim każdej obserwacji odpowiada
kropka o współrzędnych XY. 

O występowaniu związku świadczy układanie się kropek według jakiegoś
kształtu (krzywej). O braku związku
świadczy chmura punktów niepodobna do żadnej krzywej.

Punkty układające się według prostej świadczą o zależności liniowej
(wyjątek: linia pozioma lub pionowa)
Punkty układające się według krzywej świadczą
o zależności nieliniowej.

**Przykład:  Zależność pomiędzy zamożnością a spożyciem mięsa**

Organizacja Narodów Zjednoczonych do spraw Wyżywienia i Rolnictwa znana jako FAO
udostępnia dane dotyczące konsumpcji żywności na świecie. Bank światowy
udostępnia dane dotyczące dochodu narodowego. 

Konsumpcja mięsa jest mierzona jako średnia konsumpcja w kilogramach w każdym kraju (*per capita* się mówi);
Dochód podobnie jako średnia wielkość dochodu narodowego *per capita*. 
Dane dotyczą roku 2013.


```{r message=FALSE, echo=FALSE}
## Dane FAO/WorldBank
meatCons <- read.csv(file='meatCons_vs_GDP.csv',sep=';',header=T)
ggplot(meatCons, aes(x = gdp2013, y = y2013)) +
  geom_point(color="steelblue", size=1) +
  geom_smooth(method = "lm") +
  geom_smooth(method = "loess", color="red")
```

###  Pomiar siły zależności: współczynnik korelacji liniowej Pearsona

Kowariancja to średnia arytemtyczna iloczynów odchyleń wartości zmiennych $X$, $Y$
od ich wartości średnich. Dla $n$ obserwacji na zmiennych $X$ oraz $Y$
można powyższe zapisać w postaci następującej formuły:

$$\mathrm{cov} (xy) = \frac{1}{n} \left( (x_1 - \bar x) (y_1 - \bar y)  + ... +
(x_n- \bar x) (y_n - \bar y) \right)$$

Kowariancja zależy od rozproszenia (im większe tym większa), 
ma też dziwną jednostkę (jednostkaX · jednostkaY) oraz zależy 
od wybranych skal (tony vs gramy na przykład.)

Z powyższych powodów do pomiaru związku pomiędzy cechami używa się
standaryzowanego współczynnika kowariancji, 
zwanego **współczynnikiem korelacji liniowej**, (*Pearson linear
correlation coefficient*). Standaryzacja polega na podzieleniu wartości
kowariacji przez iloczyn odchyleń standardowych $s_x$ oraz $s_y$.

$$r_{xy} = \frac{\mathrm{cov}(xy) }{s_x \cdot s_y}$$

Współczynnik jest miarą niemianowaną, przyjmującą wartości ze zbioru $[-1;1]$; 
Skrajne wartości $\pm 1$
świadczą o związku funkcyjnym (wszystkie punkty układają się na linii prostej);
wartość zero świadczy o braku związku (linia pozioma/pionowa)

![](./covariance_explained.png){width=75%}


Interpretacja opisowa: wartości powyżej 0,9 świadczą o silnej zależności.

**Przykład: korelacja między spożyciem mięsa a GDP**

```{r, results=F, echo=F, message=F}
rpm <- cor(meatCons$y1980, meatCons$y2013, method = "pearson")
rpm.out <- cor.test(meatCons$y1980, meatCons$y2013, method="pearson")
rpm.p <- rpm.out["p.value"]
```

Współczynnik korelacji liniowej wynosi `r rpm` (umiarkowana korelacja).

Czy ta wartość jest istotnie różna od zera? Jest na to stosowny
test statystyczny, który sprowadza się do określenia jakie jest
prawdopodobieństwo otrzymania r = `r rpm` przy założeniu że 
prawdziwa wartość r wynosi zero. Otóż w naszym przykładzie
to prawdopodobieństwo wynosi `r sprintf ("%e", rpm.p)` 
(czyli jest ekstremalnie małe -- r jest istotnie różne od zera).

### Macierz korelacji

Wstępnym etapem analizy zależności między zmiennymi jest często
hurtowa ocena współczynników korelacji w postaci kwadratowej **macierzy korelacji**. 

**Przykład: korelacja pomiędzy wiekiem, edukacją, szczęściem a stanem zdrowia**

Mohammadi S. i inni badali zależność pomiędzy wiekiem, poziomem edukacji, szczęściem a stanem zdrowia.
(The relationship between happiness and self-rated health: A population-based study of 19499 Iranian adults;
https://doi.org/10.1371/journal.pone.0265914)

```{r, message=F}
h0 <- read.csv("iran_happiness.csv", sep = ',', dec = ".",  header=T, na.string="NA" ) %>%
  select (age, edu, Happiness, Health) %>%
  na.omit()
cor(h0, use = "complete.obs")
```

Albo w bardziej efektownej postaci tekstowo-graficznej:

```{r, message=F}
library("corrplot")
corrplot.mixed(cor(h0))
```

### Pomiar siły zależności: regresja liniowa

**Regresja liniowa** zakłada, że istnieje związek przyczyna-skutek
i ten związek można opisać linią prostą (stąd liniowa). Skutek jest
jeden i nazywa się go **zmienną zależną** a przyczyn może być wiele i noszą
nazwę **zmiennych niezależnych** (albo **predyktorów**).
W przypadku gdy związek dotyczy dwóch zmiennych mówi się o **regresji prostej**.
Przykładowo zależność
pomiędzy spożywaniem kawy w czasie sesji egzaminacyjnej a wynikiem egzaminu
można formalnie zapisać jako:

$$ \textrm{wynik} = b_0 + b_1 \cdot \textrm{kawa}$$

Współczynnik $b_1$ określa wpływ spożycia kawy na wynik egzaminu.
W szczególności jeżeli $b_1 = 0$ to
nie ma związku między spożywaniem kawy a wynikiem egzaminu.

Jeżeli zmiennych niezależnych jest więcej niż jedna,
to mówimy o **regresji wielorakiej**. Przykładowo
zależność
pomiędzy wynikiem egzaminu, spożyciem kawy czasem nauki oraz predyspozycjami
opisuje następujący model regresji:

$$\textrm{wynik} = b_0 + b_1 \cdot \textrm{kawa} + b_2 \cdot \textrm{czas} + b_3 \cdot \textrm{predyspozycje} $$

Współczynnik $b_1$ określa wpływ spożycia kawy
$b_2$ czasu poświęconego na naukę,
a $b_3$ predyspozycji
(intelektualnych, mierzonych np. średnią ocenę ze studiów)


### Regresja prosta

Równianie regresji dla zmiennych $Y$ (skutek) oraz $X$ (przyczyna) można zapisać następująco:

$$Y = b_0 + b_1 \cdot X + e $$

$Y = b_0 + b_1 \cdot X$ to **część deterministyczna**,
a $e$ oznacza **składnik losowy**.
O tym składniku zakładamy, że średnia jego wartość wynosi zero.
Można to sobie wyobrazić, że w populacji jest jakaś prawdziwa zależność
$Y = b_0 + b_1 \cdot X$ pomiędzy $X$ a $Y$, która w próbie
ujawnia się z błędem o charakterze losowym. Ten błąd może wynikać
z pominięcia jakiejś ważnej zmiennej (model
to zawsze uproszczenie rzeczywistości), przybliżonego charakteru linii
prostej jako zależności pomiędzy $X$ a $Y$ (prosta ale nie do końca prosta)
albo błędu pomiaru.

Współczynnik $a$ (nachylenia prostej) określa wielkość efektu
w przypadku regresji, tj. siły zależności pomiędzy zmiennymi.

Współczynnik $a$ ma prostą interpretację: jeżeli wartość zmiennej $X$
rośnie o jednostkę to wartość zmiennej $Y$ zmienia
się przeciętnie o $b_1$ jednostek zmiennej Y. 
Wyraz wolny zwykle nie ma sensownej interpretacji
(formalnie jest to wartość zmiennej $Y$ dla $X=0$)

Oznaczmy przez $y_i$ wartości obserwowane (zwane też empirycznymi)
a przez $\hat y_i$ *wartości teoretyczne* (leżące na prostej linii regresji).

Wartości $b_0$ oraz $b_1$ wyznacza się minimalizując sumę kwadratów
odchyleń wartości teoretycznych od wartości empirycznych, tj.:

$$(\hat y_1 - y_1)^2 + (\hat y_2 - y_2)^2 + ... +  (\hat y_n - y_n)^2$$

Rozwiązując powyższy **problem minimalizacyjny** otrzymujemy wzory
definiujące parametry $b_0$ oraz $b_1$. Metoda wyznaczania parametrów
linii prostej w oparciu o minimalizację sumy kwadratów odchyleń 
nosi nazwę **metoda największych kwadratów**.

Przypominamy, że **estymatorem** nazywamy metodę oszacowania parametru na podstawie próby.
Ponieważ traktujemy $b_0$ oraz $b_1$ jako parametry jakieś populacji generalnej
to wzory na $b_0$ oraz $b_1$ statystyk nazwie estymatorami parametrów
$b_0$ oraz $b_1$. W konsekwencji tego $b_0$/$b_1$ posiadają jakąś wartość średnią oraz wariancję.

Przypominamy że wartość średnia **dobrego estymatora** powinna wynosić zero (bo wtedy nie ma błędu systematycznego)
oraz że wariancja estymatora powinna maleć wraz ze wzrostem liczebności próby. Można udowodnić
że estymatory parametrów $b_0$/$b_1$
uzyskane **metodą najmniejszych kwadratów** posiadają obie właściwości.

Graficznie **kryterium minimalizacyjne** przedstawia rysunek

![](./kmnk_roznice.png){width=75%}

Suma podniesionych do kwadratu odległości pomiędzy czerwonymi
i niebieskimi kropkami ma być minimalna. Kropki niebieskie to
wartości empiryczne; kropki czerwone to wartości teoretyczne.
Zadanie wyznaczenie
parametrów takiej prostej oczywiście realizuje program komputerowy.

Można udowodnić że bez względu czy punkty na wykresie układają się
w przybliżeniu wzdłuż prostej czy nie, zawsze **jakaś prosta** zostanie
dopasowana (jeżeli tylko punktów jest więcej niż jeden.) 
Jak to ocenić w sposób bardziej konkretny a nie tylko na oko dopasowanie
prostej do wartości empirycznych?

**Ocena dopasowania: wariancja resztowa oraz średni błąd szacunku**

Oznaczając *resztę* jako: $e_i = y_i - \hat y_i$, definiujemy **wariancję
resztową**  jako:

$$s_e^2 = \frac{e_1^2 + e_2^2 + ... e_n^2}{n-k}$$.

Gdzie $n$ oznacza liczbę obserwacji (liczebność próby), a $k$ liczbę
szacowanych parametrów bez wyrazu wolnego czyli jeden w regresji
prostej (a więcej niż jeden w regresji wielorakiej o czym dalej.)

Pierwiastek kwadratowy z **wariancji resztowej**.
nazywamy **średnim błędem szacunku**  (*mean square error*, MSE)

**Ocena dopasowania: współczynniki zbieżności i determinacji**

Suma kwadratów reszt (albo odchyleń wartości teoretycznych
od wartości empirycznych,
albo suma kwadratów błędów vel **resztowa suma kwadratów**):

$$\mathrm{RSK} = (y_1 - \hat y_1)^2 + (y_2 - \hat y_2)^2 + ... +  (y_n - \hat y_n)^2$$.

Suma kwadratów odchyleń **wartości empirycznych**
od średniej (**ogólna suma kwadratów**):

$$\mathrm{OSK} = (y_1 - \bar y)^2 + (y_2 - \bar y)^2 + ... +  (y_n - \bar y)^2$$

Suma kwadratów odchyleń **wartości teoretycznych**
od średniej (**wyjaśniona suma kwadratów**):

$$\mathrm{WSK} = (\hat y_1 - \bar y)^2 + (\hat y_2 - \bar y)^2 + ... +  (\hat y_n - \bar y)^2$$

Można wykazać, że $\mathrm{OSK} = \mathrm{WSK} + \mathrm{RSK}$ zatem (po podzieleniu obu stron
równania przez $\mathrm{OSK}$ otrzymujemy:

$$ 1 =  \mathrm{WSK}/\mathrm{OSK} + \mathrm{RSK}/\mathrm{OSK}$$

**Współczynnik zbieżności** oznaczany jako $R^2$ to $\mathrm{WSK}/\mathrm{OSK}$.

**Współczynnik determinacji** oznaczany jako $\Phi^2$ (duża grecka litera Fi) to $RSK/OSK$.

Współczynniki przyjmują wartość z przedziału $[0,1]$ lub $[0, 100]$% jeżeli
ich wartości zostaną pomnożone przez 100.

Interpretacja współczynnika zbieżności: udział (procent) zmienność wyjaśnianej
przez linię regresji. Im $R^2$ jest bliższe jedności (lub 100% jeżeli
jest współczynnik zbieżności jest wyrażony w procentach) tym lepiej.

**Ocena dopasowania: istotność parametru $a$**

Jeżeli: $Y= 0 \cdot X + b_0$, to $Y = b_0$ czyli nie ma zależności
pomiędzy $X$ oraz $Y$.
Wartości $b_1$ bliskie zero wskazują na słabą zależność
pomiędzy cechami.

Przypominamy, że **estymator** parametru $b_1$ ma średnią równą prawdziej wartości $b_1$.
Dodatkowo zakładamy, że rozkład tego estymatora jest normalny. To założenie
pozwala wiarygodnie oszacować wariancję; w konsekwencji znamy dokładny 
rozkład (bo przypominamy, że rozkład
normalny jest określony przez dwa parametry: średnią oraz właśnie wariancję)

Można teraz zadać pytanie jeżeli faktycznie $b_1=0$, to jakie jest prawdopodobieństwo, że
współczynnik $\hat b_1$ oszacowany
na podstawie $n$ obserwacji będzie (co do wartości bezwzględnej) większy niż $b_e$.
Albo inaczej: otrzymaliśmy $b_e$, jakie jest prawdopodobieństwo
otrzymania takiej wartości (lub większej co do wartości bezwzględnej)
przy założeniu, że istotnie $b_1=0$.

Jeżeli takie prawdopodobieństwo jest duże, to uznajemy, że być może $b_1 = 0$,
a jeżeli małe to będziemy skłonni uznać, że $b_1 \not= 0$. 
Duże/małe przyjmujemy arbitralnie, zwykle
jest to $0,1$, $0,05$ lub $0,01$. Tak zgadza się, to prawdopodobieństwo
to **poziom istotności**

W każdym programie komputerowym na wydruku wyników linii regresji są podane wartości
prawdopodobieństwa $\hat b_1 > b_e$ (co do wartości bezwzględnej). Jeżeli jest
ono mniejsze
niż ustalony **poziom istotności** to $b_1$ ma wartość istotnie różną od zera.

Testowanie istotności współczynnika regresji jest ważnym kryterium oceny
jakości dopasowania.
Regresja z **nieistotnym** współczynnikiem nie
może być podstawą do interpretowania zależności pomiędzy $X$ oraz $Y$.

**Przykład: Waga a wzrost rugbystów**

```{r message=FALSE, echo=FALSE}
rwc <- read.csv("rwc-2015-2023.csv", sep = ';', dec = ".",  header=T, na.string="NA" ) %>%
  filter (year == 2023) %>%
select(year, weight, height )

n0 <- nrow(rwc)
```

Zależność między wagą (`weight`) a wzrostem (`height`):

$$ \textrm{height} = b_0 + b_1 \textrm{weight}$$
Oszacowanie tego równania na próbie `r n0` uczestników
Pucharu Świata w rugby w 2023 roku
daje następujące wyniki:


```{r, warning=F, message=F}

ggplot(rwc, aes(x = weight, y = height)) + geom_point() +
  geom_smooth(method='lm', se=F)

#
lm.0 <- lm(data=rwc, height ~ weight ); 
lmc <- coef(lm.0)
coeff_b <- lmc["weight"]
lmr <- summary(lm.0)$r.squared

lmsum0 <- summary(lm.0)
lm.0.coef <- as.data.frame(coef(summary(lm.0)))

## wielkości standaryzowane
##lm.0.std <- round(coef(lm.beta(lm.0)), 2)
##lm_std_txt <- sprintf ("%f", lm.0.std )
## Przedziały ufności
lm.0.ci <- round(confint(lm.0), 2)
lm_ci_txt <- sprintf ("%f--%f", lm.0.ci[,1], lm.0.ci[,2] )

## zestawienie tabelaryczne wyników
lm.0.coef.df <- tibble::rownames_to_column(lm.0.coef, "Parametr") %>%
  mutate(ci=lm_ci_txt)

kable(lm.0.coef.df, row.names = F, 
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'CI95') )

```


Co oznacza, że wzrost wagi o 1kg
skutkuje przeciętnie większym wzrostem o `r coeff_b` cm. Współczynnik determinacji
wynosi `r sprintf ("%.2f", lmr * 100)`%. 
Współczynnik nachylenia prostej jest istotny ponieważ wartość $p$ (tak mała, że w tabeli
oznaczona jako 0)
jest grubo poniżej zwyczajowego poziomu istotności (p < 0,05). 

Kolumna `CI95` zawiera 95% przedziały ufności: z 95% prawdopodobieństwem wartość współczynnika nachylenia
prostej znajduje się w przedziale 0,24--0,32.

**Przykład: zamożność  a konsumpcja mięsa**

```{r message=FALSE, echo=FALSE }
meatCons <- read.csv(file='meatCons_vs_GDP.csv',sep=';',header=T)
n0 <- nrow(meatCons)
```

Następujący równanie opisuje zależność pomiędzy dochodem narodowym na głowę (*per capita*)
a konsumpcją mięsa w kilogramach:

$$\textrm{konsumpcja} = b_0 + b_1 \textrm{gdp}$$
Model oszacowano dla `r nrow(n0)` krajów świata w roku 2013 na podstawie danych
pobranych z bazy FAO Food Balance Sheet oraz Banku Światowego, otrzymując
następujące wyniki


```{r, message=F}
ggplot(meatCons, aes(x = gdp2013, y = y2013)) + geom_point() +
  geom_smooth(method='lm', se=F)

lm.0 <- lm(data=meatCons, y2013 ~ gdp2013 ); 
##summary(lm.0)

lmc <- coef(lm.0)
coeff_b <- lmc["gdp2013"]
lmr <- summary(lm.0)$r.squared

lmsum0 <- summary(lm.0)
lm.0.coef <- as.data.frame(coef(summary(lm.0)))

## wielkości standaryzowane
##lm.0.std <- round(coef(lm.beta(lm.0)), 2)
##lm_std_txt <- sprintf ("%f", lm.0.std )
## Przedziały ufności
lm.0.ci <- round(confint(lm.0), 2)
lm_ci_txt <- sprintf ("%f--%f", lm.0.ci[,1], lm.0.ci[,2] )

## zestawienie tabelaryczne wyników
lm.0.coef.df <- tibble::rownames_to_column(lm.0.coef, "Parametr") %>%
  mutate(ci=lm_ci_txt)

kable(lm.0.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'CI95') )

```



Każdy USD *per capita* więcej dochodu narodowego (GDP) oznacza przeciętny 
wzrost spożycia mięsa o `r coeff_b`  kg.  Przeciętna różnica wartości teoretycznych
od empirycznych wynosi 21,04 kg (średni błąd szacunku). 
Współczynnik zbieżności wynosi `r sprintf ("%.2f", lmr * 100)`%.
Współczynnik nachylenia prostej (mimo że jego wartość wynosi zaledwie
`r coeff_b`) jest statystycznie istotny.

Nie ma przykładów zastosowania regresji prostej w literaturze przedmiotu,
bo jest ona zbyt dużym uproszczeniem rzeczywistości. Jest to jednak
dobry punkt startu do bardziej skomplikowanego modelu regresji wielorakiej.


### Przypadek ogólny: regresja wieloraka

Uogólnieniem regresji prostej jest regresja wieloraka. W modelu
regresji wielorakiej po lewej stronie równania występuje zmienna
liczbowa oznaczona jako $Y$, a po prawej zmienne liczbowe 
lub nominalne, $X_1, \ldots, X_k$: 

$$Y = b_0 + b_1 \cdot X_1 + b_2 \cdot X_2 + ... + b_k \cdot X_k $$

Wpływ każdej
zmiennej $X_i$ na zmienną zależną $Y$ jest określony przez odpowiedni współczynnik $b_i$.

Podobnie jak w przypadku regresji prostej do oceny stopnia dopasowania modelu do danych
wykorzystuje się: średni błąd szacunku, współczynnik zbieżności $R^2$ oraz
weryfikuje się istotność współczynników $b_i$.

**Standaryzacja współczynników regresji**

Ponieważ współczynniki regresji $b_1, …, b_k$ mogą być wyrażone w różnych jednostkach miary,
bezpośrednie porównanie jest niemożliwe; mały współczynnik może w rzeczywistości być ważniejszy niż większy.
Jeżeli chcemy porównywać wielkości współczynników to trzeba je **zestandaryzować**.

Standaryzowany współczynnik regresji dla $i$-tej zmiennej
obliczony jest poprzez pomnożenie współczynnika regresji $b_i$ przez $s_{xi}$
i podzielenie przez $s_y$, tj. $\beta_i = b_i s_{xi}/ s_y$. Dla przypomnienia $s_{xi}$
to odchylenie standardowe zmiennej $X_i$, a $s_y$ to odchylenie standardowe zmiennej $Y$.
Interpretacja współczynnika standardyzowanego jest cokolwiek dziwaczna:
zmiana zmiennej $X_i$ o jedno odchylenie standardowe ($s_{xi}$)
skutkuje zmianą zmiennej $Y$ o $b_i$ jej odchylenia standardowego $s_y$.
Na szczęście współczynniki regresji standaryzuje się nie w celu lepszej interpretacji,
tylko w celu umożliwienia porównania ich względnej wielkości (*wielkości efektu*).
W publikacjach medycznych zwykle używa się litery $b$ na oznaczenie współczynników niestandaryzowanych
a litery $\beta$ na oznaczenie współczynników standaryzowanych.

**Wielkość efektu**

Współczynniki regresji to miara wielkości efektu, która wskazuje na siłę zależności między zmiennymi.
Standaryzacja pozwala na porównanie wielkości efektu zmiennych mierzonych w różnych jednostkach miary.
Standaryzacja przydaje się także w przypadku posługiwania się skalami pomiarowymi mierzącymi
przekonania i postawy, które z definicji są bezjednostkowe. 

**Wybór zmiennych objaśniających**

Zwykle jest tak, że do objaśniającej kształtowanie się wartości zmiennej $Y$ kandyduje wiele potencjalnych
predyktorów $X_k$.
Model zawierający wszystkie $X_k$ predyktory niekoniecznie będzie najlepszy.
Nie wdając się w omawianie szczegółowych zasad poprzestaniemy na dwóch kryteriach:

1. Model prostszy jest lepszy od modelu bardziej skomplikowanego jeżeli adekwatnie objaśnia zmienność $Y$
   (zasada brzytwy Ockhama)

2. Model powinien zawierać tylko zmienne o współczynnikach, których wartości są statystycznie różne od zera

Regresja krokowa (**stepwise regression**) jest metodą  wyboru najlepszych predyktorów
spośród większego zbioru zmiennych. Występuje w dwóch wariantach  **dołączania** i **eliminacji**.
Ponieważ **eliminacja** wydaje się prostsza omówimy tylko ten wariant.

W metodzie eliminacji początkowym modelem jest model zawierający wszystkie potencjalne $X_k$ predyktory.
Następnie testujemy istotność wszystkich współczynników regresji i usuwamy
ze zbioru predyktorów ten, który jest „najbardziej nieistotny“ (ma największą wartość $p$)
Procedurę powtarzamy dla modelu bez usuniętej zmiennej.
Procedurę przerywamy gdy wszystkie współczynniki regresji są statystycznie istotne.

**Przykład: zależność pomiędzy ciśnienie skurczowym, BMI oraz wiekiem**


$$\textrm{ciśnienie} = b_0 + b_1 \textrm{BMI} + b_2\textrm{wiek}$$

Dane pochodzą z badania: Zależność pomiędzy BMI i wiekiem a występowaniem cukrzycy
wśród dorosłych osób w Chinach. Badanie kohortowe (Chen i inni, *Association of body mass index
and age with incident diabetes in Chinese adults: a population-based cohort study.*
BMJ Open. 2018 Sep 28;8(9):e021768. doi: 10.1136/bmjopen-2018-021768. PMID: 30269064; PMCID: PMC6169758.)

Oryginalny zbiór danych liczy 60 tysięcy obserwacji. Dla celów przykładu losowo wybrano 90, 490
oraz 4490 obserwacji.

Oszacowanie równania dla próby o wielkości 90 obserwacji daje następujące wyniki:


```{r}
##s0 <- read.csv("RC_Health_Care_samples.csv", sep = ';', header = T )
s0 <- read.csv("RC_Health_Care_samples.csv", sep = ';', header = T ) %>%
  mutate (
      genderF = case_when (gender == 2 ~ 1, TRUE ~ 0 ),
      current.smoker = case_when(smoking.status == 1 ~ 1,  
                         TRUE ~ 0),
      ever.smoker = case_when(smoking.status == 2 ~ 1,  
                                     TRUE ~ 0),
          current.drinker = case_when(drinking.status == 1 ~ 1,  
                                     TRUE ~ 0),
          ever.drinker = case_when(drinking.status == 2 ~ 1,  
                                  TRUE ~ 0)
          )

###
s1 <- s0 %>% filter (sample == 's')
s2 <- s0 %>% filter (sample == 'm')
s3 <- s0 %>% filter (sample == 'b')

lm.1 <- lm(data=s1, SBP ~ BMI + age  ); 
lmsum1 <- summary(lm.1)
lm.1.coef <- as.data.frame(coef(summary(lm.1)))
lmr <- summary(lm.1)$r.squared

## wielkości standaryzowane
lm.1.std <- round(coef(lm.beta(lm.1)), 2)
lm_std_txt <- sprintf ("%f", lm.1.std )
## Przedziały ufności
lm.1.ci <- round(confint(lm.1), 2)
lm_ci_txt <- sprintf ("%f--%f", lm.1.ci[,1], lm.1.ci[,2] )

## zestawienie tabelaryczne wyników
lm.1.coef.df <- tibble::rownames_to_column(lm.1.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.1.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI95') )

```

Współczynnik zbieżności wynosi `r sprintf ("%.2f", lmr * 100)`%.

Oszacowanie równania dla próby o wielkości 490 obserwacji daje następujące
wyniki:


```{r}
lm.2 <- lm(data=s2, SBP ~ BMI + age  ); 
lmsum2 <- summary(lm.2)

lm.2.coef <- as.data.frame(coef(summary(lm.2)))
lmr <- summary(lm.2)$r.squared
## wielkości standaryzowane
lm.2.std <- round(coef(lm.beta(lm.2)), 2)
lm_std_txt <- sprintf ("%f", lm.2.std )
## Przedziały ufności
lm.2.ci <- round(confint(lm.2), 2)
lm_ci_txt <- sprintf ("%f--%f", lm.2.ci[,1], lm.2.ci[,2] )

## zestawienie tabelaryczne wyników
lm.2.coef.df <- tibble::rownames_to_column(lm.2.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.2.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI95') )
```

Współczynnik zbieżności wynosi `r sprintf ("%.2f", lmr * 100)`%.

Oszacowanie równania dla próby o wielkości 4490 obserwacji daje następujące
wyniki:


```{r}
lm.3 <- lm(data=s3, SBP ~ BMI + age  ); 
lmsum3 <- summary(lm.3)

lm.3.coef <- as.data.frame(coef(summary(lm.3)))
lmr <- summary(lm.3)$r.squared
## wielkości standaryzowane
lm.3.std <- round(coef(lm.beta(lm.3)), 2)
lm_std_txt <- sprintf ("%f", lm.3.std )
## Przedziały ufności
lm.3.ci <- round(confint(lm.3), 2)
lm_ci_txt <- sprintf ("%f--%f", lm.3.ci[,1], lm.3.ci[,2] )

## zestawienie tabelaryczne wyników
lm.3.coef.df <- tibble::rownames_to_column(lm.3.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.3.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI') )
```

Współczynnik zbieżności wynosi `r sprintf ("%.2f", lmr * 100)`%.

### Zmienne zero-jedynkowe

Zamiast (celem wykazania związku między zmienną licznową a nominalną) porównywać 
średnie w grupach możemy wykorzystać metodę regresji
wielorakiej. Zmienna nominalna jest zamieniana na jedną lub więcej
zmiennych binarnych, które przyjmują tylko dwie wartości 0 lub 1.

Przykładowo rodzaj miejsca pracy (skala nominalna; dwie wartości: szpital, przychodnia)
można zamienić na zmienną binarną `praca` przypisując 1 = szpital, oraz
0 = przychodnia (lub odwrotnie). Załóżmy że poziom stresu zależy od stażu pracy, satysfakcji
(obie mierzone na skali liczbowej)
rodzaju miejsca pracy. Możemy to zapisać jako następujące równanie regresji

$$\textrm{stres} = b_0 + b_1\textrm{staż} + b_2 \textrm{satysfakcja} + b_3 \textrm{praca}$$
Jaka jest interpretacja współczynnika $b_3$? Zakładając że 0 = przychodnia, $b_3$ oznacza 
przeciętną zmianę wielkości stresu
spowodowaną pracą w szpitalu w porównaniu do pracy w przychodni. Jeżeli ten współczynnik jest istotny
statystycznie, to istnieje zależność pomiędzy stresem a miejscem pracy. Czyli zamiast
stosować test $t$-Studenta i porównywać średnie w grupach,
możemy oszacować model regresji z wykorzystaniem stosownej
zmiennej zero-jedynkowej a następnie sprawdzić czy współczynnik stojący przy tej zmiennej jest istotny.

Jeżeli zmienna nominalna ma $n$ wartości należy ją zamienić na $n-1$ zmiennych zero-jedynkowych.
Załóżmy że stress zależy także od wykształcenia, mierzonego w skali nominalnej
(średnie, licencjat, magisterskie.) Tworzymy dwie zmienne:
magister (jeden jeżeli respondent ma wykształcenie magisterskie lub 0 jeżeli nie ma) 
oraz licencjat (jeden jeżeli respondent ma licencjat lub 0 jeżeli nie ma). Równanie
regresji ma postać:

$$\textrm{stres} = b_0 + b_1\textrm{staż} + b_2 \textrm{satysfakcja} + b_3 \textrm{praca}
+ b_4 \textrm{magister} + b_5 \textrm{licencjat} $$

Jeżeli $\textrm{magister} = 0$ oraz $\textrm{licencjat} = 0$ to osoba ma wykształcenie średnie.

Interpretacja: $b_4$ (jeżeli istotne) oznacza przeciętną zmianę wielkości stresu osoby z wykształceniem magisterskim w porównaniu do osoby z wykształceniem średnim. Podobnie $b_5$ oznacza przeciętną zmianę 
wielkości stresu osoby z wykształceniem licencjackim 
w porównaniu do osoby z wykształceniem średnim.

**Przykład: zależność pomiędzy ciśnienie skurczowym, BMI, wiekiem, płcią, paleniem i piciem**

Poprzednio rozważany model zależności pomiędzy  ciśnienie skurczowym, BMI oraz wiekiem 
rozszerzymy o trzy zmienne: płeć (kobieta/mężczyzna),
status względem picia alkoholu (pije, pił, nigdy nie pił)
oraz status względem palenia (palił, pali, nigdy nie palił). 
Zwróćmy uwagę że zmienne mierzące status względem palenia/picia mają nie dwie a trzy wartości. 
Należy każdą zamienić na dwie zmienne binarne, wg schematu:

`current.smoker` (pali) = 1 jeżeli pali, 0 w przeciwnym przypadku

`ever.smoker` (kiedyś palił) = 1 jeżeli palił ale nie pali, 0 w przeciwnym przypadku

Zmienna płeć `genderF` = 1 jeżeli kobieta, lub 0 jeżeli mężczyzna. Zauważmy, że nazwa zmiennej
dwuwartościowej wskazuje która wartość jest zakodowana jako 1. Przykładowo `genderF` (*female* żeby się
trzymać języka angielskiego) wskazuje że jedynką jest kobieta.
Taka konwencja ułatwia interpretację. Gdybyśmy zamiast `genderF` nazwali zmienną `gender` to na pierwszy
rzut oka nie było by wiadomo co zakodowano jako jeden. A tak wiadomo od razu jak
interpretować parametr stojący przy tej zmiennej: zmiana wielkości ciśnienia u kobiet w porównaniu do mężczyzn.

Rozważany model ma postać:

$$SBP = b_0 + b_1 \textrm{BMI} + b_2 \textrm{age} + b_3 \textrm{genderF} + 
b_4 \textrm{current.smoker} + b_5 \textrm{ever.smoker} + 
b_6 \textrm{current.drinker} + b_7 \textrm{ever.drinker}$$


Oszacowanie tego równania dla próby o wielkości 90 obserwacji daje następujące wyniki:

```{r}
lm.1 <- lm(data=s1, SBP ~ BMI + age + genderF + current.smoker + ever.smoker + current.drinker + ever.drinker );
lmsum1 <- summary(lm.1)
##lmsum1
##lm.beta(lm1)
lmr <- summary(lm.1)$r.squared

lm.1.coef <- as.data.frame(coef(summary(lm.1)))
## wielkości standaryzowane
lm.1.std <- round(coef(lm.beta(lm.1)), 2)
lm_std_txt <- sprintf ("%f", lm.1.std )
## Przedziały ufności
lm.1.ci <- round(confint(lm.1), 2)
lm_ci_txt <- sprintf ("%f %f", lm.1.ci[,1], lm.1.ci[,2] )

## zestawienie tabelaryczne wyników
lm.1.coef.df <- tibble::rownames_to_column(lm.1.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.1.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI') )

```

Współczynnik zbieżności wynosi `r sprintf ("%.2f", lmr * 100)`%. Tylko dwie na siedem zmiennych
są istotne. Zwróćmy uwagę że nieistotnie zmienne mają przedziały ufności zawierające zero. W konsekwencji
z 95% prawdopodobieństwem wartości tych współczynników mogą być raz ujemne raz dodatnie--nie mamy
nawet pewności co do kierunku zależności między zmienną zmienną objaśniającą a ciśnieniem.
Zmienne, które okazały się istotne jednocześnie mają największą wielkość efektu (kolumna `Beta`)
i nie jest to przypadek.

Oszacowanie tego samego równania dla próba o wielkości 4490 obserwacji daje następujące
wyniki:

```{r}
lm.3 <- lm(data=s3, SBP ~ BMI + age + genderF + current.smoker + ever.smoker + current.drinker + ever.drinker );
lmsum3 <- summary(lm.3)
lmr <- summary(lm.3)$r.squared
lmr7 <- lmr
##lmsum1
##lm.beta(lm1)

lm.3.coef <- as.data.frame(coef(summary(lm.3)))
## wielkości standaryzowane
lm.3.std <- round(coef(lm.beta(lm.3)), 2)
lm_std_txt <- sprintf ("%f", lm.3.std )
## Przedziały ufności
lm.3.ci <- round(confint(lm.3), 2)
lm_ci_txt <- sprintf ("%f %f", lm.3.ci[,1], lm.3.ci[,2] )

## zestawienie tabelaryczne wyników
lm.3.coef.df <- tibble::rownames_to_column(lm.3.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.3.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI') )

```

Współczynnik zbieżności wynosi `r sprintf ("%.2f", lmr * 100)`%. Zwiększenie
liczebności próby spowodowało, że tylko dwie z siedmiu zmiennych 
mają nieistotne wartości. Analizując wartości standaryzowane możemy ustalić
które zmienne mają największy wpływ na wielkość ciśnienia krwi.

Ktoś mógłby dojść do wniosku że wszystko da się **uistotnić**
wystarczy zwiększyć wielkość próby. Teoretycznie tak, praktycznie nie. 
W praktyce nie interesuje nas niewielka wielkość 
efektu (znikomy wpływ czegoś na coś). Dodatkowo zebranie dużej próby może
być kosztowne czyli w praktyce niemożliwe -- nie mamy dość dużo pieniędzy.
Można teoretycznie określić jaka wielkość próby pozwoli nam na ocenę jakiej
wielkości efektu. Sposób postępowania jest wtedy następujący: określamy
jaka wielkość efektu ma **znaczenie praktyczne**, na tej podstawie określamy
niezbędną minimalną liczebność próby. Takie zaawansowane podejście
wykracza poza ramy tego podręcznika.

**Przykład: regresja krokowa**

W modelu zależność pomiędzy ciśnienie skurczowym, BMI, wiekiem, płcią, paleniem i piciem
(próba 4490) zmienne `ever.drinker` oraz `ever.smoker` są nieistotne przy czym współczynnik
przy zmiennej `ever.drinker` ma wartość $p$ równą 0,309 zaś przy zmiennej
`ever.smoker` ma wartość 0,05324. Usuwamy zmienną `ever.drinker` (bo wartość $p$ jest większa)
i szacujemy równanie regresji dla sześciu pozostałych zmiennych. Otrzymujemy:


```{r}
lm.3 <- lm(data=s3, SBP ~ BMI + age + genderF + current.smoker + ever.smoker + current.drinker );
lmsum3 <- summary(lm.3)
lmr <- summary(lm.3)$r.squared
##lmsum1
##lm.beta(lm1)

lm.3.coef <- as.data.frame(coef(summary(lm.3)))
## wielkości standaryzowane
lm.3.std <- round(coef(lm.beta(lm.3)), 2)
lm_std_txt <- sprintf ("%f", lm.3.std )
## Przedziały ufności
lm.3.ci <- round(confint(lm.3), 2)
lm_ci_txt <- sprintf ("%f %f", lm.3.ci[,1], lm.3.ci[,2] )

## zestawienie tabelaryczne wyników
lm.3.coef.df <- tibble::rownames_to_column(lm.3.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.3.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI') )

```

Współczynnik przy zmiennej `ever.smoker` dalej uparcie jest nieistotny. Usuwamy
teraz tę zmienną. Otrzymujemy:

```{r}
lm.3 <- lm(data=s3, SBP ~ BMI + age + genderF + current.smoker + current.drinker );
lmsum3 <- summary(lm.3)
lmr <- summary(lm.3)$r.squared
##lmsum1
##lm.beta(lm1)

lm.3.coef <- as.data.frame(coef(summary(lm.3)))
## wielkości standaryzowane
lm.3.std <- round(coef(lm.beta(lm.3)), 2)
lm_std_txt <- sprintf ("%f", lm.3.std )
## Przedziały ufności
lm.3.ci <- round(confint(lm.3), 2)
lm_ci_txt <- sprintf ("%f %f", lm.3.ci[,1], lm.3.ci[,2] )

## zestawienie tabelaryczne wyników
lm.3.coef.df <- tibble::rownames_to_column(lm.3.coef, "Parametr") %>%
  mutate(std=lm_std_txt,  ci=lm_ci_txt)

kable(lm.3.coef.df, row.names = F,
      col.names = c('Zmienna', 'B', 'Błąd stand', 'z', 'p', 'Beta', 'CI') )

```

Wszystkie współczynniki mają istotnie różnie od zera wartości. Wartość
współczynnika zbieżności ostatecznego modelu wynosi `r sprintf ("%.2f", lmr * 100)`%.
Usuwając nieistotne zmienne z modelu obniżyliśmy wartość
współczynnika zmienności o 
`r round(lmr7, 4) * 100`%  -  `r round(lmr, 4) * 100`%  =  `r round(lmr7 - lmr, 4) * 100`%, czyli
tyle co nic.

## Przypadek specjalny: regresja logistyczna

Jeżeli zmienna $Y$ jest zmienną **dwuwartościową**, czyli taką która przyjmuje tylko dwie 
wartości (np. chory/zdrowy), to metoda regresji nie może być zastosowana. 
Przykładowo jeżeli zakodujemy te wartości jako chory=0 i zdrowy=1,
to zastosowanie regresji
doprowadzi do obliczenia (teoretycznych) wartości $Y$ różnych od $0$ i $1$.
Taki wynik nie ma sensownej interpretacji...

Ale zamiast szacować regresję $Y$ względem ($X$/$X$-ów) można szacować
regresję względem ryzyka dla $Y$ (czyli prawdopodobieństwa że $Y$ przyjmnie wartość 1).
Tutaj znowu pojawia się jednak trudność, bo ryzyko może przyjąć tylko wartości
z przedziału $[0,1]$.
Nie wchodząc w matematyczne zawiłości
model zapisuje się jako (ln oznacza logarytm naturalny):

$$\ln(\frac{p}{1-p}) = b_0 + b_1 \cdot x_1  + \ldots + b_k \cdot x_k$$

Zauważmy, że $o = \frac{p}{1-p}$ to nic innego jak szansa (**odds**).
Parametr $b_i$ jest miarą wpływu zmiennej $X_i$ na zmienną $Y$.
Jeżeli $X_i$ wzrośnie o jednostkę, to logarytm ilorazu szans
wzrośnie o $\ln(o)$ (przy założeniu, że pozostałem zmienne $X$ mają
pewne ustalone wartości a zmienia się tylko $X_i$).
Jeżeli $X_i$ jest zmienną **dwuwartościową**
to interpretacja jest jeszcze prostsza: jest to logarytm ilorazu szans
dla wartości $X_i=1$ względem $X_i=0$. 

Zwykle zamiast **logarytmu ilorazu szans** wolimy interpretować zmianę w kategoriach
**ilorazu szans**. Aby otrzymać ów iloraz należy wykonać następujące 
przekształcenie ($\exp$ oznacza podstawę logarytmu naturalnego):

$$o = \exp^{\ln(o)}$$

Dla przypomnienia: zwykle iloraz szans wyraża się
w procentach, czyli mnoży przez 100. Jeżeli ta liczba jest większa od 100 oznacza
to wzrost szansy, a jeżeli mniejsza od 100, spadek szansy.


**Ocena dopasowania**

Nie ma w przypadku regresji logistycznej możliwości obliczenia sumy
kwadratów reszt (*residual sum of squares*) oraz współczynnika zbieżności.
Model ocenia się 
używając jako kryterium dewiancję (*deviance*). Dewiancja to miara, której
wielkość zależy od proporcji pomiędzy liczbą sukcesów obliczonych
z modelu a liczbą sukcesów zaobserwowanych (jak dokładnie dewiancja
jest liczona nie jest dla nas istotne).

Wyjaśnijmy to na przykładzie
prostego modelu pomiędzy wystąpieniem osteoporozy a płcią. Model ma postać:

$$\ln(o) = b_0 + b_1 \textrm{płeć}$$

Po oszacowaniu $b_0$ oraz $b_1$ możemy łatwo obliczyć $\ln(o)$.
Wiedząc że $\ln(o)=\frac{p}{1-p}$ możemy stąd obliczyć prawdopodobieństwo, które
jak widać będzie różne dla kobiet i mężczyzn.
Po pomnożeniu tych prawdopodobieństw przez liczebności dostajemy
(teoretyczne) liczebności sukcesów (tj. wystąpienia osteoporozy).
Dewiancja będzie tym większa im różnica między tymi
teoretycznymi liczebnościami a liczebnościami empirycznymi będzie większa.

Jako minimum porównuje się wielkość dewiancji szacowanego modelu
z modelem zerowym (*null model*), tj. modelem w którym po prawej stronie
równania występuje tylko stała:

$$\ln(o) = b_0$$

W tym modelu prawdopodobieństwo osteoporozy jest identyczne dla
kobiet i mężczyzn, zatem w oczywisty sposób dewiancja tego modelu
będzie większa. Pytanie jest czy różnica jest istotna statystycznie.
Jeżeli jest większa to przyjmuje się, że szacowany model jest lepszy od modelu
trywialnego (warunek minimum przydatności.)

Jeżeli model zawiera wiele zmiennych w tym zmienne liczbowe, idea
liczenia dewiancji jest podobna, ale oczywiście szczegóły są już bardziej
skomplikowane. Szczegóły te nie są  wszakże dla nas istotne.

**Minimalne kryteria oceny przydatności modelu regresji logistycznej**:
istotnie mniejsza od modelu zerowego dewiancja oraz istotnie różne
od zera parametry przy zmiennych niezależnych (predyktorach)

**Ocena skuteczności klasyfikacji**

Model regresji logistycznej nie oblicza wartości zmiennej prognozowanej,
bo ta nie jest liczbą, tylko **klasyfikuje**, tj. ustala (albo prognozuje) wartość
zmiennej nominalnej w kategoriach „sukces”/„porażka”.
Ważnym kryterium oceny jakości modelu  jest ocena jakości
klasyfikacji, to jest ocena na ile model poprawnie
przypisuje przypadkom kategorie zmiennej prognozowanej. Im mniejsza
rozbieżność pomiędzy wartościami rzeczywistymi, a prognozowanymi tym oczywiście lepiej.

Tę jakość klasyfikacji ocenia się za pomocą dwóch wskaźników,
czułość (*sensitivity*) oraz swoistość (*specifity*). 

1. Odsetek sukcesów zaklasyfikowanych jako „sukces” (**Czułość**); określany
   także jako TPR (*true-positive-rate*)
2. Odsetek porażek zaklasyfikowanych jako „porażka” (**Swoistość**);
   określany także jako TNR (*true-negative-rate*)

Klasyfikacja w modelu regresji logistycznej wygląda następująco.
Jeżeli prawdopodobieństwo obliczone 
jest wyższe-lub-równe niż założona **wartość graniczna**, to zakładamy „sukces”,
jeżeli tak nie jest, to zakładamy „porażkę”. 
Wartość graniczna jest ustala albo
arbitralnie albo na podstawie jakieś dodatkowej (pozastatystycznej) informacji.
Domyślnie za wartość graniczną przyjmuje się zwykle 0,5, co oznacza że
wartości $p \geq p_g$ zostaną zamienione na „sukces”
a wartości $p < p_g$ zostaną zamienione na „porażkę”.

**Ocena dopasowania: krzywa ROC**

Czułości oraz swoistości zależą od prawdopodobieństwa granicznego.
Im wyższa
jest wartość prawdopodobieństwa granicznego  tym mniej będzie „sukcesów“.

Krzywa ROC przedstawia w układzie współrzędnych XY wartości
czułości oraz swoistości dla różnych wartości granicznych.
Współczynnik AUC (*area under curve*) to wielkość pola pod
krzywą wyrażona w procentach pola kwadratu o boku 100%.
AUC zawiera się w przedziale 50--100. Im większa wartość tym lepiej.
Model który klasyfikuje czysto losowo ma wartość AUC równą 50%.

![](./ROCcurve.png)

**Przykład #1: Osteoporoza i witamina D**

```{r}
vd0 <- read.csv("vitD.csv", sep = ',', dec = ".",  header=T, na.string="NA" ) %>%
  select(d=vitamin_D_level, age, gender, osteoporosis) %>%
  mutate (genderF = recode(gender, 
                         '1' = 1, 
                         '2' = 0))
sample.size=nrow(vd0)
```

Al Zarooni A.A.R i inni badali wpływ różnych czynników na ryzyka na
wystąpienie osteoporozy (Risk factors for vitamin D deficiency
in Abu Dhabi Emirati population; https://doi.org/10.1371/journal.pone.0264064),
takich jak deficyt witaminy D, wiek oraz płeć w grupie `r sample.size` osób.

Zacznijmy od modelu zerowego tj. takiego w którym ryzyko/prawdopodobieństwo/szansa
wystąpienia osteoporozy jest takie same bez względu na wielkości innych zmiennych.
Odpowiada to następującemu równaniu:

$$\ln(o) = b_0$$

W tabeli zestawiono wartości parametrów oszacowanego modelu, ilorazy szans, przedziału ufności
oraz prawdopodobieństwo

```{r}
## Najpierw Model zerowy
glm.0 = glm(osteoporosis ~ NULL, data = vd0, family = "binomial")
## Tylko część wydruku
gml.0.coef <- as.data.frame(coef(summary(glm.0)))
intercept <- gml.0.coef[1,1]
logit <- intercept
prob0 <- exp(logit)/(1+exp(logit)) 
## About 6.6%
## Dodanie kolumny zamiast nazw wierszy
gml.0.coef.df <- tibble::rownames_to_column(gml.0.coef, "Parametr")
##kable(gml.0.coef.df, row.names = F,
##      col.names = c('Parametr', 'Ocena', 'Błąd stand', 'z', 'p') )
```

Można obliczyć że (teoretyczne) prawdopodobieństwo wystąpienia osteoporozy
wyniosło `r prob0`. Krzywa ROC dla modelu zerowego wygląda następująco:

```{r, message=F}
pred.0 <- predict(glm.0, type = "response")
y.pred.0 <- ifelse(pred.0 < 0.5, 0, 1)
roc_obj <- roc(vd0$osteoporosis, pred.0, legacy.axes = T)
##plot(roc_obj, main = "ROC Curve for the Logistic Regression Model", legacy.axes = T)
auc<- auc_value <- auc(roc_obj)

ggroc(roc_obj,
      legacy.axes = T,
      colour = 'steelblue', size = 2) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')'))
```

Model zerowy jak sama nazwa wskazuje może tylko służyć do porównania
z bardziej skomplikowanymi modelami.

Takim bardziej skomplikowanym modelem będzie przykładowo 
zależność pomiędzy wystąpieniem osteoporozy a płcią, którą
można opisać następującym równaniem regresji:

$$\ln(o) = b_0 + b_1 \textrm{kobieta}$$

Zmienna `kobieta` przyjmuje wartość 1 jeżeli osoba była kobietą
oraz zero w przypadku jeżeli była mężczyzną.
Dla przypomnienia $o$ jest szansą wystąpienia osteoporozy.

W tabeli zestawiono wartości parametrów oszacowanego modelu, ilorazy szans, przedziału ufności
oraz prawdopodobieństwo

```{r, message=F}
## Model1

glm.1 = glm(osteoporosis ~ genderF, data = vd0, family = "binomial")
## oryginalne wartości współczynników
gml.1.coef <- as.data.frame(coef(summary(glm.1)))
## OR
glm.1.or <- round(exp(coef(glm.1)), 2)
glm_or_txt <- sprintf ("%f", glm.1.or )
## Przedziały ufności
glm.1.ci <- round(exp(confint(glm.1)), 2)
glm_ci_txt <- sprintf ("%f--%f", glm.1.ci[,1], glm.1.ci[,2] )

## zestawienie tabelaryczne wyników
gml.1.coef.df <- tibble::rownames_to_column(gml.1.coef, "Parametr") %>%
  mutate(or=glm_or_txt,  ci=glm_ci_txt)

kable(gml.1.coef.df, row.names = F,
      col.names = c('Parametr', 'Ocena', 'Błąd stand', 'z', 'p', 'OR', 'CI') )
```

Znając wartości współczynników równania można obliczyć wartości $\ln(o)$

```{r}
## Prawdopodobieństwa
intercept <- gml.1.coef[1,1]
beta1 <- gml.1.coef[2,1]
## F=1
logit_F <- intercept + beta1
logit_M <- intercept 

probF <- exp(logit_F)/(1+exp(logit_F)) 
probM <- exp(logit_M)/(1+exp(logit_M)) 

## Istotność modelu
pchisq.glm.1 <- pchisq(glm.1$null.deviance -  glm.1$deviance, glm.1$df.null - glm.1$df.residual, lower.tail = F)
##anova(glm.0, glm.1, test = 'Chisq')
##pchisq.glm.1
```

Dewiancja modelu jest istotnie mniejsza od modelu zerowego (wartość $p$ wynosi bowiem `r pchisq.glm.1`)

Zależność pomiędzy wystąpieniem osteoporozy a płcią, wiekiem oraz poziomem witaminy D
można opisać następującym równaniem regresji:

$$\ln(o) = b_0 + b_1 \textrm{kobieta} + b_2 \textrm{wiek} + b_3 \textrm{poziomD}$$

W tabeli zestawiono wartości parametrów oszacowanego modelu, ilorazy szans, przedziału ufności
oraz prawdopodobieństwo


```{r, message=F}
glm.2 = glm(osteoporosis ~ d + age + genderF, data = vd0, family = "binomial")
## oryginalne wartości współczynników
gml.2.coef <- as.data.frame(coef(summary(glm.2)))
## OR
glm.2.or <- round(exp(coef(glm.2)), 2)
glm_or_txt <- sprintf ("%f", glm.2.or )
## Przedziały ufności
glm.2.ci <- round(exp(confint(glm.2)), 2)
glm_ci_txt <- sprintf ("%f--%f", glm.2.ci[,1], glm.2.ci[,2] )

## zestawienie tabelaryczne wyników
gml.2.coef.df <- tibble::rownames_to_column(gml.2.coef, "Parametr") %>%
  mutate(or=glm_or_txt,
         ci=glm_ci_txt)

kable(gml.2.coef.df, row.names = F,
      col.names = c('Parametr', 'Ocena', 'Błąd stand', 'z', 'p', 'OR', 'CI') )
```

Macierz pomyłek (*confussion matrix*)

```{r}
## Prawdopodobieństwa
##
## Predykcja
pred.2 = predict(glm.2, type = "response")
y.pred.2 = ifelse(pred.2 < 0.5, 0, 1)

table <- table(y.pred.2, vd0$osteoporosis)
dimnames(table) <- list(
  'Prognoza' = c("0", "1"),
  'Osteoporoza' = c("0", "1")
)

table

czulosc <- table[4] / (table[3]+table[4])
swoistosc <- table[1] / (table[1]+table[2])
```

Stąd: czułość `r czulosc`; swoistość `r swoistosc`

Istotność modelu

```{r}
pchisq.glm.2 <- pchisq(glm.2$null.deviance -  glm.2$deviance, glm.2$df.null - glm.2$df.residual, lower.tail = F)
##pchisq.glm.2
##anova(glm.0, glm.2, test = 'Chisq')
```

Dewiancja jest istotnie mniejsza od dewiancji modelu zerowego (p = `r pchisq.glm.2`)

Krzywa ROC

```{r, message=F}
roc_obj <- roc(vd0$osteoporosis, pred.2, legacy.axes = T)
##plot(roc_obj, main = "ROC Curve for the Logistic Regression Model", legacy.axes = T)
auc<- auc_value <- auc(roc_obj)

ggroc(roc_obj,
      legacy.axes = T,
      colour = 'steelblue', size = 2) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')'))

```

## Przypadek specjalny: dwie zmienne co najmniej porządkowe

###  Pomiar siły zależności: współczynnik korelacji rang 

Współczynnik korelacji rang (Spearmana vel *Spearman's Rank-Order Correlation*)
może być stosowany
w przypadku gdy cechy są mierzone w skali porządkowej (lub lepszej)

Obliczenie współczynnika Spearmana dla $N$ obserwacji na zmiennych $XY$
polega na zamianie wartości
zmiennych $X$ oraz $Y$ na **rangi** (numery porządkowe od $1...N$). 
Następnie stosowana jest formuła współczynnika korelacji 
liniowej Pearsona ($\tau_x$ oraz $\tau_y$ oznaczają **rangi**):

$$\rho_{xy} = \frac{\textrm{cov}(\tau_x, \tau_y)}{s_{\tau_x}  s_{\tau_y}}$$

Współczynnik $\rho_{xy}$ to -- podobnie jak **oryginalny** współczynnik
korelacji liniowej Pearsona -- miara niemianowana, o wartościach
ze zbioru [-1;1];

**Przykład: spożycie mięsa**

Współczynnik Pearsona i Spearmana dla zależności między spożyciem mięsa w 1980
a spożyciem mięsa w 2013 roku (zmienna objaśniana):

```{r message=FALSE, echo=FALSE, warning=F}

rpm <- cor(meatCons$y1980, meatCons$y2013, method = "pearson")
rsm <- cor(meatCons$y1980, meatCons$y2013, method = "spearman")
sprintf ("współczynnik Pearsona: %.2f", rpm)
sprintf ("współczynnik Spearmana: %.2f", rsm)

rsm.out <- cor.test(meatCons$y1980, meatCons$y2013, method="spearman")
rsm.p <- rsm.out["p.value"]

```

Nie ma sensu liczenia współczynnika korelacji rang w przypadku kiedy obie
cechy są liczbami, bo wtedy należy użyć normalnego współczynnika Pearsona.
Ale nie jest to też błędem więc w powyższym przykładzie 
go liczymy :-)

Współczynnik korelacji liniowej Spearmana wynosi `r rsm` (umiarkowana korelacja).

Czy ta wartość jest istotnie różna od zera? Jest na to stosowny
test statystyczny, który sprowadza się do określenia jakie jest
prawdopodobieństwo otrzymania $r_s$ = `r rsm` przy założeniu że 
prawdziwa wartość $r_s$ wynosi zero. Otóż w naszym przykładzie
to prawdopodobieństwo wynosi `r sprintf ("%e", rsm.p)` 
(czyli jest ekstremalnie małe -- $r_s$ jest istotnie różne od zera).


## Podsumowanie

Przedstawiono 6 następujących metod ustalania zależności między zmiennymi:

1. korelogram

2. tablica korelacyjna/test chi-kwadrat

3. współczynnik korelacji Pearsona

4. współczynnik korelacji Spearmana

5. regresja liniową i logistyczna

6. testy $t$-Studenta, U Manna-Whitneya, ANOVA albo test Kruskalla-Wallisa


# Przykłady badań ankietowych

Uwaga: ankieta nie jest kolejną metodą statystyczną tylko techniką zbierania danych.
Wszystkie metody już zostały przedstawione i żadna nowe nie będzie.

## Jak zacząć badanie?

Każde w tym ankietowe.

Należy zastanowić się nad trzema sprawami: 

1. Co chcemy ustalić? 
2. Jakie dane są nam potrzebne żeby ustalić to co chcemy ustalić. 
3. Jak te dane zebrać (czyli co i w jaki sposób zmierzyć)


### Co chcemy ustalić?

Najlepiej jakąś zależność. Na przykład: Stress a wypalenie zawodowe;
satysfakcja zawodowa a retencja; determinanty satysfakcji zawodowej

Może być od biedy opis czegoś lub porównanie czegoś z czymś. Przykłady:
nadwaga wśród studentów wydziału zdrowia PSW; Analiza porównawcza
wypalenia zawodowego pielęgniarek
pracujących w różnych systemach opieki.

### Co i jak mamy mierzyć?
	
Jeżeli mamy zamiar badań nadwagę, to powinniśmy zmierzyć masę ciała.
Jeżeli celem jest ustalenie zależności pomiędzy stresem a wypaleniem
zawodowym to niewątpliwie powinniśmy zmierzyć stress i wypalenia.  Jak
dotąd banalnie prosto. Problem zaczyna się w momencie odpowiedzi na
pytanie **jak**

### Mierzenie twardych faktów vs mierzenia przekonań

Możemy pytać w ankiecie o dwie rzeczy:

* **Fakty** (wiek, staż, zawód, tętno, przebyte choroby)

* **Przekonania**, **Wartości**, **Postawy**; 
  **Uczucia** (strach / radość) albo **Zamiary**
  (w języku Attitudes/Emotions/Intentions)

Mierzenie **faktów** nie wymaga dodatkowych objaśnień. Problem jest
z mierzeniem **przekonań**.

**Przekonanie** to idea, którą jednostka uważa 
za prawdziwą. **Wartości** to trwałe przekonania o tym, 
co jest ważne dla jednostki.  Stają się standardami, według których jednostki dokonują wyborów.
**Postawy** to mentalne dyspozycje/nastawienie 
przed podjęciem decyzji, które skutkują 
określonym zachowaniem (zrobię to a nie tamto). Postawy 
kształtowane są wartościami i przekonaniami.

### Pomiar przekonań, wartości i postaw

Postawy/uczucia/zamiary są to pojęcia
abstrakcyjne. Często (albo zawsze) definiowane w obszarze psychologii,
nauk o zarządzaniu itp.

Pomiar *przekonań* jest dokonywany w specyficzny sposób.
**Definicja koncepcyjna** definiuje pojęcie 
(zaufanie do kogoś/czegoś to **przekonanie**, że 
*działania tego kogoś/czegoś okażą się zgodne z naszymi
oczekiwaniami*; satysfakcja to
**uczucie** *przyjemności, zadowolenia z czegoś*;
samoskuteczność to 
**przekonanie**, iż *jest się w stanie zrealizować określone działanie lub osiągnąć wyznaczone cele*).
**Definicja operacyjna** określa jak zmierzyć pojęcie
(jak zmierzyć satysfakcję)
Przejście od DK do DO bywa czasami mocno, hmm... arbitralne.

### Skala Likerta

Przykładowo chcemy się dowiedzieć czy i jak bardzo respondenci boją się COVID19. 

W najprostszej wersji się po prostu pytamy: 
**Czy pan/pani boi się COVID19?** i dajemy 
respondentowi trzy możliwe  warianty odpowiedzi: Tak/Nie/Nie wiem. 

Może też być pięć wariantów: bardzo się boję--boję się--ani/ani--nie boję się--zupełnie się nie boję.

Taką skalę pomiarową określamy jak wiemy jako **porządkową**. Pomiary nie są liczbami
ale są uporządkowane.
Rangi wartości są już liczbami (np 1--5 w drugim przykładzie), można je np. uśredniać
Tego typu skala pomiarowa, typowa dla ankiet, nosi nazwę skali **Likerta**.
Można sobie wymyślać skalę Likerta 7-punktową i więcej. 

Moim zdaniem powyżej  7 wariantów normalny respondent będzie miał problem 
czy się bardziej-bardziej  czy bardziej-bardziej-bardziej boi.

### Skala pomiarowa/inwentarz/kwestionariusz

Ponieważ skala Likerta jest zgrubna to 
uważa się powszechnie że lepszy wynik da pomiar 
wielokrotny. 
W naukach podstawowych mierzymy (np. linijką) parę razy, a wynik uśredniamy co daje pomiar bardziej 
precyzyjny tutaj pytamy się parę razy o to samo co
ma dać podobny efekt (mniejszy średni błąd pomiaru). 
Taka seria pytań nosi też nazwę skali albo **inwentarza**.

Nie pytamy się zatem **Czy pan/pani boi się COVID19?** tylko zadajemy serię
pytań o strach względem COVID19. 


1. I am most afraid of Corona

2. It makes me uncomfortable to think about Corona

3. My hands become clammy when I think about Corona

4. I am afraid of losing my life because of Corona

5. When I watch news and stories about Corona on social media, I become nervous or anxious.

6. I cannot sleep because I’m worrying about getting Corona.

7. My heart races or palpitates when I think about getting Corona

albo:

1. Boję się koronawirusa

2. Czuję dyskomfort, gdy myślę o koronawirusie

3. Pocą mi się dłonie, gdy myślę o koronawirusie

4. Boję się, że mogę stracić życie z powodu koronawirusa

5. Gdy oglądam wiadomości i czytam o koronawirusie w mediach
    społecznościowych, robię się nerwowy i niespokojny

6. Nie mogę spać, ponieważ martwię się, że ja lub moi bliscy zarażą się

7. Dostaję palpitacji serca, gdy myślę o tym, że mógłbym się zarazić.

Odpowiadający ma do wyboru pięć wariantów odpowiedzi:
**zdecydowanie nie**/**nie**/**nie mam zdania**/**tak**/**zdecydowanie tak**


The Fear of COVID-19 Scale: Development and Initial Validation. 
International Journal of
Mental Health and Addiction, 1–9. 
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7100496/

*Fear of COVID-19 Scale (FCV-19S) across countries: Measurement invariance issues*
https://onlinelibrary.wiley.com/doi/10.1002/nop2.855

*Fear of COVID-19, psychological distress, work satisfaction and turnover 
intention among frontline nurses*
https://onlinelibrary.wiley.com/doi/full/10.1111/jonm.13168

Lęk przed koronawirusem COVID-19
i lęk przed śmiercią – polskie adaptacje narzędzi
https://www.termedia.pl/Fear-of-COVID-19-and-death-anxiety-Polish-adaptations-of-scales,116,44937,1,1.html

### Model pomiaru

Ukryty czynnik (strach) kształtuje wartości indykatorów (odpowiedzi na pytania)
Taki sposób pomiaru **ukrytego czynnika** (latent w języku) określa się
mianem refleksyjnego (co jest kalką od *reflexive*). Na rysunku
kierunek strzałki obrazuje zależność (czynnik→indykator)


![](./pomiar_ses-cropped.png)

Alternatywny sposób definiowania ukrytego (w pewnym sensie, raczej złożonego)
czynnika nosi nazwę **formatywnego** (albo indeksu): czynnik jest sumą indykatorów.
Przykładem może być SES: 
status socjo-ekonomiczny będący agregatem wykształcenia (W), dochodu (D) 
oraz zawodu (Z).


W założeniu indykatory są jednakowo dobrymi miarami
czynnika refleksyjnego i jako takie powinny być mocno
skorelowane (mierzą to samo). 
Natomiast składniki czynnika formatywnego nie powinny
być skorelowane, raczej każdy powinien mierzyć **inny
aspekt** czynnika. Ktoś może być profesorem 
za przeproszeniem filozofii, nie mieć pracy i kiepskie
dochody. 
Tylko jeden z trzech aspektów podwyższa mu SES;
albo świetnie zarabiająca prostytutka bez matury.

Jeżeli w czynniku refleksyjnym pominiemy jeden z trzech indykatorów to nic się
nie stanie oprócz tego że pomiar będzie mniej precyzyjny. Jeżeli
w czynniku formatywnym pominiemy indykator to popełniamy gruby błąd bo pomijamy
jeden istotny składnik całości.

Dobrą wiadomością jest, że najprostszy sposób pomiaru traktuje czynniki
refleksyjne i formatywne jednakowo: wartością czynnika jest suma 
wartości indykatorów. Jeżeli indykatory są mierzone za pomocą skali Likerta
suma rang po prostu. W skali strachu przed COVID ten kto się najbardziej
boi powinien odpowiedzieć 7 razy **zdecydowanie tak** co odpowiada 
sumie 35 rang (jeżeli rangujemy od 1 do 5). 
Ten który się wcale nie boi zaś 7.

Małym utrudnieniem mogą być **pytania odwrócone**. Jeżeli pytamy
o strach przed COVID i w każdym pytaniu jak bardzo ktoś się boi, albo jak
bardzo mu serce bije, ale w jednym z pytań zapytamy **nie boję się COVID**
To ranga 5 odpowiada uczuciu **braku strachu**. Rangi w pytaniach odwróconych
należy przeliczyć (odwrócić): 1 zamienić na 5, 2 na 4 itd...
Jeżeli używamy cudzych skal to w opisie powinno być wskazane które
pytania są odwrócone.

**Zalecany schemat postępowania jeżeli w ankiecie mają być mierzone
przekonania** (strach, samoskuteczność, wypalenie zawodowe, stress czy satysfakcja):

* Dokształcamy się nieco z psychologii mimo wszystko

* Robimy przegląd literatury i znajdujemy skalę, którą ktoś już wymyślił żeby
  to mierzyć; **raczej nie należy wymyślać własnych skal**.

* Robimy ankietę (w Internecie) i zbieramy dane

* Wykonujemy analizę statystyczną

Banalnie proste

## Przykład 1: Wiedza na temat szkodliwości palenia i jej uwarunkowania wśród studentów PSW

```{r}
s0 <- read.csv("palenie_PSW.csv", sep = ',',  header=F, skip=1, na.string="NA", fileEncoding = "UTF-8",
   col.names = c('time', 
   'status', 'palenie.staz', 
   'palenie.rzucenie', 
   'uzaleznienie', 
   'P5',
   'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 
   'ocena.wiedzy', 'wzorce.palenia', 'plec', 'wiek', 'staz', 'miejsce.pracy'))

s1 <- s0 %>%
   mutate(
staz=recode(staz,
'0-3 lat'   = '06 i mniej',
'4-6 lat'   = '06 i mniej',
'7-9 lat'   = '07-12',
'8-12 lat'  = '07-12',
'10-12 lat' = '07-12',
'13-15 lat' = '13-18',
'16-18 lat' = '13-18',
'19-21 lat' = '19 i więcej',
'22-24 lat' = '19 i więcej',
'25 lat i więcej' = '19 i więcej') ) %>%
#
##T12. Uważasz, że bardziej szkodliwe dla zdrowia jest: [JW]
# "Każda forma kontaktu"
mutate (P5 = case_when( str_detect(P5, "Każda forma kontaktu") ~ 1, TRUE ~ 0)) %>%
##==
# "Palenie czynne"
# "Palenie bierne"
# "Nie wiem"
#
##T16
mutate (
 P9A = case_when( str_detect(P9, "Przewlekła obturacyjna choroba płuc") ~ 1, TRUE ~ 0),
 P9B = case_when( str_detect(P9, "Astma oskrzelowa") ~ 1, TRUE ~ 0),
 P9C = case_when( str_detect(P9, "Alergie wziewne") ~ 1, TRUE ~ 0),
 P9D = case_when( str_detect(P9, "Przewlekłe zapalenie oskrzeli") ~ 1, TRUE ~ 0),
 P9E = case_when( str_detect(P9, "Infekcje dróg oddechowych") ~ 1, TRUE ~ 0),
 ##
 P9F = case_when( str_detect(P9, "Gruźlica") ~ -1, TRUE ~ 0),
 P9G = case_when( str_detect(P9, "Zapalenie płuc") ~ -1, TRUE ~ 0),
 P9H = case_when( str_detect(P9, "Palenie nie powoduje") ~ -1, TRUE ~ 0),
 P9I = case_when( str_detect(P9, "Nie wiem") ~ -1, TRUE ~ 0),
#
#T17
#
 P10A = case_when( str_detect(P10, "Nadciśnienie tętnicze krwi") ~ 1, TRUE ~ 0),
 P10B = case_when( str_detect(P10, "Zawał mięśnia sercowego") ~ 1, TRUE ~ 0),
 P10C = case_when( str_detect(P10, "Udar mózgu") ~ 1, TRUE ~ 0),
 P10D = case_when( str_detect(P10, "Choroba niedokrwienna serca") ~ 1, TRUE ~ 0),
 P10E = case_when( str_detect(P10, "Miażdżyca tętnic obwodowych") ~ 1, TRUE ~ 0),
 P10F = case_when( str_detect(P10, "Zaburzenie rytmu serca") ~ 1, TRUE ~ 0),
 P10G = case_when( str_detect(P10, "Choroba Buergera") ~ 1, TRUE ~ 0),
 ##
 P10H = case_when( str_detect(P10, "Hipercholesterolemia") ~ -1, TRUE ~ 0),
 P10I = case_when( str_detect(P10, "Tętniak aorty") ~ -1, TRUE ~ 0),
 P10J = case_when( str_detect(P10, "Palenie nie powoduje") ~ -1, TRUE ~ 0)) %>%
# 
#T18. Czy palenie papierosów powoduje choroby układu pokarmowego? [JW]
#"Tak"
#==
mutate (P11 = case_when( str_detect(P11, "Tak") ~ 1, TRUE ~ 0)) %>%
#"Nie"
#"wiem"
#
#T19. Jaki według Ciebie ma wpływ palenie papierosów na narządy zmysłów?
#
mutate (
 P12A = case_when( str_detect(P12, "Upośledza węch i smak") ~ 1, TRUE ~ 0),
 P12B = case_when( str_detect(P12, "Powoduje podrażnienie spojówek") ~ 1, TRUE ~ 0),
 P12C = case_when( str_detect(P12, "Obniża apetyt") ~ 1, TRUE ~ 0),
 P12D = case_when( str_detect(P12, "Niszczy struny głosowe") ~ 1, TRUE ~ 0),
 P12E = case_when( str_detect(P12, "Zmniejsza ostrość wzroku") ~ 1, TRUE ~ 0),
 ##
 P12F = case_when( str_detect(P12, "Palenie nie ma") ~ -1, TRUE ~ 0)) %>%
  mutate (
    P.total = P5 + 
          P9A + P9B + P9C + P9D + P9E + P9F + P9G + P9H + P9I +
          P10A + P10B + P10C + P10D + P10E + P10F + P10G + P10H + P10I +
          P11 +
          P12A + P12B + P12C + P12D + P12E + P12F )

```

### Cel

Celem jest ocena wielkości zjawiska palenia tytoniu oraz
poziom wiedzy na temat szkodliwości palenia tytoniu
wśród
studentów RM/PO PSW oraz zweryfikowanie wpływu wybranych czynników warunkujących na ten nałóg.

**Postawiono następujące hipotezy badawcze**

1. jaka jest wielkość zjawiska palenie tytoniu wśród studentów PSW?

2. jaka jest wiedza na temat szkodliwości palenia tytoniu wśród studentów PSW?

3. czy palenie jest skorelowane z płcią, stażem pracy i miejscem pracy?

4. czy wiedza na temat szkodliwości palenie jest skorelowana z płcią, stażem pracy i miejscem pracy?

5. czy palenie jest skorelowane z wiedzą na temat szkodliwości palenia?


### Metoda

Badanie ankietowe wśród studentów RM oraz PO przeprowadzono w styczniu 2023.
Ankieta zawierała pytania dotyczące palenia tytoniu (pali/nie pali/palił, jak długo pali itd),
test wiedzy na temat szkodliwości palenia oraz pytania
o rodzaj miejsca pracy, staż pracy i płeć itd.

Pięć następujących pytań oceniało wiedzę ankietowanego:

* Uważasz, że bardziej szkodliwe dla zdrowia jest (JW),
* Jakie według Ciebie choroby układu oddechowego mogą być spowodowane
  bezpośrednio przez palenie papierosów?
* Czy palenie papierosów powoduje choroby układu pokarmowego? (JW)
* Jakie według Ciebie choroby kardiologiczne mogą być spowodowane
  bezpośrednio przez palenie papierosów?
  Jaki według Ciebie ma wpływ palenie papierosów na narządy zmysłów? (wielokrotnego)

W przypadku pytań jednokrotnego wyboru, za wskazanie poprawnej odpowiedzi respondent otrzymywał 1 punkt.
W przypadku pytań wielokrotnego wyboru za wskazanie prawidłowej odpowiedzi respondent otrzymywał 1 punkt, ale
za wskazanie nieprawidłowej
otrzymywał (minus) -1 punkt (aby nie opłacała się strategia zaznaczenia wszystkich odpowiedzi).
Maksymalna możliwa do uzyskania liczba punktów wynosiła 19.

### Zastosowane metody statystyczne

* Hipotezę 1. oceniono na podstawie odsetka respondentów palących

* Hipotezę 2. oceniono na podstawie odsetka respondentów wykazujących się dobrą i bardzo dobrą wiedzą na temat palenia

* Hipotezę 3--5 zweryfikowano z wykorzystaniem tablic korelacyjnych/testu chi-kwadrat
oraz porównania średniego poziomu depresji w grupach za pomocą testów Manna-Whitneya oraz
Kruskalla-Wallisa


### Metryczka (analiza respondentów)


```{r, echo=F}
P.total.mean <- mean (s1$P.total)
P.total.sd <- sd (s1$P.total)
P.total.median <- median(s1$P.total)
P.total.q3 <- quantile(s1$P.total, prob=.75)
P.total.N <- nrow(s1)
ex.p <- ggplot(s1, aes(x = P.total)) + 
  geom_histogram(binwidth = 2, fill='steelblue', color='navyblue') +
  ylab("liczba respondentów") +
  xlab("Wynik testu") +
  ggtitle("Studenci wg wyniku testu na znajomość szkodliwości palenia") 
ex.p
```

W badaniu wzięło udział `r P.total.N` studentów. 
Otrzymano `r P.total.N` poprawnie
wypełnionych ankiet. Średnia wartość testu oceniającego wiedzę
wyniosła `r P.total.mean` (odchylenie
standardowe `r P.total.sd`)

Rozkład ankietowanych ze względu na status względem
palenia przedstawiono na rysunku


```{r}
s0.status <- s1 %>%
  select (status) %>%
  group_by(status)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )

p.status <- s0.status %>%
  ggplot(aes(x = status, y = prop )) +
  ggtitle("Studenci wg statusu palenia (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.status, aes(label=sprintf("%.2f", prop), y= prop), vjust=1.5, color="white" ) 
p.status
```

Rozkład ankietowanych ze względu na płeć przedstawiono na rysunku

```{r}
s0.sex <- s1 %>%
  select (plec) %>%
  group_by(plec)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )

p.1 <- s0.sex %>%
  ggplot(aes(x = reorder(plec, prop), y = prop )) +
  ggtitle("Studenci wg płci (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.sex, aes(label=sprintf("%.2f", prop), y= prop), hjust=1.5, color="white" ) +
  #scale_x_discrete (breaks=var.names,  labels=var.labels) +
  coord_flip()
p.1
```

Rozład ankietowanych ze względu na staż pracy przedstawiono na rysunku

```{r}
s0.staz <- s1 %>%
  select (staz) %>%
  group_by(staz)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )

p.3 <- s0.staz %>%
  ggplot(aes(x = staz, y = prop )) +
  ggtitle("Studenci wg stażu pracy (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.staz, aes(label=sprintf("%.2f", prop), y= prop), vjust=1.5, color="white" ) 
#scale_x_discrete (breaks=var.names,  labels=var.labels) +
##coord_flip()
p.3
```

Rozkład ankietowanych ze względu na rodzaj miejsca pracy
przedstawiono na rysunku

```{r}
s0.miejsce <- s1 %>%
  select (miejsce.pracy) %>%
  group_by(miejsce.pracy)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )

p.4 <- s0.miejsce %>%
  ggplot(aes(x = miejsce.pracy, y = prop )) +
  ggtitle("Studenci wg miejsca pracy (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.miejsce, aes(label=sprintf("%.2f", prop), y= prop), vjust=1.5, color="white" ) 
#scale_x_discrete (breaks=var.names,  labels=var.labels) +
##coord_flip()
p.4
```

### Weryfikacja hipotezy 1

```{r, echo=F}
pala_lub_palili <- s0 %>% filter (status != 'Nigdy nie paliłem/am') %>%
  summarize(n=n())
```

Palą lub paliło `r pala_lub_palili` respondentów 
( `r sprintf("%.f", pala_lub_palili/ P.total.N *100)` %).
Żeby stwierdzić czy to jest dużo czy mało to np. można by porównać
z jakąś średnią ogólnopolską.

### Weryfikacja hipotezy 2

Średnia wartość uzyskana w teście wyniosła `r P.total.mean`
(mediana `r P.total.median`); 3/4 respondentów nie uzyskało więcej niż
`r P.total.q3` (czyli `r sprintf("%.1f", P.total.q3/19 *100)` %)

### Weryfikacja hipotez 3--5

Czy palenie jest skorelowane z płcią?

```{r}
t.sex.f <- s1 %>%
  select (status, plec) %>% 
  table()

t.sex.t <- kable(t.sex.f)
t.sex.t

chi_test <- chisq.test(t.sex.f)
chi_test
```

Nie jest o czym świadczy wysoka wartość p (`r chi_test["p.value"]`)

Czy palenie jest skorelowane ze stażem pracy?

```{r}
## staż

t.staz.f <- s1 %>%
  select (status, staz) %>% 
  table()

t.staz.t <- kable(t.staz.f)
t.staz.t

chi_test <- chisq.test(t.staz.f)
chi_test
```

Nie jest o czym świadczy wysoka wartość p (`r chi_test["p.value"]`)


Czy palenie jest skorelowane z miejscem pracy?

```{r}
##

t.praca.f <- s1 %>%
  select (status, miejsce.pracy) %>% 
  table()

t.praca.t <- kable(t.praca.f)
t.praca.t

chi_test <- chisq.test(t.praca.f)
chi_test
```

Nie jest o czym świadczy wysoka wartość p (`r chi_test["p.value"]`)

Czy wiedza na temat palenia jest skorelowana z płcią:

```{r}
##########################
## Wiedza a płeć, staż, miejsce pracy

s0.pl <- s1 %>%
  group_by(plec) %>%
  summarise(m = mean(P.total), n=n())
kable(s0.pl, col.names = c('płeć', 'średnia', 'n'))
wilcoxp <- wilcox.test(P.total ~ plec, data=s1)
wilcoxp['p.value']
```

Porównujemy dwie grupy zatem stosujemy test Manna-Whitneya.
Wartość p wynosi `r wilcoxp['p.value']` -- nie ma podstaw
od odrzucenia hipotezy o braku korelacji na poziomie 0,05 (ale na poziomie
0,1 już byśmy mogli przyjąć że takowa korelacji istnieje)

Czy wiedza na temat palenia jest skorelowana z miejscem pracy:

```{r}
s0.mp <- s1 %>%
  group_by(miejsce.pracy) %>%
  summarise(m = mean(P.total), n=n())
kable(s0.mp, col.names = c('m.pracy', 'średnia', 'n'))
wilcoxp <- wilcox.test(P.total ~ miejsce.pracy, data=s1)
wilcoxp['p.value']
```

Porównujemy dwie grupy zatem stosujemy test Manna-Whitneya.
Wartość p wynosi `r wilcoxp['p.value']` -- nie ma podstaw
od odrzucenia hipotezy o braku korelacji na poziomie 0,05.

Czy wiedza na temat palenia jest skorelowana ze stażem:

```{r}
s0.st <- s1 %>%
  group_by(staz) %>%
  summarise(m = mean(P.total), n=n())
kable(s0.st, col.names = c('staż', 'średnia', 'n'))
kw<- kruskal.test(P.total ~ staz, data = s1)
kw["p.value"]
#wilcoxp <- wilcox.test(P.total ~ staz, data=s1)
#wilcoxp['p.value']
```

Porównujemy więcej niż dwie grupy zatem stosujemy test Kruskalla-Wallisa.
Wartość p wynosi `r kw["p.value"]` -- nie ma podstaw
od odrzucenia hipotezy o braku korelacji na poziomie 0,05.

Czy wiedza o szkodliwości palenia jest skorelowana
ze statusem względem palenia? Chcemy zastosować tablicę wielodzielczą/test chi kwadrat. Musimy zatem zamienić skalę liczbową zmiennej  mierzącej wiedzę nt szkodliwości palenia na nominalną, np tak:
0--5 mała; 6--10 średnia; 11--15 duża, 16--19 ogromna:

```{r}
## Wiedza a palenie
wiedza.status.t <- s1 %>%
  select (P.total, status) %>% 
  mutate( P.total=case_when(P.total < 6 ~ "mała",  
                         P.total < 11 ~ "średna", 
                         P.total < 16 ~ "duża",
                         TRUE ~ "ogromna") ) %>%
  table()

ws.t <- kable(wiedza.status.t)
ws.t

chi_test <- chisq.test(wiedza.status.t)
chi_test
```

Widza i status wzg. palenia nie jest skorelowana
o czym świadczy wysoka wartość p (`r chi_test["p.value"]`)

Można to samo zweryfikować porównując średnie w grupach
i stosując test Kruskalla-Wallisa

```{r}
## albo średnia wiedzia w grupach wg statusu

s0.sw <- s1 %>%
  group_by(status) %>%
  summarise(m = mean(P.total), n=n())
kable(s0.sw, col.names = c('status', 'średnia', 'n'))

kw<- kruskal.test(P.total ~ status, data = s1)
kw["p.value"]
```

Wynik jest identyczny (wysoka wartość p `r kw["p.value"]`)

### Wnioski

* Ponad połowa studentów pali lub paliła 

* Nie ma związku pomiędzy statusem względem palenia/wiedzą o szkodliwości
palenia a płcią, miejscem pracy, stażem.

## Przykład 2: Depresja i jej uwarunkowania wśród studentów PSW

### Cel

Celem jest ustalenie czy depresja jest istotnym problemem wśród
studentów RM/PO PSW oraz 
zweryfikowanie wybranych czynników warunkujących depresję.

### Metoda

Badanie ankietowe wśród studentów RM oraz PO przeprowadzono w styczniu 2023.
Ankieta zawierała test samooceny depresji Becka oraz pytania
o rodzaj miejsca pracy, staż pracy i płeć.

Test samooceny depresji Becka składa się z 21 pytań. W każdym pytaniu
możliwe są 4 warianty odpowiedzi, odpowiadające zwiększonej intensywności objawów depresji,
którym w związku z tym przypisuje się od zera do 3 punktów. Maksymalna liczba punktów
w teście wynosi 63 a minimalna 0.

Interpretacja wyników testu Becka 0--19 brak/łagodna depresja;
20--25 umiarkowana; 26--63 cieżka depresja.

Postawiono następujące hipotezy badawcze

1. depresja stanowi duży problem wśród studentów PSW

2. problem depresji zależy od miejsca pracy

3. problem depresji zależy od stażu pracy

4. problem depresji zależy od płci

Sposoby weryfikacji:

* Hipotezę 1. oceniono na podstawie odsetka respondentów wykazujących ciężką postać depresji;

* Hipotezę 2--4 zweryfikowano z wykorzystaniem tablic wielodzielczych/testu chi-kwadrat
oraz porównania średniego poziomu depresji w grupach za pomocą testów Manna-Whitneya oraz
Kruskalla-Wallisa


```{r, echo=F}
s0 <- read.csv("depresja_PSW_2023.csv", sep = ',',  header=F, skip=1, na.string="NA",
   col.names = c('time', 'P1', 'P2', 'P3', 'P4', 'P5',
   'P6', 'P7', 'P8', 'P9', 'P10',
   'P11', 'P12', 'P13', 'P14', 'P15',
   'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'praca', 'staz', 'plec', 'x1'),
               fileEncoding = "UTF-8") %>%
   mutate(
staz=recode(staz,
'0-3 lat'   = '06 i mniej',
'4-6 lat'   = '06 i mniej',
'7-9 lat'   = '07-12',
'8-12 lat'  = '07-12',
'10-12 lat' = '07-12',
'13-15 lat' = '13-18',
'16-18 lat' = '13-18',
'19-21 lat' = '19 i więcej',
'22-24 lat' = '19 i więcej',
'25 lat i więcej' = '19 i więcej'),
P1=recode(P1,
 'Nie jestem smutny ani przygnębiony.'=0,
 'Odczuwam często smutek, przygnębienie'=1,
 'Przeżywam stale smutek, przygnębienie i nie mogę uwolnić się od tych przeżyć.'=2,
 'Jestem stale tak smutny i nieszczęśliwy, że jest to nie do wytrzymania.'=3),
###
P2=recode(P2,
 'Nie przejmuję się zbytnio przyszłością.'=0,
 'Często martwię się o przyszłość.'=1,
 'Obawiam się, że w przyszłości nic dobrego mnie nie czeka.'=2,
 'Czuję, że przyszłość jest beznadziejna i nic tego nie zmieni.'=3),
###
P3=recode(P3,
 'Sądzę, że nie popełniam większych zaniedbań.'=0,
 'Sądzę, że czynię więcej zaniedbań niż inni.'=1,
 'Kiedy spoglądam na to, co robiłem, widzę mnóstwo błędów i zaniedbań.'=2,
 'Jestem zupełnie niewydolny i wszystko robię źle.'=3),
###
P4=recode(P4,
 'To, co robię, sprawia mi przyjemność.'=0,
 'Nie cieszy mnie to, co robię.'=1,
 'Nic mi teraz nie daje prawdziwego zadowolenia.'=2,
 'Nie potrafię przeżywać zadowolenia i przyjemności; wszystko mnie nuży.'=3),
##
P5=recode(P5,
 'Nie czuję się winnym ani wobec siebie, ani wobec innych.'=0,
 'Dość często miewam wyrzuty sumienia.'=1,
 'Często czuję, że zawiniłem.'=2,
 'Stale czuję się winny.'=3),
##
P6=recode(P6,
 'Sądzę, że nie zasługuję na karę'=0,
 'Sądzę, że zasługuję na karę'=1,
 'Spodziewam się ukarania'=2,
 'Wiem, że jestem karany (lub ukarany)'=3),
##
P7=recode(P7,
 'Jestem z siebie zadowolony'=0,
 'Nie jestem z siebie zadowolony'=1,
 'Czuję do siebie niechęć'=2,
 'Nienawidzę siebie'=3),
##
P8=recode(P8,
 'Nie czuję się gorszy od innych ludzi'=0,
 'Zarzucam sobie, że jestem nieudolny i popełniam błędy'=1,
 'Stale potępiam siebie za popełnione błędy'=2,
 'Winię siebie za wszelkie zło, które istnieje'=3),
##
P9=recode(P9,
 'Nie myślę o odebraniu sobie życia'=0,
 'Myślę o samobójstwie — ale nie mógłbym tego dokonać'=1,
 'Pragnę odebrać sobie życie'=2,
 'Popełnię samobójstwo, jak będzie odpowiednia sposobność'=3),
##
P10=recode(P10,
 'Nie płaczę częściej niż zwykle'=0,
 'Płaczę częściej niż dawniej'=1,
 'Ciągle chce mi się płakać'=2,
 'Chciałbym płakać, lecz nie jestem w stanie'=3),
##
P11=recode(P11,
 'Nie jestem bardziej podenerwowany niż dawniej'=0,
 'Jestem bardziej nerwowy i przykry niż dawniej'=1,
 'Jestem stale zdenerwowany lub rozdrażniony'=2,
 'Wszystko, co dawniej mnie drażniło, stało się obojętne'=3),
##
P12=recode(P12,
 'Ludzie interesują mnie jak dawniej'=0,
 'Interesuję się ludźmi mniej niż dawniej'=1,
 'Utraciłem większość zainteresowań innymi ludźmi'=2,
 'Utraciłem wszelkie zainteresowanie innymi ludźmi'=3),
P13=recode(P13,
 'Decyzje podejmuję łatwo, tak jak dawniej'=0,
 'Częściej niż kiedyś odwlekam podjęcie decyzji'=1,
 'Mam dużo trudności z podjęciem decyzji'=2,
 'Nie jestem w stanie podjąć żadnej decyzji'=3),
P14=recode(P14,
 'Sądzę, że wyglądam nie gorzej niż dawniej'=0,
 'Martwię się tym, że wyglądam staro i nieatrakcyjnie'=1,
 'Czuję, że wyglądam coraz gorzej'=2,
 'Jestem przekonany, że wyglądam okropnie i odpychająco'=3),
P15=recode(P15,
 'Mogę pracować jak dawniej'=0,
 'Z trudem rozpoczynam każdą czynność'=1,
 'Z wielkim wysiłkiem zmuszam się do zrobienia czegokolwiek'=2,
 'Nie jestem w stanie nic zrobić'=3),
##
P16=recode(P16,
 'Sypiam dobrze, jak zwykle'=0,
 'Sypiam gorzej niż dawniej'=1,
 'Rano budzę się 1–2 godziny za wcześnie i trudno jest mi ponownie usnąć'=2,
 'Budzę się kilka godzin za wcześnie i nie mogę usnąć'=3),
##
P17=recode(P17,
 'Nie męczę się bardziej niż dawniej'=0,
 'Męczę się znacznie łatwiej niż poprzednio.'=1,
 'Męczę się wszystkim, co robię.'=2,
 'Jestem zbyt zmęczony, aby cokolwiek robić.'=3),
##
P18=recode(P18,
 'Mam apetyt nie gorszy niż dawniej'=0,
 'Mam trochę gorszy apetyt'=1,
 'Apetyt mam wyraźnie gorszy'=2,
 'Nie mam w ogóle apetytu'=3),
##
P19=recode(P19,
 'Nie tracę na wadze (w okresie ostatniego miesiąca)'=0,
 'Straciłem na wadze więcej niż 2 kg'=1,
 'Straciłem na wadze więcej niż 4 kg'=2,
 'Straciłem na wadze więcej niż 6 kg'=3),
P20=recode(P20,
 'Nie martwię się o swoje zdrowie bardziej niż zawsze'=0,
 'Martwię się swoimi dolegliwościami, mam rozstrój żołądka, zaparcie, bóle'=1,
 'Stan mojego zdrowia bardzo mnie martwi, często o tym myślę'=2,
 'Tak bardzo martwię się o swoje zdrowie, że nie mogę o niczym innym myśleć'=3),
P21=recode(P21,
'Moje zainteresowania seksualne nie uległy zmianom'=0,
'Jestem mniej zainteresowany sprawami płci (seksu)'=1,
'Problemy płciowe wyraźnie mniej mnie interesują'=2,
'Utraciłem wszelkie zainteresowanie sprawami seksu'=3)) %>%
  mutate (P=P1+P2+P3+P4+P5+P6 + P7 + P8 + P9 +P10 + 
            P11+P12+P13+P14+P15+P16 + P17 + P18 + P19 +P20 + P21,
          Depresja = case_when( P < 20 ~ "B", P < 26 ~ "Ł", TRUE ~ "C")) 

```

### Metryczka


```{r, echo=F}
s0.N <- nrow(s0)
##summary(s0$P)
s0.mean <- mean(s0$P)
s0.sd <- sd(s0$P)
```

W badaniu wzięło udział `r s0.N` studentów. Otrzymano `r s0.N` poprawnie
wypełnionych ankiet. Średnia wartość testu Becka wyniosła `r s0.mean` (odchylenie
standardowe `r s0.sd`)


```{r}
ex.p <- ggplot(s0, aes(x = P)) + 
  geom_histogram(binwidth = 2, fill='steelblue', color='navyblue') +
  ylab("liczba respondentów") +
  xlab("Wynik testu") +
  ggtitle("Studenci wg wyniku testu Becka") 
ex.p

###
s0.sex <- s0 %>%
  select (plec) %>%
  group_by(plec)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )


p.1 <- s0.sex %>%
  ggplot(aes(x = reorder(plec, prop), y = prop )) +
  ggtitle("Studenci wg płci (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.sex, aes(label=sprintf("%.2f", prop), y= prop), hjust=1.5, color="white" ) +
  #scale_x_discrete (breaks=var.names,  labels=var.labels) +
  coord_flip()
p.1

##
s0.staz <- s0 %>%
  select (staz) %>%
  group_by(staz)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )

p.3 <- s0.staz %>%
  ggplot(aes(x = staz, y = prop )) +
  ggtitle("Studenci wg stażu pracy (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.staz, aes(label=sprintf("%.2f", prop), y= prop), vjust=1.5, color="white" ) 
  #scale_x_discrete (breaks=var.names,  labels=var.labels) +
  ##coord_flip()
p.3
```



### Weryfikacja hipotezy 1

```{r, echo=F}
s0.dep <- s0 %>%
  select (Depresja) %>%
  group_by(Depresja)%>%
  summarize(n=n())%>%
  mutate(prop=n/sum(n) * 100 )


p.2 <- s0.dep %>%
  ggplot(aes(x = reorder(Depresja, prop), y = prop )) +
  ggtitle("Studenci wg stanu psychicznego (%)") +
  xlab("") + ylab("%") +
  geom_bar(position = 'dodge', stat = 'identity', fill = "steelblue") +
  geom_text(data=s0.dep, aes(label=sprintf("%.2f", prop), y= prop), hjust=1.5, color="white" ) +
  #scale_x_discrete (breaks=var.names,  labels=var.labels) +
  coord_flip()
p.2
```

Ciężką postać depresji wykazuje zaledwie 3% studentów. Należy odrzucić hipotezę
że depresja stanowi poważny problem wśród studentów RM/PO PSW.

### Weryfikacja hipotez 2--4

Aby móc zastosować metody tablicy wielodzielczej i testu chi-kwadrat
oryginalne wartości liczbowe depresji zamieniono
na skalę porządkową: 0--19 brak/łagodna depresja (B);
20--25 umiarkowana (Ł); 26--63 ciężka depresja (C).

### Depresja a płeć 

Tablica wielodzielcza i test chi-kwadrat:

```{r, echo=F}
dep.sex.f <- s0 %>%
  select (Depresja, plec) %>% 
  table()

dep.sex.t <- kable(dep.sex.f)
dep.sex.t

chi_test <- chisq.test(dep.sex.f)
chi_test
```

### Depresja a staż 

Tablica wielodzielcza i test chi-kwadrat:

```{r, echo=F}
## tablica 
## depresja staż

dep.staz.f <- s0 %>%
  select (Depresja, staz) %>% 
  table()

dep.staz.t <- kable(dep.staz.f)
dep.staz.t

chi_test <- chisq.test(dep.staz.f)
chi_test
```

albo jeżeli depresję mierzymy na skali liczbowej
można porównać wartości średnie i zastosować test Kruskalla-Wallisa

```{r}
s0.staz <- s0 %>%
  group_by(staz) %>%
  summarise(m = mean(P), n=n())
kable(s0.staz, col.names = c('staż', 'średnia', 'n'))


kw<- kruskal.test(P ~ staz, data = s0)
kw["p.value"]
```

Wynik jest ten sam (brak zależności)

### Depresja a rodzaj miejsca pracy  

Tablica wielodzielcza i test chi-kwadrat:

```{r}
##
dep.praca.f <- s0 %>%
  select (Depresja, praca) %>% 
  table()

dep.praca.t <- kable(dep.praca.f)
dep.praca.t

chi_test <- chisq.test(dep.praca.f)
chi_test
```

Albo jeżeli depresję mierzymy na skali liczbowej
można porównać wartości średnie i zastosować test Manna-Whitneya

```{r, echo=F}
## Depresja ~ praca
s0.mp <- s0 %>%
  group_by(praca) %>%
  summarise(m = mean(P), n=n())
kable(s0.mp, col.names = c('m-pracy', 'średnia', 'n'))
wilcoxp <- wilcox.test(P ~ praca, data=s0)
wilcoxp['p.value']
```

Wynik jest ten sam (brak zależności)

## Wnioski

* Depresja nie jest istotnym problemem wśród studentów RM/PO PSW

* Nie ma związku pomiędzy depresją a stażem, płcią i miejscem pracy

## Przykład 3:

<span style="color: red;">W przygotowaniu na podstawie ankiety:
https://docs.google.com/forms/d/1bgNMhPEJMjiWeLfrmEAnPpns5U7Rooc-KOaeS7XlLV0/edit
</span>

# Załączniki

## Ankieta Depresja: Skala Depresji Becka

### Pytania

Pytanie 1

0. Nie jestem smutny ani przygnębiony.
1. Odczuwam często smutek, przygnębienie
2. Przeżywam stale smutek, przygnębienie i nie mogę uwolnić się od tych przeżyć.
3. Jestem stale tak smutny i nieszczęśliwy, że jest to nie do wytrzymania.

Pytanie 2

0. Nie przejmuję się zbytnio przyszłością.
1. Często martwię się o przyszłość.
2. Obawiam się, że w przyszłości nic dobrego mnie nie czeka.
3. Czuję, że przyszłość jest beznadziejna i nic tego nie zmieni.

Pytanie 3

0. Sądzę, że nie popełniam większych zaniedbań.
1. Sądzę, że czynię więcej zaniedbań niż inni.
2. Kiedy spoglądam na to, co robiłem, widzę mnóstwo błędów i zaniedbań.
3. Jestem zupełnie niewydolny i wszystko robię źle.

Pytanie 4

0. To, co robię, sprawia mi przyjemność.
1. Nie cieszy mnie to, co robię.
2. Nic mi teraz nie daje prawdziwego zadowolenia.
3. Nie potrafię przeżywać zadowolenia i przyjemności; wszystko mnie nuży.

Pytanie 5

0. Nie czuję się winnym ani wobec siebie, ani wobec innych.
1. Dość często miewam wyrzuty sumienia.
2. Często czuję, że zawiniłem.
3. Stale czuję się winny.

Pytanie 6

0. Sądzę, że nie zasługuję na karę
1. Sądzę, że zasługuję na karę
2. Spodziewam się ukarania
3. Wiem, że jestem karany (lub ukarany)

Pytanie 7

0. Jestem z siebie zadowolony
1. Nie jestem z siebie zadowolony
2. Czuję do siebie niechęć
3. Nienawidzę siebie

Pytanie 8

0. Nie czuję się gorszy od innych ludzi
1. Zarzucam sobie, że jestem nieudolny i popełniam błędy
2. Stale potępiam siebie za popełnione błędy
3. Winię siebie za wszelkie zło, które istnieje

Pytanie 9

0. Nie myślę o odebraniu sobie życia
1. Myślę o samobójstwie — ale nie mógłbym tego dokonać
2. Pragnę odebrać sobie życie
3. Popełnię samobójstwo, jak będzie odpowiednia sposobność

Pytanie 10

0. Nie płaczę częściej niż zwykle
1. Płaczę częściej niż dawniej
2. Ciągle chce mi się płakać
3. Chciałbym płakać, lecz nie jestem w stanie

Pytanie 11

0. Nie jestem bardziej podenerwowany niż dawniej
1. Jestem bardziej nerwowy i przykry niż dawniej
2. Jestem stale zdenerwowany lub rozdrażniony
3. Wszystko, co dawniej mnie drażniło, stało się obojętne

Pytanie 12

0. Ludzie interesują mnie jak dawniej
1. Interesuję się ludźmi mniej niż dawniej
2. Utraciłem większość zainteresowań innymi ludźmi
3. Utraciłem wszelkie zainteresowanie innymi ludźmi

Pytanie 13

0. Decyzje podejmuję łatwo, tak jak dawniej
1. Częściej niż kiedyś odwlekam podjęcie decyzji
2. Mam dużo trudności z podjęciem decyzji
3. Nie jestem w stanie podjąć żadnej decyzji

Pytanie 14

0. Sądzę, że wyglądam nie gorzej niż dawniej
1. Martwię się tym, że wyglądam staro i nieatrakcyjnie
2. Czuję, że wyglądam coraz gorzej
3. Jestem przekonany, że wyglądam okropnie i odpychająco

Pytanie 15

0. Mogę pracować jak dawniej
1. Z trudem rozpoczynam każdą czynność
2. Z wielkim wysiłkiem zmuszam się do zrobienia czegokolwiek
3. Nie jestem w stanie nic zrobić

Pytanie 16

0. Sypiam dobrze, jak zwykle
1. Sypiam gorzej niż dawniej
2. Rano budzę się 1–2 godziny za wcześnie i trudno jest mi ponownie usnąć
3. Budzę się kilka godzin za wcześnie i nie mogę usnąć

Pytanie 17

0. Nie męczę się bardziej niż dawniej
1. Męczę się znacznie łatwiej niż poprzednio.
2. Męczę się wszystkim, co robię.
3. Jestem zbyt zmęczony, aby cokolwiek robić.

Pytanie 18

0. Mam apetyt nie gorszy niż dawniej
1. Mam trochę gorszy apetyt
2. Apetyt mam wyraźnie gorszy
3. Nie mam w ogóle apetytu

Pytanie 19

0. Nie tracę na wadze (w okresie ostatniego miesiąca)
1. Straciłem na wadze więcej niż 2 kg
2. Straciłem na wadze więcej niż 4 kg
3. Straciłem na wadze więcej niż 6 kg

Pytanie 20

0. Nie martwię się o swoje zdrowie bardziej niż zawsze
1. Martwię się swoimi dolegliwościami, mam rozstrój żołądka, zaparcie, bóle
2. Stan mojego zdrowia bardzo mnie martwi, często o tym myślę
3. Tak bardzo martwię się o swoje zdrowie, że nie mogę o niczym innym myśleć

Pytanie 21

0. Moje zainteresowania seksualne nie uległy zmianom
1. Jestem mniej zainteresowany sprawami płci (seksu)
2. Problemy płciowe wyraźnie mniej mnie interesują
3. Utraciłem wszelkie zainteresowanie sprawami seksu

### Nazwy pytań:

Odczuwanie smutku i przygnębienia (1)
Martwienie się o przyszłość (2)
Uważasz, że zaniedbujesz swoje obowiązki? (3)
Jesteś zadowolony z siebie? (4)
Czy często masz poczucie winy? (5)
Czy zasługujesz na karę? (6)
Zadowolenie z siebie (7)
Czy czujesz się gorszy od innych? (8)
Czy masz myśli samobójcze? (9)
Często chce Ci się płakać? (10)
Jesteś ostatnio bardziej nerwowy i rozdrażniony? (11)
Czy zmieniło się coś w Twoim zainteresowaniu innymi ludźmi? (12)
Czy ostatnio miewasz większe problemy z podejmowaniem różnych decyzji? (13)
Czy uważasz, że wyglądasz gorzej i mniej atrakcyjnie niż kiedyś? (14)
Czy masz większe trudności z wykonywaniem różnych prac i zadań? (15)
Masz kłopoty ze snem? (16)
Czy męczysz się bardziej niż zwykle? (17)
Czy masz kłopoty z apetytem? (18)
W ciągu ostatniego miesiąca nie stosowałem diety, aby schudnąć,
lecz straciłem na wadze (19)
Czy ostatnio bardziej martwisz się swoim stanem zdrowia? (20)
Czy masz kłopoty z potencją? (21)

### Interpretacja wyników

1. 00--11 (brak depresji)
2. 12--19 (depresja łagodna)
3. 20--25 (depresja umiarkowana)
4. 26--63 (depresja ciężka)

### Źródło

https://psychiatra.bydgoszcz.eu/publikacje-dla-pacjenta/depresja/skala-depresji-becka/

http://centrum-psychologiczne.com/files/files/Skala_Depresji_Becka_word.pdf

## Ankieta Palenie

Poziom wiedzy personelu pielęgniarskiego na temat szkodliwości palenia tytoniu

### Pytania

1. Płeć
□ Kobieta
□ Mężczyzna

2. Wiek

3. Pochodzenie
□ wieś
□ Miasto do 20 tys. mieszkańców
□ Miasto powyżej 20 tyś mieszkańców

4. Wykształcenie
□ Średnie medyczne
□ Licencjat pielęgniarstwa
□ Magister pielęgniarstwa
□ Inne wyższe

5. Staż pracy
□ Mniej niż rok
□ 1-10 lat
□ 10-15 lat
□ Więcej niż 15 lat

6. Miejsce pracy
□ Oddział zabiegowy
□ Oddział zachowawczy
□ Przychodnia/poradnia

7. Czy kiedykolwiek paliłeś/aś papierosy?
□ Paliłem/łam
□ W dalszym ciągu palę
□ Nigdy nie paliłem/am

8. Od ilu lat palisz?
□ Nie palę/Nie dotyczy
□ Mniej niż rok
□ 1-10 lat
□ 11-15 lat
□ Więcej niż 15 l

9. Czy zdarza Ci się palić w miejscu pracy?
□ Tak
□ Nie
□ Nie dotyczy

10. Czy próbowałeś kiedykolwiek rzucić palenie?
□ Tak, udało się
□ Tak, ale wróciłem/am do nałogu
□ Nie
□ Nie dotyczy

11. Czy paląc przyznajesz się do uzależnienia
□ Tak
□ Nie
□ Nie dotyczy

12. Uważasz, że bardziej szkodliwe dla zdrowia jest:
□ Palenie czynne - dym tytoniowy wdychany bezpośrednio przez palacza
□ Palenie bierne-boczny strumień dymu
☒ Każda forma kontaktu z dymem jest równie szkodliwa
□ Nie wiem/Nie mam zdania

13. Czy uważasz,że przepisy prawa powinny zabraniać palenia w obecności dzieci
poniżej 15 roku życia?
□ Tak
□ Nie
□ Nie wiem/nie mam zdania

14. Czy przerwa na papierosa pomaga Ci w sytuacjach stresowych?
□ Tak
□ Nie
□ Nie dotyczy

15. Czy palenie nikotyny sprawia Ci przyjemność?
□ Tak
□ Nie
□ Nie dotyczy

16. Jakie według Ciebie choroby układu oddechowego mogą być spowodowane
bezpośrednio przez palenie papierosów?(wielokrotnego)
☒ Przewlekła obturacyjna choroba płuc
☒ Astma oskrzelowa
☒ Alergie wziewne
□ Gruźlica
□ Zapalenie płuc
☒ Przewlekłe zapalenie oskrzeli
☒ Infekcje dróg oddechowych
□ Palenie nie powoduje chorób układu oddechowego
□ Nie wiem

17. Jakie według Ciebie choroby kardiologiczne mogą być spowodowane
bezpośrednio przez palenie papierosów? (wielokrotnego)
☒ Nadciśnienie tętnicze krwi
☒ Zawał mięśnia sercowego
☒ Udar mózgu
☒ Choroba niedokrwienna serca
☒ Miażdżyca tętnic obwodowych
☒ Zaburzenie rytmu serca
☒ Choroba Buergera
□ Hipercholesterolemia
□ Tętniak aorty
□ Palenie nie powoduje chorób kardiologicznych

18. Czy palenie papierosów powoduje choroby układu pokarmowego?
☒ Tak
□ Nie
□ Nie wiem

19. Jaki według Ciebie ma wpływ palenie papierosów na narządy zmysłów? (wielokrotnego)
☒ Upośledza węch i smak
☒ Powoduje podrażnienie spojówek
☒ Obniża apetyt
☒ Niszczy struny głosowe
☒ Zmniejsza ostrość wzroku
□ Palenie nie ma negatywnego wpływu na narządy zmysłu.

20. Jak oceniasz swoją wiedzę na temat palenia papierosów i jego wpływu na zdrowie człowieka?
□ Bardzo dobrze
□ Dobrze
□ Przeciętnie
□ Źle

21. Czy wzorce sięgania po tytoń wyniosłaś/wyniosłeś z domu rodzinnego
□ Tak
□ Nie
□ Nie dotyczy


Prawidłowe odpowiedzi zaznaczono ☒

# Łagodne wprowadzenie z Jamovi

Jak wspomniano w rozdziale 1, statystkę można uprawiać (tj. liczyć statystyki w drugim tego słowa znaczeniu :-))
wykorzystując różne programy. My zdecydowaliśmy się promować **Jamovi**, program 
który naszym zdaniem jest najlepszym -- z punktu widzenia większości
studentów Nauk o Zdrowiu -- połączeniem ceny, możliwości, prostoty i łatwości nauki.

## Podstawy pracy z Jamovi

Jamovi jest oprogramowaniem rozpowszechnianym na licencji typu *Open Source*,
a więc można go używać za darmo. Program jest dostępny ze strony
https://www.jamovi.org/download.html. Klikamy, ściągamy, uruchamiamy instalator.
Program jest dość duży, ale to nie jest aż tak wielki problem w czasach kiedy
pojemności dysków w domowym komputerze zaczynają się od 250 gigabajtów.
Po zainstalowaniu uruchamiamy program, którego ekrano startowy wygląda jak
na rysunku

![](./jamovi_main_screen.png)

Menu akcji umożliwia wykonanie podstawowych akcji: 

* wczytanie danych i zapisanie danych (pierwsza pozycja menu oznaczona jako
  trzy poziome kreski)

* podgląd (w sensie skontrolowania wartości zmiennych) i modyfikację 
  danych (pozycje **Zmienne** oraz **Dane**)

* wykonanie obliczeń (pozycja **Analizy**)

* modyfikowanie raportu (pozycja **Edit**)


Typowa sesja w **Jamovi**:

1. Wczytanie danych z pliku o praktycznie dowolnym formacie. Jeżeli przykładowo 
   dane są wynikiem wykonania badania ankietowego z wykorzystaniem Formularzy Google to    zalecamy posługiwanie się formatem CSV.

2. Transformacja danych. Przekodowanie wartości nominalnych na rangi. Przekodowanie
wartości liczbowych na nominalne. 
Odwrócenie pytań odwróconych. Obliczenie sum/srednich rang dla wielu zmiennych.

3. Wykonanie obliczeń: 

  1. Analiza struktury (**Eksploracja**), 
  2. Analiza zależności między zmienną liczbową a nominalną (*testy t*/**ANOVA**),
  3. Analiza zależności między zmiennymi liczbowymi: współczynnik korelacji
     liniowej/macierz korelacji (*Regresja*)
  4  Analiza zależnosci między zmienną liczbową a zmiennymi liczbowymi/nominalnymi:
     regresja liniowa i logistyczna (**Regresja**)
  4. Analiza zależności między zmiennymi nominalnymi: tablica wielodzielcza, test
    chi-kwadrat zgodności (*Częstości*)
    
   Wykonanie obliczeń jest banalnie proste i sprowadza się do wybrania myszką odpowiednich
   zmiennych oraz procedury która ma być wykonana. 
   Wynik obliczeń pojawia się natychmiast w **oknie wyników**. Jeżeli coś 
   nam nie wyszło można procedurę poprawić a poprzedni wynik usunąć z okna wynikowego.
   
4. Zapisania  danych (pozycja trzy poziome kreski). Po skończeniu pracy wynik można
   zapisać żeby np. wysłać wykładowcy lub nie zaczynać od zera jeżeli będziemy musieli
   pracę kontynuuować bo wykładowca chciał żebyśmy coś poprawili.
   
## Przykład: analiza ankiety satysfakcja--wiedza o paleniu--zamiar odejścia

Przykład nieco absurdalny, ale za to w zwartej postaci ilustrujący 
praktyczne sposoby transformacji danych oraz
wykorzystania wszystkich procedur omawianych w podręczniku.

### Wczytanie danych

W wyniku przeprowadzenia badania ankietowego zebrano za pomocą Formularza Google
dane dotyczące
satysfkacji/zamiaru odejścia oraz wiedzy nt. szkodliwości palenia tytoniu.
Wyniki wyeksportowano do arkusza kalkulacyjnego, którego początek
wygląda jakoś tak:

![](./GoogleFormsTestA.png)
Ankieta składa się z 10 następujących pytań:

`Ogólnie rzecz biorąc nie lubię swojej pracy`	(kolumna `B`),
`Ogólnie rzecz biorąc jestem zadowolony ze swojej pracy` (`C`),
`Ogólnie rzecz biorąc, lubię tu pracować`	(`D`),
`Jakie według Ciebie choroby układu oddechowego mogą być spowodowane
bezpośrednio przez palenie papierosów?` (`E`),
`Często poważnie rozważam odejście z obecnej pracy` (`F`),
`Zamierzam rzucić obecną pracę`	(`G`),
`Zacząłem szukać innej pracy` (`H`),
`Płeć`	(`I`),
`Wiek (w latach)`	 (`J`),
oraz `Staż pracy` (`K`).

Ponadto Formularz Googla dodał automatycznie sygnaturę czasową
jako zawartość pierwszej kolumny (`A`).

Zmieniamy wartości w pierwszym wierszu, który powinien zawierać nazwy zmiennych.
Nazwy zmiennych powinny być jednowyrazowe i w miarę krótkie żeby się później
można nimi wygodnie posługiwać. Jednocześnie nie powinny być za krótkie żeby
od razu było widać jakie dane zawiera zmienna.

Jak widać
pytania z kolumn `B`--`C` mierzą to samo (satysfakcję) 
więc zmieniamy im nazwę na bardziej zwartą `s1`, `s2` oraz `s3` (`s` od satysfakcja). 
Podobnie
ponieważ pytania z kolumn `F`--`H` też mierzą to samo (zmiar odejścia), to
też zmieniamy nazwy na coś krótszego: `zo1`, `zo2`, `zo3`. Kolumnę `E` nazywamy
`wiedza_nt_palenia` a kolumny `I`, `J` oraz `K` odpowiednio:
`plec`, `wiek` oraz `staz`.

Teraz arkusz wygląda jakoś tak:

![](./GoogleFormsTestHdr.png)

Arkusz eksportujemy wybierając format CSV. Bez problemu powinniśmy
go wczytać do Jamovi (trzy poziome kreski →`Otwórz`)

Reasumując:

* Pytania oznaczone jako `s1`/`s2`/`s3` mierzą
  **satysfakcję z pracy**; pytania `zo1`/`zo2`/`zo3` mierzą **zamiar odejścia
  z pracy**. Pytania `s1`--`s3` oraz `zo1`--`zo3` są pytaniami jednokrotnego wyboru.
  
* Pytanie oznaczone jako `wiedza_nt_palenia` mierzy wiedzę na temat palenia tytoniu.
  Jest to przykład wykorzystania pytania z wielokrotnym wyborem.

* Pytania `plec`, `wiek`, `staz` mierzą płeć (`kobieta`/`mężczyna`), wiek (lata ukończone)
  oraz staż pracy (lata przepracowane)
  
* Pierwsza kolumna nie jest potrzebna ale jest dodawana przez aplikację Formularze Google.

![](./Jamovi_data_import.png)

### Przekodowanie danych

Zwykle zawartość arkusza zawierającego wyniki ankiety wymaga przekodowania.
W naszym przykładzie należy wykonać:

* Zmienne s1--s3 oraz zo1--zo3 są mierzone w skali porządkowej. Wartości tych zmiennych
  chcemy zmienić (przekodować) na rangi wg schematu: `Zdecydowanie się nie zgadzam` = 1;
  `Nie zgadzam się` = 2; `Trudno powiedzieć` = 3 itd.
  Dodatkowo zauważmy że s1 jest pytaniem odwróconym. 
  W takich pytaniach należy przeliczyć rangi wg prostej formuły s1r = 6 - s1.
  
  * Miarą satysfakcji będzie suma rang s1r+s2+s3.
  * Miarą zamiaru odejścia będzie suma rang zo1+zo2+zo3
  
* Zmienna `plec` jest mierzona w skali nominalnej. Nie musimy jest przekodowywać

* Wartość zmiennej `wiedza_nt_palenia` należy przekodować na liczbę wg schematu:
  za wybranie poprawnej odpowiedzi plus jeden punkt; za wybranie błędnej odpowiedzi 
  minus jeden punkt.
  
  * Miarą wiedzy nt. palenia będzy suma punktów uzyskanych za odpowiedzi prawidłowe
    minus suma punktów uzyskanych za odpowiedzi nieprawidłowe.
  
Uwaga: Sposób mierzenia wiedzy nt. palenia jest niepotrzebnie pokręcony; zamiast
pytania z wielokrotnym wyborem spośród 8 możliwości/wariantów prościej jest zastosować
8 pytań Tak/Nie po czym pytania poprawne zsumować 
a pytania niepoprawne też dodać a wartość odjąć od sumy uzyskanej dla pytań poprawnych.
My o tym wiemy, że tak jest bez sensu ale pokazujemy jako przykład przekodowania
pytania z wielokrotnym wyborem.

* Wartości zmiennych `wiek` oraz `staz` są liczbami. Mogą być analizowane tak-jak-są
(regresja/korelacja) ale można też je przekodować na wartości nominalne
(mały-średni-duży staż) i zastosować metody z grupy zmienna-liczbowa/zmienna nominalna
(takie jak test ANOVA czy Kruskala-Wallisa)

Przekodowanie wykonujemy wybierając **Dane** w menu głównym. 

1. Klikamy w nazwę zmienną, którą zamierzamy przekodować. Niech to będzie `s1`. 
   Kolumna po kliknięciu zmieni kolor. 

2. Wybieramy ikonę `Przekształcenie`. Wypełniamy jak na rysunku poniżej:

Uwaga: Jamovi nie zmieni wartości zmiennej `s1` tylko utworzy nową zmienną
z przekodowanymi wartościami. Zmienna na podstawie której jest tworzona
nowa zmienna nazywa się źródłową (`s1` w naszym przykładzie jest źródłowa.)

![](./przeksztalcenie_0.png)

Wpisujemy sensowną nazwę (na przykład `s1p` od przekodowana). Jak będziemy
używać sensownych nazwa łatwiej będzie nam się pracowało. Dobrze jest
też podać w opisie co zawiera zmienna.

Klikamy w pole wyboru na dole (obok napisu `za pomocą przekształcenia`)
Powinniśmy zobaczyć coś takiego:

![](./przeksztalcenie_1.png)

Wybieramy `Utwórz nowe przekształcenie`. Wpisujemy sensowną nazwę
przekształcenia (na przykład `Likert2R5`) oraz formułę przekształcenia:

```
IF ($source=="Zdecydowanie się nie zgadzam", 1,
 IF ($source=="Nie zgadzam się", 2,
   IF ($source=="Trudno powiedzieć", 3,
      IF ($source=="Zgadzam się", 4, 5))))
```

Formuła może wydawać się przerażająca, ale jest koncepcyjnie bardzo prosta:

```
IF (warunek, jeżeli-prawda, jeżeli-fałsz)
```

`Warunek` to fragment `$source=="Zdecydowanie się nie zgadzam"`:

* `$source` oznacza bieżącą wartość zmiennej źródłowej

* `==` to **operator** równości; jest więcej operatorów, które można
  wybrać z menu

* `$source=="Zdecydowanie się nie zgadzam"` oznacza, że jeżeli 
  bieżącą wartością w kolumnie źródłowej jest `Zdecydowanie się nie zgadzam`
  to wykonaj `jeżeli-prawda`; w wypadku przeciwnym wykonaj `jeżeli-fałsz`.

`jeżeli-prawda` to zwykle wstawienie nowej wartości; 
`jeżeli-fałsz` to często następna formuła `IF` albo wstawienie innej
nowej wartości. Przykładowo jeżeli 
bieżącą wartością w kolumnie źródłowej jest `Zdecydowanie się nie zgadzam`
  to wstaw `1`, jeżeli nie jest to wstaw `0`:
  
```
  IF ($source=="Zdecydowanie się nie zgadzam", 1,0)
```

Ponieważ w naszym przykładzie mamy do przekodowania nie dwie a 5 wartości 
musimy użyć 4 warunków, które
są zagnieżdżone jeden w drugim. Można powyższe przepisać, można 
też skopiować z podręcznika i wkleić do Jamovi.

![](./przeksztalcenie_1p.png)

Naciskamy Enter i gotowe. Zostaje utworzona zmienna `s1p`
zawierająca zamiast napisów rangi.

Jeżeli uporaliśmy się z przekodowaniem `s1` 
ustawiamy kursor na `s2` w okno danych. Naciskamy ikonę `Przekształcenie`.
Upewniamy się że zmienną źródłową jest `s2`.
Zmieniamy nazwę nowej zmiennej na `s2p`. Klikamy
w pole wyboru przekształcenia. Poprzednio były tam tylko dwie pozycje
`Brak` oraz `Utwórz nowe przekształcenie` teraz jest trzecia pozycja
`Likert2R5` czyli przekształcenie które zdefiniowaliśmy dla zmiennej s1p.
Wybieramy `Likert2R5` bo zmienną `s2` chcemy przekodować dokładnie
w ten sam sposób jak `s1`. Po wybraniu przekształcenia w oknie danych
pojawia się nowa zmienna `s2p`

![](./przeksztalcenie_3.png)

W podobny łatwy sposób przekodowujemy `s3` oraz `zo1`, `zo2`, `zo3`

**Uwaga**: polecenie `IF` wpisujemy używając dużych liter. Słowo
`$source` wpisujemy tak jak jest to zademonstrowane (`$Source` jest błędem.)

Przekodowanie pytanie z możliwością wielokrotnego wyboru jest równie
proste tyle że pisania jest więcej. Zmienna `wiedza_na_temat_palenia` może zawierać
do ośmiu następujących napisów oddzielonych średnikami:
`Przewlekła obturacyjna choroba płuc`,
`Astma oskrzelowa`,
`Alergie wziewne`,
`Gruźlica` (B),
`Zapalenie płuc` (B),
`Przewlekłe zapalenie oskrzeli`,
`Infekcje dróg oddechowych`,
`Palenie nie powoduje chorób układu oddechowego` (B).

Odpowiedzi błędne oznaczono jako (B).

W arkuszu lub oknie danych Jamovi ta zmienna wygląda jakoś tak:

```
...,Przewlekła obturacyjna choroba płuc,...
...,Przewlekła obturacyjna choroba płuc;Astma oskrzelowa;Alergie wziewne;Gruźlica;Zapalenie płuc;Przewlekłe zapalenie oskrzeli,...
...,Astma oskrzelowa,
...,Astma oskrzelowa;Gruźlica;Przewlekłe zapalenie oskrzeli,...
...,Przewlekła obturacyjna choroba płuc;Astma oskrzelowa;Infekcje dróg oddechowych,...
```

Należy zsumować wystąpienia poprawne i wystąpienia błędne. W tym celu trzeba utworzyć tyle
nowych zmiennych ile jest wariantów odpowiedzi, czyli w naszym przykładzie osiem. Każda
nowa zmienna jest przekodowywana za pomocą prostej formuły wykorzystującą funkcję `CONTAINS` (zawiera).
Przykładowo pierwsza (nazwijmy ją `wiedz1p`) powinna być utworzona w oparciu o następujące przekształcenie

```
CONTAINS("Przewlekła obturacyjna choroba płuc", $source)
```
![](./przeksztalcenie_4.png)

![](./przeksztalcenie_contains.png)

Funkcja CONTAINS wstawi 1 jeżeli `$source` zawiera `Przewlekła obturacyjna choroba płuc`.
Oczywiście następna zmienna powinna zawierać `Astma oskrzelowa`:

```
CONTAINS("Astma oskrzelowa", $source)
```
I tak dalej aż do ostatniego wariantu odpowiedzi:

```
CONTAINS('Alergie wziewne', $source)
CONTAINS('Gruźlica', $source)
CONTAINS('Zapalenie płuc', $source)
CONTAINS('Przewlekłe zapalenie oskrzeli', $source)
CONTAINS('Infekcje dróg oddechowych', $source)
CONTAINS('Palenie nie powoduje chorób układu oddechowego', $source)
```

Każda zmienna `wiedza1`...`wiedza8` zawiera 1 jeżeli ankietowany wskazał dany wariant lub zero jeżeli
nie wskazał.

Ostatnia sprawa to przekodowanie liczb na wartości nominalne. Przykładowo chcemy podzielić
ankietowanych na grupy stażowe: mały (do pięciu lat), średni (5--15 lat), duży (16 i więcej) staż pracy.

Wartości liczbowe stażu pracy zawiera zmienna `staz`. Aby ją przekodować
należy użyć następującego przekształcenia:

```
IF ($source < 5, "M",
  IF ($source < 16, "S", "D"))
```

Poleceń `IF` musi być o jedno mniej niż mamy klas. W naszym przykładzie zatem dwa. Jeżeli
`staż` jest mniejszy od 5 wstawiony zostanie napis `M`, jeżeli `staż` jest mniejszy od 16
wstawiony zostanie napis `S` a w przeciwnym wypadku zostanie wstawiony napis `D`.

Gdyby ktoś się niepokoił że 3 spełnia jednocześnie `$source < 5` oraz `$source < 16`
to dodamy, że pierwszy się liczy. Przekształcenie kończy działanie po spełnieniu pierwszego warunku i nie
wykonuje dalszych porównań. Dlatego liczba 3 zostanie zamieniona na `M` a nie na `S`.

Podobnie przekodowujemy zmienną `wiek`.

### Wyliczenie nowych zmiennych

**Przekodowanie** to była w zasadzie zamiana sposobu mierzenia. **Wyliczenie** to utworzenie
nowej zmiennej, zwykle w oparciu o jakąś formułę matematyczną. Na przykład odwrócenie pytanie s1p
realizuje `s1pr = 6 - s1p`. Satysfakcja to suma rang z trzech pytań:
`satysfakcja =  s1pr + s2p + s3p`.

W celu wyliczanie nowych zmiennych należy wybrać Dane Oblicz. Pojawia sie okno
zmiennej wyliczonej zatytułowane `ZMIENNA WYLICZONA`

Pierwszy pasek zawiera nazwę zmienną (domyślnie nazwę kolumny w konwencji arkusza kalkulacyjnego, w przykładzie
jest to litera `H`) W polu definiowania zmiennej należy wpisać
stosowną formułę matematyczną. W przypadku odwracania pytania `s1p` będzie to:

```
6 - s1p
```

W przypadku liczenia łącznej satysfakcji (przy założeniu,
że wcześniej utworzyliśmy zmienną `s1pr`):

```
SUM(s1pr, s2p, s3p)
```

![](./zmienna_satysfakcja.png)

Jeżeli nie chcemy sumy ale np. średnią powinniśmy użyć

```
MEAN(s1pr, s2p, s3p)
```

Inne funkcje matematyczne są dostępne po klinięciu w pole wyboru znajdujące się po lewej
stronie pola definiowania zmiennej.

Powiedzieliśmy że miarą wiedzy nt. palenia będzy suma punktów uzyskanych za odpowiedzi prawidłowe minus
suma punktów uzyskanych za odpowiedzi nieprawidłowe. Odpowiedzi prawidłowe to
`w1p`, `w2p`, `w3p`, `w6` oraz `w7`. Odpowiedzi błędne to `w4p`, `w5p`, `w8p`. Zatem
w polu definiowania zmiennej wpisujemy:

```
SUM(w1p, w2p, w3p, w6, w7) - SUM(w4p, w5p, w8p)
```

### Analiza struktury

Wybieramy `Analizy`→`Eksploracja`→`Statystyki opisowe`.

W wyświetlonym oknie po lewej deklarujemy co ma być liczone. Wynik
pojawi się po prawej (por rysunek)

Ustawiamy kursor na zmiennej która nas interesuje i klikamy w strzałkę górną.
Jeżeli chcemy podzielić wartości zmiennej na grupy według jakiejś 
zmiennej nominalnej, to ustawiamy kursor na tej zmiennej nominalnej
(na przykład `plec`) i klikamy strzałkę dolną.

Można analizować wiele zmiennych na raz. Wystarczy w tym celu ustawić
kursor na zmiennej i kliknąć w odpowiednią strzałkę. Zawartość okna
wynikowego zostanie automagicznie uaktualniona.

![](./statystyki_opisowe_okno.png)
Poniżej okien wyboru zmiennych są zakładki określające
precyzyjnie co ma być obliczone oraz jakie wykresy mają
zostać wyrysowane. Przykładowo domyślny wydruk nie zawiera
rozstępu kwartylowego. Żeby go dodać do wyniku należy
w zakładce `Statystyki` zaznaczyć przycisk `IQR`.


![](./statystyki_opisowe_wynik.png)

### Analiza zależności: zmienne nominalne

Wybieramy `Analizy`→`Częstości`→`Próby niezależne`.

Podobnie jak w przypadku analizy struktury jest wyświetlana
lista zmiennych oraz okna i strzałki pozwalające
wygodnie wybrać to co ma być analizowane. Jest to tak proste
że wystarczy przyjrzeć się przykładowemu rysunkowi żeby
wiedzieć jak postępować. Przykładową analizę zależności
pomiędzy zmiennymi nominalnymi `zamiarOklasa` oraz `staz.klasa` przedstawia rysunek.

![](./tabele_krzyzowe.png)


### Analiza zależności: zmienna liczbowa/zmienna nominalna

Wybieramy `Analizy`→`Testy t`→`Test t dla prób niezależnych` i/lub
`Analizy`→`ANOVA`→`Jednoczynnikowa ANOVA`.

Zostanie wyświetlony znajomy interfejs. Wybieramy
co trzeba. Wynik automagicznie pojawia się w lewym oknie.


![](./testy.png)

### Analiza zależności: zmienna liczbowa/zmienna liczbowa lub nominalna
 
Wybieramy `Analizy`→`Regresja`→`Regresja liniowa`

Interfejs podobny do poprzednio opisywanych. Wybieramy
zmienną zależną (musi oczywiście być liczbowa) klikając w górną strzłkę. 
Zmienne niezależne mierzone w skali liczbowej
klikając w środkową strzałkę. Zmienne niezależne mierzone
w skali nominalnej klikając w dolną strzałkę.
Wynik automagicznie pojawia się w lewym oknie.

![](./regresja_liniowa.png)

### Regresja logistyczna

Wybieramy  `Analizy`→`Regresja`→`Regresja logistyczna`→`Dwie wartości`

Interfejs podobny do analizy regresji. Wybieramy
zmienną zależną klikając w górną strzłkę. Zmienna ta
**musi** być zmienną dwuwartościową.

Zmienne niezależne mierzone w skali liczbowej
wybieramy klikając w środkową strzałkę a zmienne niezależne mierzone
w skali nominalnej klikając w dolną strzałkę.

![](./regresja_logistyczna.png)
